<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小灰灰在青青草原</title>
  
  
  <link href="https://xinrihui.github.io/atom.xml" rel="self"/>
  
  <link href="https://xinrihui.github.io/"/>
  <updated>2022-12-24T16:17:10.782Z</updated>
  <id>https://xinrihui.github.io/</id>
  
  <author>
    <name>Xinrihui</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>计算机组成原理 -数据sense</title>
    <link href="https://xinrihui.github.io/2022/12/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%20-%E6%95%B0%E6%8D%AEsense/"/>
    <id>https://xinrihui.github.io/2022/12/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%20-%E6%95%B0%E6%8D%AEsense/</id>
    <published>2022-12-24T16:17:10.000Z</published>
    <updated>2022-12-24T16:17:10.782Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2022-12-24 16:12:25 +0000"/><meta name="source" content="yinxiang.superNote"/><meta name="updated" content="2022-12-24 16:16:12 +0000"/><title>计算机组成原理 -数据sense</title></head><body><div><br/></div><h1>1.不同硬件的性能指标</h1><div><br/></div><h2>Latency</h2><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:707px;" width="707px"><colgroup><col style="width: 285px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 162px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Latency</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Notes</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Notes2</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>L1 cache reference  （<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">读取CPU的一级缓存</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(255, 194, 0);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>0.5 ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Branch mispredict<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">(转移、分支预测)</span></span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>5   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>L2 cache reference（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);"> 读取CPU的二级缓存</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>7   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>14x L1 cache</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>L3 cache reference  </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>20   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Mutex lock/unlock（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">互斥锁\解锁</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>25   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Main memory reference（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">读取内存数据</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>100   ns  </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>200x L1 cache</div><div>20x L2 cache, </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Compress 1K bytes with Zippy</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Send 1 KB bytes over 1 Gbps network</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 4 KB randomly from SSD*</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>150,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>150 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from memory</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>250,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(255, 194, 0);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>250 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Round trip within same datacenter（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">从一个数据中心往返一次，ping一下</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>500,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>500 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(0, 168, 45);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="color: rgb(255, 255, 255);">Disk seek（磁盘寻道）</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from 1 Gbps network（千兆网络）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>40X memory, </div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from 10Gbps network（万兆网络）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div> 4X memory</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from disk</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>30,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>30 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>120x memory, </div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from SSD*</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div> 4X memory，</div><div>~1GB/sec </div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Send packet CA-&gt;Netherlands-&gt;CA（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">一个包的一次远程访问</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>150,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>150 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr></tbody></table><div><br/></div><div><span style="font-family: unset;"><span style="color: unset;">#1. 千兆网  万兆网</span></span></div><div> 百兆网（100M）100mbit/s = 0.1 Gbps /s = 100M/8 B/s=12.5MB/s</div><div> 千兆网（1G） 1000mbit/s= 1Gbps /s = 125MB /s</div><div style="text-align:justify;"> 万兆网 （10G） 10000mbit/s=10Gbps /s=1.25GB /s</div><div style="text-align:justify;"><br/></div><div>#2.  内存 和 磁盘的访问速度，随机访问差 100 ,000 倍，顺序访问为 7倍 </div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://stackoverflow.com/questions/61065606/what-is-reference-when-it-says-l1-cache-reference-or-main-memory-reference" rev="en_rl_none">https://stackoverflow.com/questions/61065606/what-is-reference-when-it-says-l1-cache-reference-or-main-memory-reference</a></div><div><a href="https://stackoverflow.com/questions/4087280/approximate-cost-to-access-various-caches-and-main-memory" rev="en_rl_none">https://stackoverflow.com/questions/4087280/approximate-cost-to-access-various-caches-and-main-memory</a></div><div><br/></div><div><br/></div><h2><span style="font-family: unset;"><span style="color: unset;">IOPS </span></span></h2><div><br/></div><div>IOPS 和 数据吞吐量  MBPS(吞吐率) 适用于不同的场合：</div><div>读取10000个1KB文件，用时10秒  Throught(吞吐量)=1MB/s ，IOPS=1000（1s 读取 1000个文件）  追求 IOPS</div><div>读取1个10MB文件，用时0.2秒  Throught(吞吐量)=50MB/s, IOPS=5  追求 吞吐量</div><div><br/></div><div>（1）对4KB数据包进行 连续读 :</div><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:390px;" width="390px"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(255, 194, 0);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>MBPS(吞吐率)</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>IOPS</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>PCIE4.0-SSD</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>7000MB/s</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>PCIE-SSD</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>2000MB /S </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SSD </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>404MB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>103K/S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SAS</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>190MB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>41K/S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SATA</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>124MB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>31K/S</div></td></tr></tbody></table><div>顺序读，SAS总体表现是 SATA硬盘的1.3倍， 普通SSD 总体表现是sata硬盘的4倍：</div><div><br/></div><div>（2）对4KB数据包进行 随机读</div><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:390px;" width="390px"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>MBPS(吞吐率)</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(255, 194, 0);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>IOPS</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>PCIE4.0-SSD</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1000K /S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>PCIE-SSD</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>500 K /S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SSD </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>505MB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>129 K /S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SAS</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1784KB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>456/S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SATA</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>466KB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>114/S</div></td></tr></tbody></table><div><br/></div><div><span style="color: rgb(255, 0, 0);">问题： 机械硬盘 （HDD）IOPS 理论值的计算</span></div><div><br/></div><div>IOPS = 1000 ms/ (寻道时间 + 旋转延迟)。可以忽略数据传输时间。</div><div><br/></div><div>7200 rpm的磁盘 IOPS = 1000 / (10.5 + 4.17) = 68 IOPS</div><div>10000 rpm的磁盘IOPS = 1000 / (7 + 3) = 100 IOPS</div><div>15000 rpm的磁盘IOPS = 1000 / (5 + 2) = 142 IOPS</div><div><br/></div><div><span style="color: rgb(255, 0, 0);">问题：为什么一定是 4KB</span></div><div>在NTFS格式的硬盘中，最小存储单元就是 4KB，测试软件会产生很多4KB小文件，</div><div><br/></div><div>随机：数据是随机分布的，以此来考验SSD对 内部数据的寻找速度，把这一堆 的 4KB小文件乱扔一气，让SSD自己找去吧。</div><div><br/></div><div>顺序：4KB 的小文件 是顺序存放的</div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://blog.csdn.net/luyegang1/article/details/74453879" rev="en_rl_none">https://blog.csdn.net/luyegang1/article/details/74453879</a></div><div><br/></div><h1>2.<span style="font-family: unset;"><span style="color: unset;">数据库的单节点性能</span></span></h1><div><br/></div><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:413px;" width="413px"><colgroup><col style="width: 283px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>QPS</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>MySQL / PosgreSQL 等 SQL 数据库</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1k </div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>MongoDB / Cassandra 等 硬盘型NoSQL 数据库</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10k</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Redis / Memcached</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>100k ~ 1m</div></td></tr></tbody></table><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="计算机组成原理" scheme="https://xinrihui.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
    
    <category term="内存性能" scheme="https://xinrihui.github.io/tags/%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD/"/>
    
    <category term="磁盘性能" scheme="https://xinrihui.github.io/tags/%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD/"/>
    
    <category term="网络性能" scheme="https://xinrihui.github.io/tags/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD/"/>
    
    <category term="延迟" scheme="https://xinrihui.github.io/tags/%E5%BB%B6%E8%BF%9F/"/>
    
    <category term="IOPS" scheme="https://xinrihui.github.io/tags/IOPS/"/>
    
  </entry>
  
  <entry>
    <title>数据结构-查找</title>
    <link href="https://xinrihui.github.io/2022/12/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%9F%A5%E6%89%BE%E6%80%BB%E7%BB%93/"/>
    <id>https://xinrihui.github.io/2022/12/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%9F%A5%E6%89%BE%E6%80%BB%E7%BB%93/</id>
    <published>2022-12-24T16:04:51.000Z</published>
    <updated>2022-12-24T16:10:09.126Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2022-06-23 01:27:46 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2022-06-23 02:35:43 +0000"/><title>数据结构-查找总结</title></head><body><div><img src="/Resources/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%9F%A5%E6%89%BE%E6%80%BB%E7%BB%93.resources/%E6%9F%A5%E6%89%BE-1.jpg" height="1491" width="2386"/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="数据结构和算法" scheme="https://xinrihui.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="二分查找" scheme="https://xinrihui.github.io/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
    
    <category term="跳表" scheme="https://xinrihui.github.io/tags/%E8%B7%B3%E8%A1%A8/"/>
    
    <category term="红黑树" scheme="https://xinrihui.github.io/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"/>
    
    <category term="B+树" scheme="https://xinrihui.github.io/tags/B-%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>MPP 数据库原理</title>
    <link href="https://xinrihui.github.io/2022/12/24/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/"/>
    <id>https://xinrihui.github.io/2022/12/24/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/</id>
    <published>2022-12-24T15:40:19.000Z</published>
    <updated>2022-12-24T15:42:31.713Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2019-03-03 11:24:10 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="evernote.win32"/><meta name="source-url" content="https://www.zybuluo.com/hadoopMan/note/1005029"/><meta name="updated" content="2022-12-24 15:37:00 +0000"/><title>MPP 数据库原理</title></head><body><div><div><span style="font-weight: bold;"><font style="font-size: 16px;">part1. SMP &amp; MPP</font></span></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">1.服务器的CPU 架构：</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">（1）SMP (Symmetric Multi Processing) 对称多处理系统。</font></div><div><font style="font-size: 16px;">所有的CPU共享全部资源，如总线，内存和I/O系统等。多个CPU之间没有区别，平等地访问内存、外设、一个操作系统。操作系统管理着一个队列，每个处理器依次处理队列中的进程。如果两个处理器同时请求访问一个资源（例如同一段内存地址），由硬件、软件的锁机制去解决资源争用问题。每一个共享的环节都可能造成 SMP 服务器扩展时的瓶颈，而<span style="font-weight: bold;">最受限制的则是内存</span>。由于每个 CPU 必须通过相同的内存总线访问相同的内存资源，因此随着 CPU 数量的增加，内存访问冲突将迅速增加。</font></div><div><font style="font-size: 16px;">（2）海量并行处理结构 (MPP ： Massive Parallel Processing)</font></div><div><font style="font-size: 16px;">由多个 SMP 节点  通过节点互联网络连接而成，<span style="font-weight: bold;">每个节点只访问自己的本地资源 ( 内存、存储等 )</span> ，是一种完全无共享 (Share Nothing) 结构，因而扩展能力最好。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">2.优点&amp;缺点</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">（1）MPP系统不共享资源，因此当需要处理的事务达到一定规模时，MPP的效率要比SMP好。由于MPP系统要在不同处理单元之间传送信息，在通讯时间少的时候，那MPP系统可以充分发挥资源的优势，达到高效率。也就是说：操作相互之间没有什么关系，处理单元之间需要进行的通信比较少，那采用MPP。典型的数据仓库环境具有大量复杂的数据处理和综合分析，要求系统具有很高的 I/O 处理能力，并且存储系统需要提供足够的 I/O 带宽与之匹配，因此适合MPP。</font></div><div><font style="font-size: 16px;">（2）OLTP 系统则以联机事务处理为主，每个交易所涉及的数据不多，要求系统具有很高的事务处理能力，能够在单位时间里处理尽量多的交易，因此适合SMP。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-weight: bold;"><font style="font-size: 16px;">引用</font></span></div><div><a href="https://www.cnblogs.com/yubo/archive/2010/04/23/1718810.html"><font style="font-size: 16px;">https://www.cnblogs.com/yubo/archive/2010/04/23/1718810.html</font></a></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><span style="font-weight: bold;">part2. </span><span style="font-weight: bold;">以 impala 为例 理解 MPP 的 pipline 执行</span></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">1. impala 是一个 MPP 的 查询引擎，它受到 google 的 dremel原理的启发而开发出来的，除了 dremel的全部功能之外，它提</font></div><div><font style="font-size: 16px;">供了 dremel不具备的 join 功能，可以说是 dremel的超集。</font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/20415850-44E2-4408-A856-CF67E38E7A4E.png" height="311" width="402"/><br/></font></div><div><font style="font-size: 16px;">2.<span style="font-weight: bold;">impala与 hive 使用同一个元数据库</span>，可以与hive 实现互访，并兼容大部分HQL 语言。 其基本原理是将一个查询根据</font></div><div><font style="font-size: 16px;">数据所在位置分割成为子查询并在各个节点上运行，各个节点运行结果在汇总形成最终结果后返回给客户端。 impala的每</font></div><div><font style="font-size: 16px;">个节点都直接读取本地数据，并在本地执行子查询。 在执行子查询时，节点之间交换数据完成各自的查询。具体的查询树</font></div><div><font style="font-size: 16px;">（图 ２）分布化过程为：</font></div><div><font style="font-size: 16px;">（1）impala接收到 SQL查询首先生成SQL查询树，由查询树区分 在本地运行 或者 是在分布式系统上运行的查询</font></div><div><font style="font-size: 16px;">（2）把SQL查询 拆散后 分配到 到各个节点上，达到高速查询的目的</font></div><div><font style="font-size: 16px;">（3）各个节点直接从 HDFS 的本地文件读取数据，各个节点上分别进行 连接 和 聚合 操作，由各个节点把处理后的数据汇总发送到接受查询的节点上，由该节点进行汇总聚合及最后的排序截取工作。</font></div><div><font style="font-size: 16px;">（4）查询失败就全部重新执行，无法容错。</font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/A88D3DDD-74C9-48DF-B0C3-E8139CC66D7B.png" height="292" width="356"/><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">3.impala 基本架构</font></div><div><font style="font-size: 16px;">impala 在每个节点上运行一个守护进程 impala daemon，每个节点都可以接受查询。 impala daemon 内部细分为impala</font></div><div><font style="font-size: 16px;">规划器（planner）、impala协调器（coordinator）、impala执行引擎（execengine）。 除此之外，impala 还需要运行状态存储器的守</font></div><div><font style="font-size: 16px;">护进程（statestore daemon），由状态存储器来保存和更新各个impala 的状态以供查询。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/CD66E110-738B-44D0-87B7-FCA6D6CE389B.png" height="384" width="801"/><br/></font></div><div><font style="font-size: 16px;">（1）用户通过impala  shell、JDBC／ODBC 程序发送查询命令到一个 impala 节点上。各个节</font></div><div><font style="font-size: 16px;">点对等，都可以有 impala 守护进程，都可以接收查询请求。</font></div><div><font style="font-size: 16px;">（2）由 impala 规划器接收和分析查询命令，<span style="font-weight: bold;">它与 namenode上的 hive、HDFS元数据库</span>和状态储存器进行通信，<span style="font-weight: bold;">获得各部</span></font></div><div><font style="font-size: 16px;"><span style="font-weight: bold;">分数据的位置，并将查询命令分割成小的子查询</span>。 状态储存器保存了各个 impala 节点的状态。</font></div><div><font style="font-size: 16px;">（3）<span style="font-weight: bold;">impala 协调器将子查询分配到各个节点的 impala 执行引擎上</span>。</font></div><div><font style="font-size: 16px;">（4）各个 impala 执行引擎执行各自的查询，它们直接读取本地 HDFS或 hbase的数据，并与其他执行引擎进行通信</font></div><div><font style="font-size: 16px;">以完成各自的查询。</font></div><div><font style="font-size: 16px;">（5）各个 impala 执行引擎把部分结果返回给 impala 协调器。</font></div><div><font style="font-size: 16px;">（6）impala 协调器汇总部分结果组成最终结果，将最终结果返回给客户端。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-weight: bold;"><font style="font-size: 16px;">part3. 对比 MPP 和 批处理计算框架（ MapReduce 和 spark ）</font></span></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">1.每个executor有独立的cpu、内存和磁盘等资源，除非 遇到 shuffle 过程即数据通过网络进行交换，每个executor不能访问其他executor的资源。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">2.每个executor执行同样的数据处理逻辑，处理的数据则是这个executor所在的节点的本地存储的数据分片。下图中垂直的虚线表示同步点（发生 shuffle ）</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">3.MPP 中最大的问题是  “拖后腿的人（straggler） ” 。下图中 大部分时间里，一直都是一个executor7在孤独的执行，而由于shuffle 其他executor必须等待它执行完 。这就是MPP架构问题的根源所在，这种情况很容易发生，比如磁盘做了Raid，但是有磁盘突然坏了，raid的性能就会下降了，或者因为硬件或者OS的问题导致CPU性能下降。</font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/916B631E-7E5B-4645-BBBE-3EE020027F44.png" height="705" width="1093"/><br/></font></div><div><font style="font-size: 16px;">4.并发是指可以有效的同时运行的查询数。MPP是完全“对称的”，即当查询开始执行时，每个节点都在并行的执行完全相同的任务。因此 <span style="font-weight: bold;">MPP支持的并发数和集群的节点数没有关系</span>。<span style="font-weight: bold;">MPP需要为高效数据处理速度放弃 并发</span>。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">5. 原本在两个同步点之间是单独的 stage 在执行，现在在MR中 则将stage切分成多个独立的“task”，在两个同步点之间，这些任务被随机的分配到空闲的executor上。而MPP的任务是和 这个 任务要处理的数据所在的节点绑定的（<span style="font-weight: bold;">计算和存储绑定</span>）。</font></div><div><font style="font-size: 16px;">MR 中，由于数据块 在多个节点上存在，这样计算框架可以在多个节点上启动任务处理本地数据，而不必在慢节点上吊死。</font></div><div><font style="font-size: 16px;">遇到性能差的 executor 只需要给他 较少的task即可。如果慢节点慢到实在不能忍，推测执行可以就会介入：执行慢的节点的任务会在其他节点启动，同时执行（谁先执行完就用谁的结果，而没有执行完的task会被kill掉）。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">6.MPP下，不需要把中间结果写入磁盘，因为每个executor处理一个task，所以数据可以直接“流入”下一执行阶段进行处理，这就是所谓的pipeline执行，性能非常可观。 但是如果在一个单独的executor中串行的处理不相关的task，就必须把中间结果写入本地磁盘，以便下一个stage能开始消费本 stage的数据。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">7.HAWQ 将 MPP和批处理系统进行了融合</font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/BD325DAA-06F6-4FBA-B682-EA149CC2C93F.png" height="449" width="1120"/><br/></font></div><div><font style="font-size: 16px;">Greenplum中的segemnt是指常驻在节点上的PostgreSQL单独实例，当然这里的PostgreSql是经过修改的。这些单实例可以用来生成“executor”进程，每个查询在单节点对应一个executor。如果是小查询，可以由4个executor进程完成或者一个也可以。如果是大的查询，可能就需要100个甚至1000个executor了。不管查询是大是小，都是按照MPP的方式完成的，即一个进程只能处理本地数据，并且中间结果不写磁盘。但是虚拟segment则可以让executor在任何节点执行。</font></div><div><font style="font-size: 16px;">（1）可以动态增加和删除集群中的”straggler“节点，</font></div><div><font style="font-size: 16px;">（2）查询现在需要的executor数是动态的，这就可以得到更高的并发性</font></div><div><font style="font-size: 16px;">（3）数据pipeline。在两个stage之间，实时的把数据从一个executor传递到另外一个（独立的查询依然是MPP的流程，而不是批处理的流程），所以不需要把中间结果写磁盘</font></div><div><font style="font-size: 16px;">（4）MPP类似，我们仍然可以尽可能的在本地存储的数据上执行查询任务。每个executor尝试在存储自己需要处理数据百分比最高的节点上执行</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">8. MR 为了保证容错性，会对中间结果进行落盘并且要在落盘之后才能被下一个 task 读取，而序列化会带来高延迟。spark 发源之初是为了 改进 MR对迭代计算支持较差而设计的（并不是为了做 SQL查询，而是后来有人把它披上了SQL的外衣），但是仍然没有避免 落盘带来的时间开销。</font></div><div><font style="font-size: 16px;">而 MPP 计算模型 （eg. Greenplum <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(46, 46, 46);"><font face="Helvetica Neue">Impala</font></span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(46, 46, 46); font-family: &quot;Microsoft YaHei&quot;, 宋体, &quot;Myriad Pro&quot;, Lato, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;"> </span>）把整个查询 划分为 一颗 执行计划树，而不是一连串的MapReduce任务；在分发执行计划后，</font></div><div><font style="font-size: 16px;">MPP使用拉取数据的方式获取结果，把结果数据 从 执行计划树的最底层叶节点 向上 传递和汇集，这样 <span style="line-height: 1.45;">减少了落盘的开销。</span></font></div><div><font style="font-size: 16px;">但是它的缺点在于 容错性无法保证，需要从业务的层面来解决。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/B27812C9-405C-4AE3-8A5D-B2FBDEDB2AF7.png" height="576" width="1338"/><br/></font></div><div><font style="font-size: 16px;">MPP下，不需要把中间结果写入磁盘，因为每个executor处理一个task，所以数据可以直接“流入”下一执行阶段进行处理，这就是所谓的pipeline执行，性能非常可观。<span style="font-weight: bold;">MR中，在一个单独的executor中串行的处理不相关的task，就必须把中间结果落盘，以便下一个执行步骤能开始消费本步骤的数据</span>。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-weight: bold;"><font style="font-size: 16px;">9.MR 和 MPP 的 设计思路</font></span></div><div><font style="font-size: 16px;"><br/></font></div><ul><li><div><font style="font-size: 16px;">hadoop ( MR + HDFS )</font></div></li></ul><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">    对于数据管理的理念是粗放型管理，以一个文件系统（HDFS）的模式，让用户根据文件夹的层级，把文件一股脑塞到一个分布式文件系统的大池子里面。而当用这些数据的时候，也是以批处理为主，所以每个机器上的文件基本都要从头到尾扫描一遍，所以也不存在太多的物理模型设计与逻辑模型设计。而数据库的本质在于数据管理，需要对外提供在线访问、增删改查等一系列操作。</font></div><div><font style="font-size: 16px;">     </font></div><div><font style="font-size: 16px;">    如果我们想在一大堆数据里面挑拣出符合某个条件的数据，数据库可以根据分区信息首先落到某个机器里，然后可以根据多维分区甚至落到某个文件上，之后再文件里面的索引数据页上使用树形结构查询，很快就可以定位到记录本身。能够做到这一切的前提是，数据库有一套很完善的数据管理和分布体系，因此查询、操作、更新、插入会非常直观高效。数据库能够做到高效的原因是把这些数据通过相对复杂的层级、分类、索引给管理起来，而Hadoop则通过完全放弃这些限制，获得了极大的自由度，但是丧失了对数据的管控能力。</font></div><div><font style="font-size: 16px;">     </font></div><div><font style="font-size: 16px;">    由于使用  这种粗放型的管理方式，只要简单地增加物理机就可以扩大hadoop的存储空间。而对于数据库来说，任何对于集群的改变都涉及到拓扑结构的变更，也可能会涉及到不同机器之间数据的迁移和 分区的记录进行重新散列 ，因此当集群中机器数量多的时候，依然维护复杂的数据管理模型会造成维护成本大幅度上升。</font></div><div><font style="font-size: 16px;">    </font></div><ul><li><div><font style="font-size: 16px;">MPP</font></div></li></ul><div><font style="font-size: 16px;">    </font></div><div><font style="font-size: 16px;">    mpp内存管理比较精细，他主要的想法是在每个机器上放个数据库。传统数据库的内存管理比较复杂，主要是内外存交互的东西，这样的架构决定了<span style="font-weight: bold;">mpp在小数据量的时候，latency 可以做的比较小，但是在大数据量的时候，Throughput做不上去</span>。MapReduce 的job是没有太多精细的内存管理的，他就是拼了命地scan，完了顶多就是个spill，这样的架构导致Throughput很大，但是latency很高。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-size: 16px; color: black; font-family: 微软雅黑; font-weight: bold;">MPP 对比</span><span style="font-size: 16px; color: black; font-family: 微软雅黑; font-weight: bold;">MapReduce</span></div><ul><ul><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">低延迟：</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">shuffle</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">过程的中间结果无需落盘，直接流入下一阶段的执行器中执行，形成数据</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">pipeline</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">  </span></div></li><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">预聚合：</span><span style="font-size: 16px;" /><span style="font-size: 16px; color: black; font-family: 微软雅黑;">同一份</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">数据使用不同</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">的维度进行</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">组织，加快查询（</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">Apache</span><span style="font-size: 16px;" /><span style="font-size: 16px; color: black; font-family: 微软雅黑;">Kylin</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">：</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">Cube</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">）</span></div></li><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">容错性：查询失败后无法利用中间结果复原，</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">必须</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">重试整个查询</span></div></li><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">吞吐量</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">低</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">：复杂的数据管理模型（索引、</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">SQL</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">执行计划树）</span></div></li><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">可</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">扩展性低：小于</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">100</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">个节点</span></div></li></ul></ul><div><br/></div><div><span style="font-size: 16px;">MR 没有考虑数据之间的依赖关系,作业之间完全独立，中间结果需存入磁盘或通过网络进行节点传输, 无法形成数据pipeline。</span></div><div><br/></div><div><span style="font-size: 16px;">spark在窄依赖中,因为每一个父 分区只能被一个子 分区所使用。因此在窄依赖中每一个父  分区计算完成后可以直接将计算结果传给其对应的子 分区，无需等待其他  分区的计算完成，因此也就无需落盘。在宽依赖关系中,因为一个子 分区需要用到多个父 分区的计算结果，所以必须等待所有的 分区计算完成后才能进行子 RDD 的计算，这被称为 pipeline-breaker。为了容错性，先计算好的分区需要落盘，等待别的 task 来这里取走数据。</span></div><div><br/></div><div><span style="font-size: 16px;">Spark 会根据宽窄依赖关系划分出不同的阶段(stage)，然后再根据 RDD 自身保存的依赖关系形成一个有向无环图(DAG)进行调度。阶段之间为宽依赖。阶段内部的 RDD 全都为窄依赖关系：将具有窄依赖关系的 RDD 分区分配到一个任务中进行管道化操作，任务内部数据无需通过网络传输且任务之间互不干扰。特别是在阶段2中，mapreduce 要把 作业1 的结果落盘，而spark直接骚气的管道操作。</span></div><div><br/></div><div><span style="font-weight: bold; font-size: 16px;">总结 mapreduce ，spark 和 mpp，就是一个 中间计算结果是否落盘的权衡，落盘导致计算慢但是系统的容错好，即任务中间失败了我还可以从落盘的数据恢复任务。MR 是啥操作都落，spark是有shuffle才落，MPP是全在内存 “落盘是什么我不知道”</span></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><span style="font-weight: bold;">10.</span><span style="font-weight: bold;">MPP 和 MR 的结合</span></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">新型MPP 数据库 将逐步与Hadoop生态系统结合混搭使用，用MPP处理PB级别的、高质量的结构化数据，同时为应用提供丰富的SQL和事务支持能力; 用Hadoop实现半结构化、非结构化数据处理。这样可同时满足结构化、半结构化和非结构化数据的处理需求。</font></div><div><font style="font-size: 16px;">但是 impala对批量数据的处理如数据挖掘分析，不如HIVE稳定可靠。而impala天然是继承Hive的元数据，所以完全可以综合两者的优点，同一套数据，多个引擎。<span style="font-weight: bold;">Impala应对秒级的交互查询，Hive应对批量数据的分析</span>。即实现“<span style="font-weight: bold;">一套数据，多个引擎</span>”。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-weight: bold;"><font style="font-size: 16px;">引用</font></span></div><div><font style="font-size: 16px;"><br/></font></div><div><a href="http://blog.jobbole.com/43233/"><font style="font-size: 16px;">http://blog.jobbole.com/43233/</font></a></div><div><a href="https://www.zhihu.com/question/22799482/answer/115844245"><font style="font-size: 16px;">https://www.zhihu.com/question/22799482/answer/115844245</font></a></div><div><a href="https://www.zhihu.com/question/22037987"><font style="font-size: 16px;">https://www.zhihu.com/question/22037987</font></a></div><div><a href="https://www.zhihu.com/question/27589901"><font style="font-size: 16px;">https://www.zhihu.com/question/27589901</font></a></div><div><a href="https://www.zybuluo.com/hadoopMan/note/1005029"><font style="font-size: 16px;">https://www.zybuluo.com/hadoopMan/note/1005029</font></a></div><div><font style="font-size: 16px;"><br/></font></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="分布式数据库系列" scheme="https://xinrihui.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="Spark" scheme="https://xinrihui.github.io/tags/Spark/"/>
    
    <category term="OLAP" scheme="https://xinrihui.github.io/tags/OLAP/"/>
    
    <category term="MPP" scheme="https://xinrihui.github.io/tags/MPP/"/>
    
    <category term="MapReduce" scheme="https://xinrihui.github.io/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>HBase - 事务</title>
    <link href="https://xinrihui.github.io/2022/12/24/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1/"/>
    <id>https://xinrihui.github.io/2022/12/24/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1/</id>
    <published>2022-12-24T15:40:19.000Z</published>
    <updated>2022-12-24T15:41:55.433Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2020-04-13 07:24:44 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="http://hbasefly.com/2017/07/26/transaction-2/"/><meta name="updated" content="2022-02-17 13:42:51 +0000"/><title>HBase 原理4：事务</title></head><body><div><div><br/></div><div><span style="font-size: 12pt;">HBase是BigTable的开源实现，事务模型也与BigTable一脉相承 –</span> <span style="font-size: 12pt; font-weight: bold;">仅支持行级别的事务</span><span style="font-size: 12pt;">。</span></div><div><span style="font-size: 12pt;">虽然Jeff Dean大神在接受采访时公开承认目前在技术领域最后悔的事情就是没有在BigTable中加入</span> <span style="font-size: 12pt; font-weight: bold;">跨行事务模型</span><span style="font-size: 12pt;">，以至于之后很多团队都在BigTable之上重复造各种各样的分布式事务轮子。</span></div><div><span style="font-size: 12pt;">之后Google又发布了一篇介绍分布式事务模型的的paper – Percolator，现在很多团队都参考该论文实现分布式事务，包括TiDB、Omid等</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">1.原子性</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase数据会首先写入WAL，再写入Memstore。写入Memstore异常很容易可以回滚，因此保证写入/更新原子性只需要保证 写入WAL的原子性即可。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase 0.98之前版本需要保证WAL写入的原子性并不容易，这由WAL的结构决定。</span></div><div><span style="font-size: 12pt;">假设一个行级事务更新R行中的3列（c1, c2, c3），来看看之前版本和当前版本的WAL结构：</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">之前版本WAL结构：</span></div></li></ul><div><span style="font-size: 12pt;">&lt;logseq1-for-edit1&gt;:&lt;KeyValue-for-edit-c1&gt;</span></div><div><span style="font-size: 12pt;">&lt;logseq2-for-edit2&gt;:&lt;KeyValue-for-edit-c2&gt;</span></div><div><span style="font-size: 12pt;">&lt;logseq3-for-edit3&gt;:&lt;KeyValue-for-edit-c3&gt;</span></div><div><span style="font-size: 12pt;">每个KV都会形成一个WAL单元，这样一行事务更新多少列就会产生多少个WAL单元。在将这些WAL单元append到日志文件的时候，一旦出现宕机或其他异常，就会出现部分写入成功的情况，原子性更新就无法保证。</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">当前版本WAL结构：</span></div></li></ul><div><span style="font-size: 12pt;">&lt;logseq#-for-entire-txn&gt;:&lt;WALEdit-for-entire-txn&gt;</span></div><div><span style="font-size: 12pt;">&lt;logseq#-for-entire-txn&gt;:&lt;-1, 3, &lt;Keyvalue-for-edit-c1&gt;, &lt;KeyValue-for-edit-c2&gt;, &lt;KeyValue-for-edit-c3&gt;&gt;</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">通过这种结构，每个事务 只会产生一个WAL单元。这样就可以保证WAL写入时候的原子性。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">2.</span><span style="font-size: 12pt; font-weight: bold;">事务隔离性&nbsp;&nbsp;保证&nbsp;&nbsp;一致性</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">2.1 写写并发控制</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">现在假设有 两个 并发写入 请求同时进来，都对</span> <span style="font-size: 12pt;"><span style="font-size: 12pt; color: rgb(255, 0, 0);">同一行数据</span></span><span style="font-size: 12pt; font-weight: bold;">&nbsp;&nbsp;</span><span style="font-size: 12pt;">进行写入。下图所示RowKey为Greg，现在分别更新 列族info 下的 Company列 和 Role列：</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">蓝色的写入请求：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/F3C23DF7-D3E7-4928-9550-8D0556ED3255.png" height="90" width="680"/></span></div><div><span style="font-size: 12pt;">虽然是 一行数据&nbsp;&nbsp; 但是&nbsp;&nbsp;底层存储的&nbsp;&nbsp;为两个 K-V&nbsp;&nbsp;元组：</span></div><div><span style="font-size: 12pt;">( key= greg + info+company , value= Cloudera&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= greg + info+role, value= Engineer )</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">绿色的写入请求：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/D40D1C81-1E1A-41E5-AA81-48F2FCF22855.png" height="78" width="554"/></span></div><div><span style="font-size: 12pt;">( key= greg + info+company , value= Restaurant&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= greg + info+role , value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;)</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">如果没有任何并发控制策略的话，写入数据（先写WAL，再写memstore）可能会出现不同 KV 写入”交叉”现象，如下图所示：</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/BDCD880D-1000-451D-899A-1D13B2A63E33.png" height="313" width="752"/></span></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">两个 并发请求&nbsp;&nbsp;都是操作同一行，这一行对应的 两个&nbsp;&nbsp;K-V&nbsp;&nbsp;元组（ 元组&nbsp;&nbsp;的值 即 value） 是&nbsp;&nbsp;交叉写入的：</span></span></div><div><span style="font-size: 12pt;">(key= greg + info+company , timestamp=1 , value= Cloudera&nbsp;&nbsp; )&nbsp;&nbsp;--&nbsp;&nbsp;蓝色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">( key= greg + info+company , timestamp=2&nbsp;&nbsp; ,value= Restaurant&nbsp;&nbsp; )&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;绿色的写入请求</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">( key= greg + info+role , timestamp=3&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;)&nbsp;&nbsp;&nbsp;&nbsp; --&nbsp;&nbsp;绿色的写入请求 </span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">( key= greg + info+role ,&nbsp;&nbsp;timestamp=4 ,value= Engineer )&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;蓝色的写入请求</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">对于&nbsp;&nbsp;每一个&nbsp;&nbsp;</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">元组&nbsp;&nbsp;的值&nbsp;&nbsp;</span><span style="font-size: 12pt;">都会取&nbsp;&nbsp;时间戳（timestamp） 最大的（标红的）， 用户最终读取到&nbsp;&nbsp;一行 数据&nbsp;&nbsp;中的两个&nbsp;&nbsp;列（元组）会产生不一致，如下：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/503BC97E-7B75-4524-8776-3F1FB3CB93D5.png" height="82" width="640"/></span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;对于 元组 可以 通过&nbsp;&nbsp; 时间戳版本&nbsp;&nbsp; 来 保证 事务，即&nbsp;&nbsp;某个 元组&nbsp;&nbsp;一定能保持一致性；</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">但是上述例子&nbsp;&nbsp;的中的&nbsp;&nbsp;不一致是出现在&nbsp;&nbsp;行上，</span></div><div><span style="font-size: 12pt;">即 一行数据的&nbsp;&nbsp; 各个列（元组）的版本&nbsp;&nbsp;出现了 混乱 ：company&nbsp;&nbsp;列取了&nbsp;&nbsp; 绿色写入请求，而 role 列 取了&nbsp;&nbsp;蓝色写入请求 ）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：如何实现写写并发控制？</span></div><div><span style="font-size: 12pt;">只需要 在写入（或更新）之前先获取</span> <span style="font-size: 12pt; font-weight: bold;">行锁</span><span style="font-size: 12pt;">，如果获取不到，说明已经有其他线程拿了该锁，就需要不断重试等待或者自旋等待，直至其他线程释放该锁。拿到锁之后开始写入数据，写入完成之后释放行锁即可。这种行锁机制是实现写写并发控制最常用的手段，后面可以看到MySQL也是使用 行锁来实现写写并发的。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：如何实现批量写入多行的写写并发？</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase支持批量写入（或批量更新），即一个线程 同时</span> <span style="font-size: 12pt; font-weight: bold;">更新同一个Region&nbsp;&nbsp;中的多行记录</span><span style="font-size: 12pt;">。</span></div><div><span style="font-size: 12pt;">那如何保证当前事务中的批量写入与其他事务中的批量写入的并发控制呢？与&nbsp;&nbsp;关系数据库 类似使用</span> <span style="font-size: 12pt; font-weight: bold;">两阶段锁协议：</span></div><div><span style="font-size: 12pt;">(1) 获取所有待写入（更新）行记录的行锁&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">(2) 开始执行写入（更新）操作</span></div><div><span style="font-size: 12pt;">(3) 写入完成之后再统一释放所有行记录的行锁</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">显然，两阶段锁协议&nbsp;&nbsp;可以避免出现死锁问题。（ 详见 《RDBMS》-> 2.数据库管理系统实现 -> 6.物理层的 并发控制）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">但是 ，</span> <span style="font-size: 12pt; font-weight: bold;">HBase&nbsp;&nbsp;的 两阶段&nbsp;&nbsp;锁协议&nbsp;&nbsp;仅仅保证了&nbsp;&nbsp;同一个 region&nbsp;&nbsp;内的隔离性，即 HBase&nbsp;&nbsp;仅支持&nbsp;&nbsp;同一个&nbsp;&nbsp;Region&nbsp;&nbsp;中的跨行事务</span><span style="font-size: 12pt;">。</span></div><div><span style="font-size: 12pt; font-weight: bold;">如果一个 事务&nbsp;&nbsp; 操作了 多个 region&nbsp;&nbsp;中的行 则&nbsp;&nbsp;还是会出现死锁</span><span style="font-size: 12pt;">。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">2.2 读写并发控制</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">读写之间是不是也需要一定的并发控制呢？如果不加并发控制，会出现什么现象呢？</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/AB4D9E36-BD93-4186-BFA4-0EA92F5EF3E8.png" height="451" width="1191"/></span></div><div><span style="font-size: 12pt;">上图分别是两个事务更新同一行数据，现在假设 第一个写事务（蓝色） 已经更新完成 ， 在第二个&nbsp;&nbsp;写事务（绿色）更新到一半的时候进来一个读请求，如果没有任何并发控制的话，读请求就会读到不一致的数据，Company列为Restaurant，Role列为Engineer</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/C0826838-55D2-4644-B2DA-F925866561A0.png" height="82" width="640"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">(key= greg + info+company , timestamp=1 , value= Cloudera&nbsp;&nbsp; )&nbsp;&nbsp;--&nbsp;&nbsp;蓝色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 70, 53);">( key= greg + info+role ,&nbsp;&nbsp;timestamp=2 ,value= Engineer )</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;蓝色的写入请求</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 70, 53);">( key= greg + info+company , timestamp=3&nbsp;&nbsp; ,value= Restaurant&nbsp;&nbsp; )&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;绿色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">----------------&nbsp;&nbsp;读取 Greg&nbsp;&nbsp;行&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">( key= greg + info+role , timestamp=4&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;)&nbsp;&nbsp;&nbsp;&nbsp; --&nbsp;&nbsp;绿色的写入请求 </span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">M1：</span></div><div><span style="font-size: 12pt;">实现读写并发最简单的方法就是 仿照 写写并发控制 – 加锁（</span><span style="font-size: 12pt; font-weight: bold;">封锁法</span><span style="font-size: 12pt;">&nbsp;&nbsp;详见 《RDBMS》-> 2.数据库管理系统实现 ）。但几乎所有数据库都不会这么做，性能太差，对于读多写少的应用来说必然不可接受。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">如果&nbsp;&nbsp;一个事务要 写某行，肯定不能让&nbsp;&nbsp;其他事务&nbsp;&nbsp;同时来写，所以 必须加上&nbsp;&nbsp;写锁（排他锁 ，X锁），</span></div><div><span style="font-size: 12pt;">若不加 写锁，可能会出现&nbsp;&nbsp;</span> <span style="font-size: 12pt; font-weight: bold;">丢失更新</span><span style="font-size: 12pt;">&nbsp;&nbsp;（</span><span style="font-size: 12pt; font-weight: bold;">Lost update</span><span style="font-size: 12pt;">） （ 详见 《RDBMS》-> 2.数据库管理系统实现 -> 6.物理层的 并发控制 ），这就是&nbsp;&nbsp; 利用&nbsp;&nbsp;封锁法&nbsp;&nbsp;实现&nbsp;&nbsp; 写写并发控制。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">如果&nbsp;&nbsp;读写并发控制 也使用&nbsp;&nbsp;封锁法中的 X锁&nbsp;&nbsp;来 实现 ，即一个事务在写&nbsp;&nbsp;某行的时候 禁止别的事务来读，虽然&nbsp;&nbsp;可以达到&nbsp;&nbsp;最高的隔离级别——可串行化，但是 系统的并发度会下降；</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">另一方面，若一个事务在写&nbsp;&nbsp;某行的时候 ，随意让&nbsp;&nbsp;别的事务来读，那么会&nbsp;&nbsp;导致&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">脏读（dirty read）</span><span style="font-size: 12pt;">&nbsp;&nbsp;、&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">不可重复读（unrepeatable read）</span></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">（ 详见 《RDBMS》-&gt; 2.数据库管理系统实现 -&gt; 6.物理层的 并发控制 ）</span></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">其实，脏读&nbsp;&nbsp;和&nbsp;&nbsp;不可重复读&nbsp;&nbsp;也不是不可以&nbsp;&nbsp;容忍，这取决于&nbsp;&nbsp;应用要求的&nbsp;&nbsp;事务的隔离级别，（详见&nbsp;&nbsp; 《分布式&nbsp;&nbsp;存储和数据库》->&nbsp;&nbsp;分布式事务处理 ）</span></div><div><span style="font-size: 12pt;">若 隔离&nbsp;&nbsp;级别为&nbsp;&nbsp; 读未提交（Read Uncommitted），则&nbsp;&nbsp;可能出现&nbsp;&nbsp; 脏读；</span></div><div><span style="font-size: 12pt;">若&nbsp;&nbsp;隔离&nbsp;&nbsp;级别为&nbsp;&nbsp;读已提交（Read Committed），则不会出现脏读，但是&nbsp;&nbsp;会出现 不可重复读；</span></div><div><span style="font-size: 12pt;">若&nbsp;&nbsp;隔离&nbsp;&nbsp;级别为&nbsp;&nbsp;&nbsp;&nbsp;可重复读 （Repeatable Read&nbsp;&nbsp;），则不会&nbsp;&nbsp;出现&nbsp;&nbsp;脏读、不可重复读&nbsp;&nbsp;但是&nbsp;&nbsp;会出现&nbsp;&nbsp;幻读；</span></div><div><span style="font-size: 12pt;">若&nbsp;&nbsp;隔离&nbsp;&nbsp;级别为&nbsp;&nbsp;可串性化 （Serializable），则&nbsp;&nbsp;不会&nbsp;&nbsp;出现&nbsp;&nbsp;脏读、不可重复读 、&nbsp;&nbsp;幻读；</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">数据库&nbsp;&nbsp;一般不会选择&nbsp;&nbsp;可串行化，MySql默认的隔离级别为 Repeatable Read ，Oracle默认的隔离级别为 Read Committed</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">因此，读写的并发&nbsp;&nbsp;控制&nbsp;&nbsp;可以采用&nbsp;&nbsp;下面的 MVCC&nbsp;&nbsp;方法&nbsp;&nbsp;</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">M2：</span><span style="font-size: 12pt; font-weight: bold;">MVCC</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase中 MVCC 机制实现主要分为两步：</span></div><ul><li><div><span style="font-size: 12pt;">在事务开始时，为每一个写（更新）事务 分配一个</span> <span style="font-size: 12pt; color: rgb(255, 0, 0);">Region级别</span> <span style="font-size: 12pt;">自增 的序列号</span></div></li><li><div><span style="font-size: 12pt;">为每一个读请求分配一个 已完成（已提交）的最大写事务序列号</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/5C08BC98-3C49-4C6E-818A-815C9094CAFF.png" height="571" width="1484"/></span></div><div><span style="font-size: 12pt;">上图中两个 写事务分别分配了 序列号1（wn=1）和 序列号2（wn=2），读请求进来的时候 事务1 已经完成（已经提交），事务2 还未完成，因此分配事务1 对应的序列号1给读请求。此时 序列号1对 本次读可见，序列号2 对本次读不可见，读到的数据是：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/F3C23DF7-D3E7-4928-9550-8D0556ED3255.png" height="90" width="680"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">(key= greg + info+company , timestamp=1 , value= Cloudera , wn=1&nbsp;&nbsp; )</span><span style="font-size: 12pt; color: rgb(255, 70, 53);">&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;蓝色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">( key= greg + info+role ,&nbsp;&nbsp;timestamp=1.5 ,value= Engineer ,&nbsp;&nbsp; wn=1 )&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;蓝色的写入请求</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">wn&nbsp;&nbsp;list（commit list） : [ 1,&nbsp;&nbsp; ]</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">( key= greg + info+company , timestamp=2&nbsp;&nbsp; ,value= Restaurant , wn=2&nbsp;&nbsp; )&nbsp;&nbsp;--&nbsp;&nbsp;绿色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">----------------&nbsp;&nbsp;读取 Greg&nbsp;&nbsp;行&nbsp;&nbsp; ( row=</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">greg ,&nbsp;&nbsp;</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(255, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">wn=max(&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">wn_list&nbsp;&nbsp;</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(255, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">)=1</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= greg + info+role , timestamp=3&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=2&nbsp;&nbsp;)&nbsp;&nbsp;&nbsp;&nbsp; --&nbsp;&nbsp;绿色的写入请求 </span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">wn&nbsp;&nbsp;list（commit list） : [ 1, 2 ]</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">由此可见，</span><span style="font-size: 12pt; font-weight: bold;">MVCC&nbsp;&nbsp;的隔离级别&nbsp;&nbsp;至少为：</span> <span style="font-size: 12pt; font-weight: bold;">读已提交</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">具体实现中，</span><span style="font-size: 12pt; font-weight: bold;">所有的写事务都会生成一个 Region级别 的自增序列</span><span style="font-size: 12pt;">，并添加到队列（每一个 region&nbsp;&nbsp;有一个）中，如下图最左侧队列，其中最底端为已经提交的事务，队列中的事务为未提交事务。现假设当前事务编号为15，并且写入完成（中间队列红色框框），但之前的写入事务还未完成（序列号为12、13、14的事务还未完成），此时当前事务必须等待，而且对读并不可见，直至之前所有事务完成之后才会对读可见（ 即读请求才能读取到该事务写入的数据 ）。如最右侧图，15号事务之前的所有事务都成功完成，此时Read Point就会移动到15号事务处，表示15号事务之前的所有改动都可见。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/0B277B7C-EE1B-43DD-ACC4-91705871EF00.png" height="412" width="1067"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">所以，MVCC的精髓是&nbsp;&nbsp;</span> <span style="font-size: 12pt;">写入的时候分配 递增版本号（Sequence Id）（该版本信息取的是&nbsp;&nbsp; 事务开始时的时间戳），读取的时候分配&nbsp;&nbsp; 一个&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">连续已完成最大</span> <span style="font-size: 12pt;">的版本 用于读取 可见，比之大的版本不可见</span><span style="font-size: 12pt;">。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">由此可见 ， 采用 MVCC 隔离级别&nbsp;&nbsp;至少可以达到：</span><span style="font-size: 12pt; font-weight: bold;">可重复读</span><span style="font-size: 12pt;">。</span></div><div><span style="font-size: 12pt;">例如， A事务 读取的时候&nbsp;&nbsp;被分配了&nbsp;&nbsp;版本 wn=3，在A事务的&nbsp;&nbsp;生命期内&nbsp;&nbsp;无论它 读 多少次，一定只能 拿到&nbsp;&nbsp; 版本 wn=3 的数据；即使在&nbsp;&nbsp; A事务的&nbsp;&nbsp;生命期内，&nbsp;&nbsp; B事务&nbsp;&nbsp;更新了数据&nbsp;&nbsp;并提交成功，数据的最大版本变为 wn=4。</span><span style="font-size: 12pt; color: unset; font-family: unset;">因此，不会出现&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">不可重复读</span><span style="font-size: 12pt; color: unset; font-family: unset;">&nbsp;&nbsp;的现象。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase一个标准写事务的流程如下：</span></div><ul><li><div><span style="font-size: 12pt; color: unset; font-family: unset;">锁行，拒绝对相同行的并发写</span></div></li><li><div><span style="font-size: 12pt;">获取当前的写入号</span></div></li><li><div><span style="font-size: 12pt;">将修改写入“写前日志”WAL(Write Ahead Log)</span></div></li><li><div><span style="font-size: 12pt;">将修改写入Memstore，同时用获取到的写入号标记KeyValue对</span></div></li><li><div><span style="font-size: 12pt;">提交事务，即尝试将读取点滚到获取到的写入号(这样变更就可以对所有新的Scan可见)</span></div></li><li><div><span style="font-size: 12pt;">打开行锁</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">HBase</span><span style="font-size: 12pt;">一个标准读事务的流程如下：</span></div><ul><li><div><span style="font-size: 12pt;">打开Scanner</span></div></li><li><div><span style="font-size: 12pt;">获取当前读取点</span></div></li><li><div><span style="font-size: 12pt;">筛选出所有memstore时间戳大于读取点的KeyValue对</span></div></li><li><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关闭Scanner</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><hr/><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：为什么&nbsp;&nbsp;读取的时候&nbsp;&nbsp;必须&nbsp;&nbsp;分配一个&nbsp;&nbsp;连续已完成最大 的版本（wn）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">1.保证了&nbsp;&nbsp;一个 Region&nbsp;&nbsp;内的&nbsp;&nbsp;单行事务：</span></div><div><br/></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">eg1.</span></span></div><div><span style="font-size: 12pt;">在同一个&nbsp;&nbsp;Region&nbsp;&nbsp;中：</span></div><ul><li><div><span style="font-size: 12pt;">t= 5 发起 写事务&nbsp;&nbsp;插入 TID=5 （</span><span style="font-size: 12pt; font-weight: bold;">TID&nbsp;&nbsp;取 事务开始时的时间戳</span><span style="font-size: 12pt;">） ：</span></div></li></ul><div><span style="font-size: 12pt;">( key= abby+ info+company , timestamp=5&nbsp;&nbsp; ,value= Restaurant , wn=5&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key=abby+ info+role , timestamp=</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">5.5</span><span style="font-size: 12pt;">&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=5 )&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">t= 7&nbsp;&nbsp;发起&nbsp;&nbsp;写事务&nbsp;&nbsp;插入&nbsp;&nbsp; TID=7：</span></div></li></ul><div><span style="font-size: 12pt;">( key= keven + info+company , timestamp=7&nbsp;&nbsp; ,value= Restaurant , wn=7&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= keven+ info+role , timestamp=</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">11</span><span style="font-size: 12pt;">&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=7 )&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><br/></div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">t= 8&nbsp;&nbsp;</span><span style="font-size: 12pt;">发起 写事务</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">&nbsp;&nbsp;插入 TID=8：</span></div></li></ul><div><span style="font-size: 12pt;">( key= greg + info+company , timestamp=8&nbsp;&nbsp; ,value= Restaurant , wn=8&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= greg + info+role , &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;timestamp= </span><span style="font-size: 12pt; color: rgb(255, 0, 0);">9</span><span style="font-size: 12pt;">&nbsp;&nbsp; , value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wn=8 )&nbsp;&nbsp; </span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">t=10&nbsp;&nbsp; 发起&nbsp;&nbsp;读事务 Read1 ，读取整个 region（分区） ，</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">此时， 已完成的&nbsp;&nbsp;最大版本号为 8 即</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">TID=8 已经提交</span><span style="font-size: 12pt;">，但是，</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">TID=7 还未提交，所以</span><span style="font-size: 12pt;">&nbsp;&nbsp;连续已完成的&nbsp;&nbsp;最大的版本号为 5&nbsp;&nbsp; ；</span></div><div><span style="font-size: 12pt;">因此 读事务Read1 能看&nbsp;&nbsp;版本&nbsp;&nbsp;小于等于 wn=5 的&nbsp;&nbsp;分区的数据，即&nbsp;&nbsp; keven&nbsp;&nbsp;和&nbsp;&nbsp;greg&nbsp;&nbsp;行 都看不到，即使&nbsp;&nbsp;Read1&nbsp;&nbsp; 在 t=12&nbsp;&nbsp;又读了一次数据。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; font-weight: bold;">----------------------------------------------------------------------</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">假设&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">读取的时候分配 一个&nbsp;&nbsp; 已完成&nbsp;&nbsp; 最大的版本 用于读取 可见</span><span style="font-size: 12pt; color: unset; font-family: unset;">，而不要求&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">连续已完成&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">&nbsp;&nbsp;，则&nbsp;&nbsp;可能出现&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">幻读</span><span style="font-size: 12pt; color: unset; font-family: unset;">：</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">t=10&nbsp;&nbsp; 发起&nbsp;&nbsp;读事务 Read1 ，读取整个 region，</span></div></li></ul><div><span style="font-size: 12pt;">此时， 已完成的&nbsp;&nbsp;最大版本号为 8 即</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">TID=8 已经提交</span><span style="font-size: 12pt;">，</span></div><div><span style="font-size: 12pt;">读事务Read1 能看&nbsp;&nbsp;版本&nbsp;&nbsp;小于等于 wn=8 的&nbsp;&nbsp;分区的数据，但是不能看未提交的，因此：</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">当 t=10&nbsp;&nbsp; Read1&nbsp;&nbsp; 能看到&nbsp;&nbsp;abby&nbsp;&nbsp;greg&nbsp;&nbsp;行，看不到&nbsp;&nbsp;keven&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">当 t=12&nbsp;&nbsp;&nbsp;&nbsp;TID=7 已经提交，Read1&nbsp;&nbsp; 能看到&nbsp;&nbsp;&nbsp;&nbsp;abby&nbsp;&nbsp;greg&nbsp;&nbsp;keven&nbsp;&nbsp;行，此时出现了&nbsp;&nbsp;在一个事务中 ，看到了&nbsp;&nbsp;前一次读取 看不到的行：keven ，即</span> <span style="font-size: 12pt; font-weight: bold;">幻读</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; font-weight: bold;">----------------------------------------------------------------------</span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">t=12&nbsp;&nbsp;发起&nbsp;&nbsp;读事务 Read2 ，读取整个 region，</span></div></li></ul><div><span style="font-size: 12pt;">此时，连续已完成的&nbsp;&nbsp;最大的版本号为 8 ，因此 读事务Read2&nbsp;&nbsp;能看&nbsp;&nbsp;版本&nbsp;&nbsp;小于等于 wn=8 的&nbsp;&nbsp;分区的数据，abby&nbsp;&nbsp;greg&nbsp;&nbsp;keven&nbsp;&nbsp;行&nbsp;&nbsp;均可见</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">2.事务写入的时候分配&nbsp;&nbsp;的 递增版本号 取的是&nbsp;&nbsp;事务提交后的时间戳，则 “读取的时候分配一个已完成最大的版本用于读取可见”&nbsp;&nbsp;也可以实现 跨行的事务</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">eg1.</span></span></div><div><span style="font-size: 12pt;">在同一个&nbsp;&nbsp;Region&nbsp;&nbsp;中：</span></div><ul><li><div><span style="font-size: 12pt;">t= 5 发起 写事务&nbsp;&nbsp;&nbsp;&nbsp;：</span></div></li></ul><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">abby</span><span style="font-size: 12pt;">+ info+company , timestamp=5&nbsp;&nbsp; ,value= Restaurant , wn=5.5)</span></div><div><span style="font-size: 12pt;">( key=</span><span style="font-size: 12pt; font-weight: bold;">abby</span><span style="font-size: 12pt;">+ info+role , timestamp=5.5&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=5.5)&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">插入 TID=5.5 （</span><span style="font-size: 12pt; font-weight: bold;">TID&nbsp;&nbsp;取 事务&nbsp;&nbsp;提交的时间戳</span><span style="font-size: 12pt;">）</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">t= 7&nbsp;&nbsp;发起&nbsp;&nbsp;写事务 ：</span></div></li></ul><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">keven</span> <span style="font-size: 12pt;">+ info+company , timestamp=7&nbsp;&nbsp; ,value= Restaurant , wn=11)</span></div><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">keven</span><span style="font-size: 12pt;">+ info+role , timestamp=11&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=11)&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">插入&nbsp;&nbsp; TID=11</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">t= 8&nbsp;&nbsp;</span><span style="font-size: 12pt;">发起 写事务</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">&nbsp;&nbsp;：</span></div></li></ul><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">greg</span> <span style="font-size: 12pt;">+ info+company , timestamp=8&nbsp;&nbsp; ,value= Restaurant , wn=9)</span></div><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">greg</span> <span style="font-size: 12pt;">+ info+role , &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;timestamp=9&nbsp;&nbsp; , value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wn=9)&nbsp;&nbsp; </span></div><div><span style="font-size: 12pt;">插入&nbsp;&nbsp; TID=9</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">t=10&nbsp;&nbsp; 发起&nbsp;&nbsp;读事务 Read1 ，读取整个 region（分区） ，</span></div></li></ul><div><span style="font-size: 12pt;">此时， 已完成（已提交）的&nbsp;&nbsp;最大版本号为 9 即</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">TID=9 已经提交</span><span style="font-size: 12pt;">，</span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">因此 读事务Read1 能看&nbsp;&nbsp;版本&nbsp;&nbsp;小于等于 wn=9 的&nbsp;&nbsp;分区的数据，即&nbsp;&nbsp;能看到&nbsp;&nbsp;abby&nbsp;&nbsp;&nbsp;&nbsp;greg&nbsp;&nbsp;行，而&nbsp;&nbsp; keven 行 看不到，即使&nbsp;&nbsp;Read1 ， 在 t=12&nbsp;&nbsp;Read1又读了一次数据，结果仍然如此。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><hr/><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">这里需要注意版本必须递增，而且&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">唯一</span><span style="font-size: 12pt; font-weight: bold;">递增版本号 的&nbsp;&nbsp;作用范围一定程度上决定了 事务是什么级别的事务</span><span style="font-size: 12pt;">，比如HBase是 Region级别的 递增版本号，那么 事务就是region级别事务。MySQL中版本是单机递增版本，那么MySQL事务就支持单机跨行事务。Percolator中版本是集群递增版本，那么Percolator事务就是分布式事务。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">因此，在分布式数据库中，</span><span style="font-size: 12pt;">一个&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">统一高可用的发号器</span><span style="font-size: 12pt;">&nbsp;&nbsp;来做 版本号的递增&nbsp;&nbsp;是实现&nbsp;&nbsp;分布式事务的关键</span><span style="font-size: 12pt;">。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：</span> <span style="font-size: 12pt;"><span style="font-size: 12pt; color: rgb(255, 0, 0);">Spanner</span>&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">如何&nbsp;&nbsp;实现&nbsp;&nbsp;跨机房的&nbsp;&nbsp;唯一递增版本号？</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">在google&nbsp;&nbsp;的&nbsp;&nbsp;Spanner&nbsp;&nbsp;中，</span><span style="font-size: 12pt; color: unset; font-family: unset;">存在两个 level&nbsp;&nbsp;的&nbsp;&nbsp;发号器：</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">在每个机房都 有一个&nbsp;&nbsp;中心发号器，该机房的节点&nbsp;&nbsp;处理的事务&nbsp;&nbsp;请求都要&nbsp;&nbsp;来这里&nbsp;&nbsp;拿一个 唯一的递增版本号。这个中心发号器&nbsp;&nbsp;自身&nbsp;&nbsp;也可以做成 分布式的，并采用分布一致性算法&nbsp;&nbsp;保证&nbsp;&nbsp;版本号唯一且递增（&nbsp;&nbsp;例如&nbsp;&nbsp; zookeeper&nbsp;&nbsp;的&nbsp;&nbsp;临时递增节点 ）</span></div></li></ul><div><span style="font-size: 12pt;">&nbsp;&nbsp;</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">分布在全球各个&nbsp;&nbsp;机房 中的集群 都有 一个 原子钟，在初始化 校准后 ，所有机房的原子钟 都是同步的（误差很小&nbsp;&nbsp;且能&nbsp;&nbsp;确定误差的范围）。</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">因此Spanner&nbsp;&nbsp;可以&nbsp;&nbsp;实现&nbsp;&nbsp; 全球所有&nbsp;&nbsp;机房中的&nbsp;&nbsp;所有节点的&nbsp;&nbsp;&nbsp;&nbsp;版本的递增，也就实现了&nbsp;&nbsp;全球 的 分布式事务，&nbsp;&nbsp;全球的所有节点可以 作为&nbsp;&nbsp;一个&nbsp;&nbsp;统一的分布式数据库 使用。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">在&nbsp;&nbsp;OceanBase 中，有 3个节点 组成的NTP 服务 来做 发号器，由NTP服务保证 3个节点的时钟同步，因为 时钟的精度可以达到 ns ，即 1 s 可以发 10^9 个号，足以满足 高并发事务的要求；若 有1台 服务器宕机，NTP 服务 会将时钟 整体向后漂移 一段时间，保证 发放的 版本号 一定随时间递增，不会出现时光倒流。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：</span><span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">OceanBase</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">为何&nbsp;&nbsp;只有&nbsp;&nbsp;可串行化&nbsp;&nbsp;和&nbsp;&nbsp;读已提交&nbsp;&nbsp;两种隔离级别？（</span><span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">对比&nbsp;&nbsp;&nbsp;&nbsp;OceanBase 和 DB2&nbsp;&nbsp;&nbsp;&nbsp;中 事务的隔离级别</span><span style="font-size: 12pt; color: rgb(255, 0, 0); font-family: unset;">）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">1.OB&nbsp;&nbsp;采用 MVCC&nbsp;&nbsp;的方法：</span></div><ul><li><div><span style="font-size: 12pt;">对于&nbsp;&nbsp;写事务，在事务 提交 之后 发一个&nbsp;&nbsp;时间戳作为&nbsp;&nbsp; 发生更新数据的版本号</span></div></li><li><div><span style="font-size: 12pt;">对于读事务，</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果隔离&nbsp;&nbsp;级别设定为&nbsp;&nbsp;可串行化，那么&nbsp;&nbsp;在整个读事务&nbsp;&nbsp;的周期中，所有的读取 都使用&nbsp;&nbsp;第一次读取&nbsp;&nbsp;拿到的版本号，即读取 只能读到&nbsp;&nbsp;更新时间 <=&nbsp;&nbsp;版本号&nbsp;&nbsp;的行 ，这样&nbsp;&nbsp;可以避免&nbsp;&nbsp;幻读（幻读一定是在我读事务的周期里更新了数据，并且更新的这一行数据有一个更大的版本号）； </span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp; 如果&nbsp;&nbsp;隔离&nbsp;&nbsp;&nbsp;&nbsp;级别设定为&nbsp;&nbsp; 读已提交，那么&nbsp;&nbsp;在整个读事务&nbsp;&nbsp;的周期中，每一次&nbsp;&nbsp;读取&nbsp;&nbsp;都拿一个&nbsp;&nbsp;新的版本号，这样就会出现&nbsp;&nbsp;每次读取&nbsp;&nbsp;所能看到的 数据版本&nbsp;&nbsp;可能不一样（不可重复读现象） </span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">2.OB&nbsp;&nbsp;的&nbsp;&nbsp;更新策略 采用&nbsp;&nbsp; “在commit&nbsp;&nbsp;开始之后&nbsp;&nbsp;才把&nbsp;&nbsp;更新写入数据库”，即&nbsp;&nbsp;遵从&nbsp;&nbsp;commit rule&nbsp;&nbsp;在提交之前&nbsp;&nbsp;先将&nbsp;&nbsp;新的值写入log&nbsp;&nbsp;中，恢复的&nbsp;&nbsp;时候&nbsp;&nbsp;使用&nbsp;&nbsp;日志中的&nbsp;&nbsp;新值&nbsp;&nbsp;去redo</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">3. OB&nbsp;&nbsp;采用&nbsp;&nbsp;主从结构，从节点&nbsp;&nbsp;中存着&nbsp;&nbsp;主节点&nbsp;&nbsp;数据的副本，为了保持&nbsp;&nbsp;一致性，读和写&nbsp;&nbsp;都请求的是主节点。</span></div><ul><li><div><span style="font-size: 12pt;">如果&nbsp;&nbsp;新数据 在主节点&nbsp;&nbsp;成功写入，那么&nbsp;&nbsp; 将 同步复制（主节点&nbsp;&nbsp;要收到&nbsp;&nbsp;从节点&nbsp;&nbsp;的写入&nbsp;&nbsp;成功的 ACK ） 到 n&nbsp;&nbsp;个&nbsp;&nbsp;从节点中（n+1 >= N/2&nbsp;&nbsp; ，N为&nbsp;&nbsp;总的副本数）</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">4.读写&nbsp;&nbsp;都是主节点&nbsp;&nbsp;导致&nbsp;&nbsp;主节点&nbsp;&nbsp;压力过大，OB&nbsp;&nbsp;采用了&nbsp;&nbsp;互为主备的方法：</span></div><div><div><font style="font-size: 12pt;"><br/></font></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">节点1</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">节点2&nbsp;&nbsp;</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">节点3</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">A库&nbsp;&nbsp;主</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">A库&nbsp;&nbsp;副本1</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">A库&nbsp;&nbsp;副本2</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">B库&nbsp;&nbsp;副本1</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">B库&nbsp;&nbsp;主</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">B库&nbsp;&nbsp;副本2</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">C库&nbsp;&nbsp;副本1</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">C库&nbsp;&nbsp;副本2</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">C库&nbsp;&nbsp;主</span></div></td></tr></tbody></table><div><span style="font-size: 12pt;">问题来了，请求 A&nbsp;&nbsp;库中的数据，我怎么知道 A库的主节点是哪个：每个节点 都有一张路由表，记录&nbsp;&nbsp;哪个库的&nbsp;&nbsp;主节点是谁，如果来了请求，发现&nbsp;&nbsp;主节点不是我，我把请求路由走</span></div></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：DB2&nbsp;&nbsp; 如何&nbsp;&nbsp;做到&nbsp;&nbsp; 4&nbsp;&nbsp;种隔离级别&nbsp;&nbsp;都支持</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">1.采用&nbsp;&nbsp;锁机制，但是它的锁很复杂：有写锁，还有读锁；</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">对于读锁，有 范围读锁，比如&nbsp;&nbsp;一个读事务：select *from A where date > 2020-06-01&nbsp;&nbsp;那么&nbsp;&nbsp;读锁会把&nbsp;&nbsp;表中&nbsp;&nbsp;满足 date > 2020-06-01&nbsp;&nbsp;行 全部锁起来&nbsp;&nbsp;不让别人写，这样就不会出现&nbsp;&nbsp;读取到一半&nbsp;&nbsp;内容被人修改的情况。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">3.</span><span style="font-size: 12pt; font-weight: bold;">事务持久性&nbsp;&nbsp;</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase事务持久化可以理解为WAL持久化，目前实现了多种持久化策略：SKIP_WAL，ASYNC_WAL，SYNC_WAL，FSYNC_WAL。</span></div><ul><li><div><span style="font-size: 12pt;">SKIP_WAL 表示不写WAL，这样写入更新性能最好，但在RegionServer宕机的时候有可能会丢失部分数据；</span></div></li><li><div><span style="font-size: 12pt;">ASYNC_WAL 表示异步将WAL持久化到硬盘，因为是异步操作所以在异常的情况下也有可能丢失少量数据；</span></div></li><li><div><span style="font-size: 12pt;">SYNC_WAL 表示同步将WAL持久化到操作系统缓存，再由操作系统将数据异步持久化到磁盘，这种场景下RS宕掉并不会丢失数据，当操作系统宕掉会导致部分数据丢失；</span></div></li><li><div><span style="font-size: 12pt;">FSYNC_WAL 表示WAL写入之后立马落盘，性能相对最差。</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">用户可以根据业务对数据丢失的敏感性在客户端配置相应的持久化策略。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><a href="http://hbasefly.com/2017/07/26/transaction-2/" style="font-size: 12pt;">http://hbasefly.com/2017/07/26/transaction-2/</a></div><div><a href="http://hbasefly.com/2017/08/19/mysql-transaction/" style="font-size: 12pt;">http://hbasefly.com/2017/08/19/mysql-transaction/</a></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="分布式数据库系列" scheme="https://xinrihui.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="HBase" scheme="https://xinrihui.github.io/tags/HBase/"/>
    
    <category term="事务" scheme="https://xinrihui.github.io/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Spark - RDD 算子</title>
    <link href="https://xinrihui.github.io/2022/12/24/2.RDD%20%E7%AE%97%E5%AD%90/"/>
    <id>https://xinrihui.github.io/2022/12/24/2.RDD%20%E7%AE%97%E5%AD%90/</id>
    <published>2022-12-24T15:30:51.000Z</published>
    <updated>2022-12-24T15:31:14.541Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-12-07 04:27:35 +0000"/><meta name="source" content="yinxiang.superNote"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="https://blog.csdn.net/CYJ2014go/article/details/83014075"/><meta name="updated" content="2022-12-24 15:29:03 +0000"/><meta name="content-class" content="yinxiang.superNote"/><title>2.RDD 算子</title></head><body><h1><span style="font-family: unset;"><span style="color: unset;">读写文件</span></span></h1><div><br/></div><div><span style="font-size: 12pt;">spark默认读取 HDFS中的文件（<span style="font-weight: bold;">hdfs://Master:9000</span>/tmp/hive1）</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">sc.textFile("hdfs://Master:9000/tmp/people") // idea IDE默认在file:///里找。最好指明文件路径 是在 HDFS 还是在本地 </div><div><br/></div><div><span style="font-size: 12pt;">读取本地文件:</span></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">val rdd=sc.textFile("file:////app/hadoop/spark110/NOTICE")   //必须在所有datanode中都有，而且都为此路径</div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">windows 下的 本地文件 路径必须使用 '\\' 隔开</span></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">data_dir = 'data\\' #   当前文件夹下有 data目录tmp_index_file_dir = data_dir + 'tmp_index_spark.bin'  lines = sc.textFile(tmp_index_file_dir,8)</div><div><br/></div><div><span style="font-size: 12pt;"><span style="color: rgb(255, 0, 0);">问题： 如何控制 输出的文件 只有一个切片</span></span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">lines = sc.textFile(tmp_index_file_dir,8) # 对大文件 进行切片 sliceNum=8，否则报错# 20/05/30 11:54:28 ERROR PythonRunner: This may have been caused by a prior exception:java.net.SocketException: Connection reset by peer: socket write errorlines=lines.map(lambda line:line.split("\t"))lines=lines.sortBy(lambda x: x[0])lines=lines.map(lambda line: line[0]+"\t"+line[1])# lines.saveAsTextFile(sorted_tmp_index_file_dir) # 在文件夹下 保存 sliceNum 个切片文件lines.coalesce(1, shuffle=True).saveAsTextFile(sorted_tmp_index_file_dir) # 在文件夹下 只有一个 切片</div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="https://stackoverflow.com/questions/24371259/how-to-make-saveastextfile-not-split-output-into-multiple-file" rev="en_rl_none"><span style="font-size: 12pt;">https://stackoverflow.com/questions/24371259/how-to-make-saveastextfile-not-split-output-into-multiple-file</span></a></div><div><br/></div><div><br/></div><h1>遍历 </h1><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">lines = sc.textFile(tmp_index_file_dir,8)  # 对大文件 要进行切片 sliceNum=8，否则报错print(lines.first())  # 显示 第1条print(lines.take(10)) # 可以看 指定数目的记录for line in lines: #TypeError: 'RDD' object is not iterable     print(line)for line in lines.collect() : # lazy 原则， 遇到 action 才真正 执行DAG 计算图；collect() 将数据从各个计算节点 拉回到主节点     print(line)</div><div><br/></div><div><br/></div><h1>重分区 </h1><div><br/></div><h2>coalesce() 和 repartition()</h2><div><br/></div><div><span style="font-size: 12pt;"><span style="color: rgb(255, 0, 0);">问题：分区太多了怎么办</span></span></div><div><br/></div><div><span style="font-size: 12pt;">在用户使用Spark的过程中，常常会使用filter算子进行数据过滤。 而频繁的过滤或者过<span style="font-family: unset;"><span style="color: unset;">滤掉的数据量过大就会产生问题，造成大量小分区的产生（每个分区数据量小）。</span></span></span></div><div><span style="font-size: 12pt;"><span style="font-family: unset;"><span style="color: unset;">例如：</span></span></span></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">val rdd2 = rdd1.filter(line=&gt;lines.contains("error")).filter(line=&gt;line.contains("info")).collect()</div><div><br/></div><div><span style="font-size: 12pt;">Spark会对每一个分区分配一个task 来执行 RDD 的计算，如果task过多，那么每个task处理的数据量很小，就会造成线程频繁的在task之间切换，使得资源开销较大，且很多任务等待执行，并行度不高，这会造成集群工作效益低下。</span></div><div><br/></div><div><span style="font-size: 12pt;">采用 重分区的函数 来进行数据紧缩，减少分区数量，将小分区合并为大分区，从而提高效率</span></div><div><br/></div><div><span style="font-size: 12pt;">coalesce() 方法的 参数 shuffle默认 为false，</span></div><div><span style="font-size: 12pt;">repartition() 等价于 coalesce(shuffle=True)</span></div><div><br/></div><div><span style="font-size: 12pt;">假设RDD有 N个分区，需要重新划分成M个分区：（N -&gt; M）</span></div><ul><li><div><span style="font-size: 12pt;">N &lt; M: 一般情况下N个分区有数据分布不均匀的状况，利用HashPartitioner函数将数据重新分区为M个，这时需要将shuffle设置为true。因为重分区前后相当于宽依赖，会发生shuffle过程，此时可以使用 coalesce(shuffle=true)，或者直接使用repartition()。</span></div></li></ul><div><br/></div><ul><li><div><span style="font-size: 12pt;">如果N &gt; M 并且 N和M相差不多(假如N是1000，M是100): 那么就可以将N个分区中的若干个分区合并成一个新的分区，最终合并为M个分区，这是前后是窄依赖关系，可以使用coalesce(shuffle=false)。</span></div></li></ul><div><br/></div><ul><li><div><span style="font-size: 12pt;">如果 N &gt;&gt; M并且两者相差悬殊: 这时如果将shuffle设置为false，父子 RDD 是窄依赖关系，他们同处在一个stage中，就可能造成spark程序的并行度不够，从而影响性能。即当前的每个分区数据量过大，需要将分区数量增加，以利用并行计算能力，这就需要把Shuffle设置为true</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="https://blog.csdn.net/lzq20115395/article/details/80602071" rev="en_rl_none"><span style="font-size: 12pt;">https://blog.csdn.net/lzq20115395/article/details/80602071</span></a></div><div><a href="http://lxw1234.com/archives/2015/07/341.htm" rev="en_rl_none"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/07/341.htm</span></a></div><div><br/></div><h2>分组 partitionBy</h2><div><br/></div><div><span style="font-size: 12pt;">repartition和partitionBy都是重新分区的算子，其中partitionBy只能作用于PairRDD. 但是，当作用于PairRDD时，repartition和partitionBy的行为是不同的。</span></div><div><br/></div><div><span style="font-size: 12pt;">repartition是把 <span style="color: #FF0000;">数据随机打散均匀分布于各个Partition，即随机数分区（不是根据 key 算出 hashcode 的 hash 分区）</span>；</span></div><div><br/></div><div><span style="font-size: 12pt;">partitionBy则在参数中指定了Partitioner（默认HashPartitioner），将每个(K,V)对按照K根据Partitioner计算得到对应的Partition。</span></div><div><span style="font-size: 12pt;">在合适的时候使用partitionBy可以减少shuffle次数，提高效率。</span></div><p><br/></p><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:570px;" width="570px"><colgroup><col style="width: 190px;"/><col style="width: 190px;"/><col style="width: 190px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>优点</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>缺点</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">repartition</span></div><div><span style="font-size: 12pt;">（随机分区）</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>使每个分区里数据尽量均匀</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>相同key的记录可能重分区到不同的分区</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">partitionBy</span></div><div><span style="font-size: 12pt;">（默认哈希分区）</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>相同key的记录会重分区到同一个分区</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>有数据倾斜的情况会导致每个分区数据量不均匀</div></td></tr></tbody></table><p><br/></p><div><br/></div><div><span style="font-size: 12pt;">我们可以自己设计合理的分区方法( 比如数量比较大的key 加个随机数 随机分到更多的分区， 这样处理数据倾斜更彻底一些)</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">def partitionBy(partitioner: Partitioner)                abstract class Partitioner extends Serializable {  def numPartitions: Int  def getPartition(key: Any): Int}</div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//查看rdd1中每个分区的元素  val rdd1 =  rdd.partitionBy(new org.apache.spark.HashPartitioner(2))rdd1.mapPartitionsWithIndex{      (partIdx,iter) =&gt; {         val part_map = scala.collection.mutable.Map[String, List[(Int,Int)]]()              while(iter.hasNext){              val part_name = "part_" + partIdx             var elem = iter.next()              if(part_map.contains(part_name)) {  var elems = part_map(part_name) elems ::= elem part_map(part_name) = elems              } else {                 part_map(part_name) = List[(Int,Int)]{elem}             }         }         part_map.iterator        }     }.collect// Map[分区ID, 该分区的元素列表] </div><div><br/></div><div><span style="font-size: 12pt;">这里的分区方法可以选择， 默认的分区就是 HashPartition分区:</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">class HashPartitioner(partitions: Int) extends Partitioner {  require(partitions &gt;= 0, s"Number of partitions ($partitions) cannot be negative.")  def numPartitions: Int = partitions  def getPartition(key: Any): Int = key match {    case null =&gt; 0    case _ =&gt; Utils.nonNegativeMod(key.hashCode, numPartitions)  }  override def equals(other: Any): Boolean = other match {    case h: HashPartitioner =&gt;      h.numPartitions == numPartitions    case _ =&gt;      false  }  override def hashCode: Int = numPartitions}</div><div><br/></div><div><span style="font-size: 12pt;">还可以选择 范围分区 RangePartitioner ：先键值排序， 确定样本大小，采样后不放回 总体的随机采样方法， 分配键值的分区，通过样本采样避免数据倾斜。</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">val rdd2 = rdd.partitionBy(new org.apache.spark.RangePartitioner(3,rdd))rdd2.glom()</div><div><br/></div><div><span style="font-size: 12pt;">还可以 自定义分区函数， 自己根据业务数据减缓数据倾斜问题:</span></div><div><br/></div><div><span style="font-size: 12pt;">要实现自定义的分区器，你需要继承 org.apache.spark.Partitioner 类并实现下面三个方法</span></div><div><br/></div><div><span style="font-size: 12pt;">* numPartitions: Int：返回创建出来的分区数。</span></div><div><span style="font-size: 12pt;">* getPartition(key: Any): Int：返回给定键的分区编号（ 0 到 numPartitions-1）。</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//自定义分区类，需继承Partitioner类class UsridPartitioner(numParts:Int) extends Partitioner{  //覆盖分区数  override def numPartitions: Int = numParts    //覆盖分区号获取函数  override def getPartition(key: Any): Int = {     if(key.toString == "A")           key.toString.toInt%10     else:          key.toString.toInt%5        }}</div><div><br/></div><div><br/></div><h1>排序 sortBy()</h1><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">list_b=[['1', '1'], ['0', '1'], ['2', '1'], ['3', '1'], ['4', '1'], ['5', '1'], ['6', '1'], ['7', '1'], ['8', '1'],['9', '1']]lines = sc.parallelize(list_b)lines=lines.sortBy( lambda x: x[0] ) # 指定 排序的键print(lines.take(10))</div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="https://www.iteblog.com/archives/1240.html" rev="en_rl_none"><span style="font-size: 12pt;">https://www.iteblog.com/archives/1240.html</span></a></div><div><a href="http://lxw1234.com/archives/2015/07/363.htm" rev="en_rl_none"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/07/363.htm</span></a></div><div><br/></div><h1>分组聚合 groupByKey   reduceByKey()</h1><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1 = sc.makeRDD(Array(("A",0),("A",2),("B",1),("B",2),("C",1)))rdd1.groupByKey().collect// res81: Array[(String, Iterable[Int])] = Array((A,CompactBuffer(0, 2)), (B,CompactBuffer(2, 1)), (C,CompactBuffer(1)))</div><div><br/></div><div><span style="font-size: 12pt;">（2）reduceByKey</span></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">reduceByKey </span>用于将RDD[K,V]中 每个 Key 对应的 Value 值 根据映射函数来运算。</span></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">效果上 相当于 利用 groupbyKey 把 相同 key 对应的 value 值 放入一个 List 中，再对 这个 List 执行  reduce </span></span></div><div><br/></div><div><span style="font-size: 12pt;">def reduceByKey(func: (V, V) =&gt; V): RDD[(K, V)]</span></div><div><br/></div><div><span style="font-size: 12pt;">def reduceByKey(func: (V, V) =&gt; V, numPartitions: Int): RDD[(K, V)]</span></div><div><br/></div><div><span style="font-size: 12pt;">def reduceByKey(partitioner: Partitioner, func: (V, V) =&gt; V): RDD[(K, V)]</span></div><div><br/></div><div><span style="font-size: 12pt;">参数 numPartitions 用于指定分区数；</span></div><div><span style="font-size: 12pt;">参数 partitioner 用于指定分区函数；</span></div><div><br/></div><div><span style="font-size: 12pt;">eg1.</span></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1 = sc.makeRDD(Array(("A",0),("A",2),("B",1),("B",2),("C",1))) rdd1.partitions.size // res82: Int = 15var rdd2 = rdd1.reduceByKey((x,y) =&gt; x + y)rdd2.collect// res85: Array[(String, Int)] = Array((A,2), (B,3), (C,1))rdd2.partitions.size// res86:Int=15 var rdd2=rdd1.reduceByKey(new org.apache.spark.HashPartitioner(2),(x,y)=&gt;x+y)//rdd2:org.apache.spark.rdd.RDD[(String,Int)]=ShuffledRDD[95]at reduceByKey at:23 rdd2.collect// res87:Array[(String,Int)]=Array((B,3),(A,2),(C,1)) rdd2.partitions.size// res88:Int=2</div><div><span style="font-size: 12pt;"><span style="color: rgb(0, 0, 255);"> </span></span></div><div><span style="font-size: 12pt;">eg2.单词统计</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：val rdd1 = sc.textFile("/home/centos/test.txt")val rdd2 = rdd1.flatMap(line=&gt;line.split(" ")) // map( line=&gt;line.split(" "))   每一行 返回一个 数组( 包含 这一行的单词) ;    flatMap 把 这个数组 拍扁 成原子的 即 一个一个单词val rdd3 = rdd2.map(word = &gt; (word,1))// val rdd4 = rdd3.reduceByKey(_ + _)  val rdd4 = rdd3.reduceByKey( (x,y) =&gt; x + y )rdd4.collect</div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">因为 groupByKey 会产生大量的 shuffle  开销，所以  可以使用 reduceByKey() ， 在map 端进行 预聚合  （详见  《大规模数据管理》-&gt;分布式计算框架 -&gt; spark 原理） </span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="http://lxw1234.com/archives/2015/07/363.htm" rev="en_rl_none"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/07/363.htm</span></a></div><div><br/></div><div><br/></div><div><br/></div><h1>操作分区 mapPartitions 和 mapPartitionsWithIndex</h1><div><br/></div><div><span style="font-size: 12pt;">（1）mapPartitions 函数 和 map 函数类似，只不过映射函数的参数 由RDD中的每一个元素 变成了 RDD中每一个分区的迭代器。mapPartitions  的作用类似于 MapReduce 中的 clean up 步骤。</span></div><div><br/></div><div><span style="font-size: 12pt;">如果在映射的过程中需要 频繁创建额外的对象，使用mapPartitions要比map高效。</span></div><div><span style="font-size: 12pt;">例如，将RDD中的所有数据通过JDBC连接写入数据库，如果使用map函数，可能要为每一个元素都创建一个connection，这样开销很大，如果使用mapPartitions，那么只需要针对每一个分区建立一个connection。</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1=sc.makeRDD(1to5,2) // 两个分片： (1,2) , (3,4,5)//rdd1有两个分区var rdd3=rdd1.mapPartitions{x=&gt;{|    var result=List[Int]()|    var i=0|    while(x.hasNext){|        i+=x.next()|    }|    result.::(i).iterator|   }|}// rdd3:org.apache.spark.rdd.RDD[Int]=MapPartitionsRDD[84]at mapPartitions at:23 //rdd3将rdd1中每个分区中的数值累加rdd3.collect// res65:Array[Int]=Array(3,12)rdd3.partitions.size//res66:Int=2</div><div><span style="font-size: 12pt;">（2）mapPartitionsWithIndex</span></div><div><br/></div><div><span style="font-size: 12pt;">函数作用同mapPartitions，不过提供了两个参数，第一个参数为分区的索引。</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1=sc.makeRDD(1to5,2)//rdd1有两个分区var rdd2=rdd1.mapPartitionsWithIndex{(x,iter)=&gt;{var result=List[String]()var i=0while(iter.hasNext){i+=iter.next()}result.::(x+"|"+i).iterator}}//rdd2将rdd1中每个分区的数字累加，并在每个分区的累加结果前面加了分区索引rdd2.collect//res13:Array[String]=Array(0|3,1|12)</div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="http://lxw1234.com/archives/2015/07/363.htm"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/07/363.htm</span></a></div><div><br/></div><h1>操作数据行 map 和 flatMap</h1><div><br/></div><div><span style="font-size: 12pt;">（1）map </span></div><div><span style="font-size: 12pt;">将一个RDD中的每个数据项，通过map中的函数映射变为一个新的元素。</span></div><img src="/Resources/2.RDD%20%E7%AE%97%E5%AD%90.resources/C736A18F-C9CC-4AB1-87FB-E5104A1ACA37.png" height="379" width="1087"/><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">输出文件内容 </span></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">hadoop fs -cat /tmp/lxw1234/1.txt// hello world// hello spark// hello hive</div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：//读取HDFS文件到RDDvar data = sc.textFile("/tmp/lxw1234/1.txt")//使用map算子var mapresult = data.map(line =&gt; line.split("\\s+"))//运算map算子结果mapresult.collect// res0: Array[Array[String]] = Array(Array(hello, world), Array(hello, spark), Array(hello, hive))</div><div><br/></div><div><span style="font-size: 12pt;"><b>scala 正则表达式 ：</b></span></div><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:380px;" width="380px"><colgroup><col style="width: 190px;"/><col style="width: 190px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">\\d</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">表示 0-9 的数字,</span></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">\\s</span></div><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">表示 空格,回车,换行等空白符,</span></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;"> \\w</span></div><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">表示单词字符 ( 数字 字母 下划线 )</span></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">+号</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">表示一个或多个的意思</span></div></td></tr></tbody></table><div><br/></div><div><span style="font-size: 12pt;">（2）flatMap</span></div><div><span style="font-size: 12pt;">flatmap()是将函数应用于RDD中的每个元素，将返回的迭代器的所有内容构成新的RDD,这样就得到了一个由各列表中的元素组成的RDD,而不是一个列表组成的RDD。</span></div><img src="/Resources/2.RDD%20%E7%AE%97%E5%AD%90.resources/51EF3E9F-6C53-4686-8475-AE5C20C21344.png" height="369" width="993"/><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：//使用flatMap算子var flatmapresult = data.flatMap(line =&gt; line.split("\\s+"))//运算flagMap算子结果flatmapresult.collect//res1: Array[String] = Array(hello, world, hello, spark, hello, hive)</div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="http://lxw1234.com/archives/2015/06/325.htm" rev="en_rl_none"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/06/325.htm</span></a></div><div><br/></div><h1>reduce </h1><div><br/></div><div><span style="font-size: 12pt;">（1）reduce </span></div><div><br/></div><div><span style="font-size: 12pt;">根据映射函数f，对RDD中的元素进行二元计算，返回计算结果。</span></div><div><br/></div><div><span style="font-size: 12pt;">reduce把一个函数作用在一个序列 [x1, x2, x3, ...] 上，这个函数 必须接收两个参数（二元操作符： x  和 y  相当于 集合中的两个元素）</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;"># python 中利用 reduce 求 sum from functools import reducedef add(x, y):   return x + yreduce(add, [1, 3, 5, 7, 9])</div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1=sc.makeRDD(1to10,2) rdd1.reduce(_+_)// res18:Int=55 var rdd2=sc.makeRDD(Array(("A",0),("A",2),("B",1),("B",2),("C",1))) rdd2.reduce((x,y)=&gt;{    // x=("A",0)  y=("A",2)|(x._1+y._1,x._2+y._2)|})// res21:(String,Int)=(CBBAA,6)</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="Spark 系列" scheme="https://xinrihui.github.io/categories/Spark-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="分布式批处理" scheme="https://xinrihui.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%89%B9%E5%A4%84%E7%90%86/"/>
    
    <category term="Spark" scheme="https://xinrihui.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark - shuffle 机制</title>
    <link href="https://xinrihui.github.io/2022/12/24/1.shuffle%20%E7%A0%94%E7%A9%B6/"/>
    <id>https://xinrihui.github.io/2022/12/24/1.shuffle%20%E7%A0%94%E7%A9%B6/</id>
    <published>2022-12-24T15:30:51.000Z</published>
    <updated>2022-12-24T15:31:14.553Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-12-07 09:55:36 +0000"/><meta name="source" content="yinxiang.superNote"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="https://tech.meituan.com/2016/05/12/spark-tuning-pro.html"/><meta name="updated" content="2022-12-24 15:29:44 +0000"/><title>1.shuffle 研究</title></head><body><h1>总结</h1><div><br/></div><div><span style="font-size: 12pt;">1.管道执行 pipeline</span></div><div><span style="font-size: 12pt;">操作都在内存中执行，不需要为了把计算结果给其他任务而将数据落盘</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">2.Shuffle是 map reduce 的中间过程。map 和 reduce 过程经常被提及 而shuffle不配有姓名，但它恰恰是 开销最大 也最值得优化的步骤</span></div><div><br/></div><div><span style="font-size: 12pt;">3.排序</span></div><div><br/></div><div><span style="font-size: 12pt;">mapreduce 是所有的 shuffle 都排序，排序的目的是： 在O(1) 的空间复杂度下在 reduce 端实现 key  的聚合；</span></div><div><br/></div><div><span style="font-size: 12pt;">spark 在一开始的版本中，为了节约排序的时间代价（快排 O(nlogn)），在 reduce 端 采用 内存中的 hashmap  来做 key  的聚合，当内存写满后再 溢写到磁盘中</span></div><div><br/></div><div><span style="font-size: 12pt;">4.Pipline &amp; writing disk</span></div><div><span style="font-size: 12pt;">mapreduce 是全部落盘，spark 是遇到shuffle 才落盘， MPP是全部pipeline；</span></div><div><span style="font-size: 12pt;">Pipeline越多 延迟越低 容错越差（没有检查点 错了就回到原点 重头再来） 任务调度更加精确 带来了系统复杂度上升（我这边计算好了要交给你 你注意接收）那么系统的吞吐量和可扩展性必然下降</span></div><div><br/></div><div><span style="font-size: 12pt;">5.宽依赖 和 窄依赖</span></div><div><br/></div><div><span style="font-size: 12pt;">窄依赖：一个子分区只依赖于一个 父分区，或者依赖于多个完整的父分区 （因为完整所以不需要把分区打散了传送）。</span></div><div><br/></div><div><span style="font-size: 12pt;">宽依赖：一个子分区 依赖多个父分区的其中一部分（因为不完整，需要将分区打散了再发送）。</span></div><div><br/></div><hr/><div><br/></div><h1>尽量避免使用shuffle类算子</h1><div><br/></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle是一个涉及到CPU(序列化反序列化)、网络IO(跨节点数据传输)以及磁盘IO(shuffle中间结果落地)的操作，所以它是最消耗性能的操作</span>。</span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle过程就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作</span>。比如reduceByKey、join等算子，都会触发shuffle操作。</span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle过程中，各个节点上的相同key都会先写入本地磁盘文件中，然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同key。而且相同key都拉取到同一个节点（优先放入内存中）进行聚合操作时，还有可能会因为一个节点上处理的key过多，导致内存不够存放，进而溢写到磁盘文件中</span>。</span></div><div><br/></div><div><span style="font-size: 12pt;">因此在shuffle过程中，可能会发生大量的磁盘文件读写的IO操作，以及数据的网络传输操作。磁盘IO和网络数据传输也是shuffle性能较差的主要原因。因此在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</span></div><div><br/></div><h2>方案1.map 端预聚合</h2><div><span style="font-size: 12pt;">在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。通常来说，在可能的情况下，<span style="font-weight: bold;">建议使用reduceByKey或者aggregateByKey算子</span>来<span style="font-weight: bold;">替代掉groupByKey算子</span>。<span style="font-weight: bold;">因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合</span>。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。</span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;"> groupByKey                                                                                                     </span></span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/8307D049-2768-4F48-B093-A2D2B865F7AB.png"/><div><span style="font-size: 12pt;"><span style="font-weight: bold;"> reduceByKey</span></span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/28927950-4E28-4D39-911C-27EFFFF657B1.png"/><div><br/></div><div><br/></div><h2>方案２.广播</h2><div><br/></div><div><span style="font-size: 12pt;">使用广播，把较小的表广播出去，相当于每个节点都复制了一份</span></div><div><span style="font-size: 12pt;">// 传统的join操作会导致shuffle操作。</span></div><div><span style="font-size: 12pt;">// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。</span></div><div><span style="font-size: 12pt;">val rdd3 = rdd1.join(rdd2)</span></div><div><br/></div><div><span style="font-size: 12pt;">// Broadcast+map的join操作，不会导致shuffle操作。</span></div><div><span style="font-size: 12pt;">// 使用Broadcast将一个数据量较小的RDD作为广播变量。</span></div><div><span style="font-size: 12pt;">val rdd2Data = rdd2.collect()</span></div><div><span style="font-size: 12pt;">val rdd2DataBroadcast = sc.broadcast(rdd2Data)</span></div><div><br/></div><div><span style="font-size: 12pt;">// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。</span></div><div><span style="font-size: 12pt;">// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。</span></div><div><span style="font-size: 12pt;">// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。</span></div><div><span style="font-size: 12pt;">val rdd3 = rdd1.map(rdd2DataBroadcast...)</span></div><div><br/></div><div><span style="font-size: 12pt;">// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。</span></div><div><span style="font-size: 12pt;">// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用：</span></span></div><div><a href="https://tech.meituan.com/spark_tuning_basic.html" rev="en_rl_none"><span style="font-size: 12pt;"><u>https://tech.meituan.com/spark_tuning_basic.html</u></span></a></div><div><br/></div><div><br/></div><h1>数据倾斜问题</h1><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">现象：</span></span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">1.绝大多数task执行得都非常快，但个别task执行极慢。比如，总共有1000个task，997个task都在1分钟之内执行完了，但是剩余两三个task却要一两个小时</span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">2.原本能够正常执行的Spark作业，某天突然报出OOM（内存溢出）异常，观察异常栈，是我们写的业务代码造成的。</span></p><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">原理：</span></span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">1.在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。比如大部分key对应10条数据，但是个别key却对应了100万条数据，那么大部分task可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别task可能分配到了100万数据，要运行一两个小时。因此，整个Spark作业的运行进度是由运行时间最长的那个task决定的。因此出现数据倾斜的时候，Spark作业看起来会运行得非常缓慢，甚至可能因为某个task处理的数据量过大导致内存溢出。举个例子：</span></p><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/D5F2C86A-0C55-4805-9390-0450E87ECE84.png"/><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">2.可能会触发shuffle操作的RDD算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。</span></p><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">解决方案</span></span></p><p style="--en-paragraph:true;"><br/></p><h2>1.聚合（groupByKey）</h2><p style="--en-paragraph:true;"><br/></p><div><span style="font-size: 12pt;">对于聚合类的shuffle ，可以采用两阶段聚合（局部聚合+全局聚合）</span></div><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;">第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)</span></p><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/3010811A-0551-46B8-A2E8-9B78C7610D2C.png"/><h2>２.连接(join)</h2><p style="--en-paragraph:true;"><br/></p><h3>1.reduce join 转换为 map join</h3><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（1）reduce join：走shuffle过程，一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join。</span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（2）map join：将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后<span style="font-weight: bold;">对其创建一个Broadcast变量</span>；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。</span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（3）缺点：我们需要将小表进行广播，此时会比较消耗内存资源，<span style="font-weight: bold;">driver和每个Executor内存中都会驻留一份小RDD的全量数据</span>。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。</span></p><p style="--en-paragraph:true;"><br/></p><h3>2.采样倾斜的key并分拆join</h3><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><b><span style="font-weight: 700;">方案实现思路：</span></b> </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（1）对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（2）然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;"> （3）接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（4）再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（5）而另外两个普通的RDD就照常join即可。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（6）最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。</span></p><p style="--en-paragraph:true;"><br/></p><p style="text-align:start;"><span style="font-size: 12pt;"><b><span style="font-weight: 700;">方案实现原理：</span></b>对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了</span></p><p style="text-align:start;"><br/></p><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/4D110DDA-A219-4A32-9A6C-09F8B67C6702.png"/><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><br/></p><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">总结：</span>针对原始RDD进行join操作时候遇到的种种问题，spark提供了高层抽象spark SQL，它将完成上述的SQL优化</span></p><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">引用：</span></span></p><p style="--en-paragraph:true;"><a href="https://tech.meituan.com/spark_tuning_pro.html" rev="en_rl_none"><span style="font-size: 12pt;">https://tech.meituan.com/spark_tuning_pro.html</span></a></p><p style="--en-paragraph:true;"><br/></p><h1>spark SQL 实现 join 的物理计划</h1><div><br/></div><h2>1.Broadcast (hash) Join</h2><div><span style="font-size: 12pt;">在SparkSQL中，对两个表做Join最直接的方式是先根据key分区，再在每个分区中把key值相同的记录拿出来做连接操作。但这样就不可避免地涉及到shuffle，而shuffle在Spark中是比较耗时的操作，我们应该尽可能的设计Spark应用使其避免大量的shuffle。步骤如下：</span></div><div><span style="font-size: 12pt;">1. broadcast阶段：将小表广播分发到大表所在的所有主机。广播算法可以有很多，最简单的是先发给driver，driver再统一分发给所有executor；要不就是基于bittorrete的p2p思路；</span></div><div><span style="font-size: 12pt;">2. hash join阶段：在每个executor上执行单机版hash join，小表映射，大表试探</span></div><div><span style="font-size: 12pt;">executor存储小表的全部数据，一定程度上牺牲了空间，换取shuffle操作大量的耗时（类似于 hive 的mapjoin ）</span></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/695F22E9-6704-42E1-9873-07EDAE923B5D.png" height="456" width="831"/><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">缺点：</span>这个方案只能用于广播较小的表，否则数据的冗余传输就远大于shuffle的开销；另外，广播时需要将被广播的表现collect到driver端，当频繁有广播出现时，对driver的内存也是一个考验。</span></div><div><span style="font-size: 12pt;">只有当表的大小在 spark.sql.autoBroadcastJoinThreshold 的设置值（默认为 10MB）之内，才会启用 broadcast join，否则采用sort merge join。此方法适合 一张大表和一张非常小的小表 join。</span></div><div><br/></div><h2>2.shuffle Hash Join （ 重分区 hash join ）</h2><div><br/></div><div><span style="font-size: 12pt;">如果一张表很小，执行join操作最优的选择无疑是broadcast hash join，效率最高。但是一旦小表数据量增大，广播所需内存、带宽等资源必然就会太大，broadcast hash join就不再是最优方案。此时可以按照join key进行分区，根据key相同必然分区相同的原理，就可以将大表join分而治之，划分为很多小表的join，充分利用集群资源并行化。</span></div><div><span style="font-size: 12pt;">分为两步：</span></div><div><span style="font-size: 12pt;">1. 对两张表分别按照 join keys进行重分区，即shuffle，目的是为了让 有相同join keys值的记录分到对应的分区中</span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/9D78FE48-5048-47F8-A919-45E85E0A7A19.png" height="293" width="876"/><div><span style="font-size: 12pt;">2. 对 各个 分区中的数据 进行join：先将 <span style="font-weight: bold;">小表的分区构造为一张hash表</span>，然后根据大表分区中记录的join keys值拿出来进行匹配；</span></div><div><br/></div><div><span style="font-size: 12pt;">优点：两张表 对应的 两个分区 自己做 join ，不用 和 其他的分区 做关联，降低开销</span></div><div><br/></div><div><span style="font-size: 12pt;">Shuffle Hash Join的条件有以下几个：</span></div><div><br/></div><div><span style="font-size: 12pt;">1）分区的平均大小不超过spark.sql.autoBroadcastJoinThreshold所配置的值，默认是10M</span></div><div><span style="font-size: 12pt;">2） 开启 尝试使用hash join的开关，spark.sql.join.preferSortMergeJoin=false</span></div><div><span style="font-size: 12pt;">3）一侧的表要明显小于另外一侧，小的一侧将被hash（明显小于的定义为3倍小，此处为经验值）</span></div><div><br/></div><div><span style="font-size: 12pt;">我们可以看到，在一定大小的表中，SparkSQL从时空结合的角度来看，将两个表进行重新分区，并且对小表中的分区进行hash化，从而完成join。在保持一定复杂度的基础上，尽量减少driver和executor的内存压力，提升了计算时的稳定性。</span></div><div><br/></div><div><br/></div><h2>3.shuffle Sort Merge Join （ 重分区 排序 join ）</h2><div><br/></div><div><span style="font-size: 12pt;">首先将两张表按照join keys进行了重新shuffle，保证join keys值相同的记录会被分在相应的分区。</span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/7675B305-2BE3-4D1D-9C37-2CE5B9423E5F.png" height="443" width="859"/><div><br/></div><div><span style="font-size: 12pt;">分区后对每个分区内的数据进行排序（<span style="font-weight: bold;">spark shuffle 阶段 自动排序</span>），排序后再对相应的分区内的记录进行连接。因为两个序列都是有序的，从头遍历，碰到key相同的就输出；如果不同，左边小就继续取左边，反之取右边。可以看出，无论分区有多大，Sort Merge Join都不用把某一侧的数据全部加载到内存中，而是 即用 即取 即丢，从而大大提升了大数据量下sql join的稳定性。</span></div><div><br/></div><div><span style="font-size: 12pt;">这是spark SQL 默认的join 方法，适合两张表都是大表的情况。</span></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/2AD3BD2D-330D-4E33-B6F6-B346A2392C93.png" height="615" width="1079"/><div><br/></div><div><span style="font-size: 12pt;">其实 <span style="font-weight: bold;">hash join</span> 的思路来源于传统的数据库</span></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">Hash Join</span></span></div><div><span style="font-size: 12pt;">先来看看这样一条SQL语句：select * from order,item where item.id = order.i_id，很简单一个Join节点，参与join的两张表是item和order，join key分别是item.id以及order.i_id。现在假设这个Join采用的是hash join算法，整个过程会经历三步：</span></div><div><span style="font-size: 12pt;">1） 确定Build Table以及Probe Table：这个概念比较重要，Build Table使用join key构建Hash Table，而Probe Table使用join key进行探测，探测成功就可以join在一起。通常情况下，小表会作为Build Table，大表作为Probe Table。此事例中item为Build Table，order为Probe Table。</span></div><div><span style="font-size: 12pt;">2） 构建Hash Table：依次读取Build Table（item）的数据，对于每一行数据根据join key（item.id）进行hash，hash到对应的Bucket，生成hash table中的一条记录。数据缓存在内存中，如果内存放不下需要dump到外存。</span></div><div><span style="font-size: 12pt;">3） 探测：再依次扫描Probe Table（order）的数据，使用相同的hash函数映射Hash Table中的记录，映射成功之后再检查join条件（item.id = order.i_id），如果匹配成功就可以将两者join在一起。</span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/54886F94-64CA-45E3-B3A6-F85E54FE56F3.png" height="493" width="805"/><div><span style="font-size: 12pt;">很显然，hash join基本都只扫描两表一次，可以认为o(a+b)，较之最极端的笛卡尔集运算a*b，时间复杂度低。</span></div><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">Join操作是传统数据库中的一个高级特性，尤其对于当前MySQL数据库更是如此，原因很简单，MySQL对Join的支持目前还比较有限，只支持Nested-Loop Join算法，因此在OLAP场景下MySQL是很难吃的消的，不要去用MySQL去跑任何OLAP业务，结果真的很难看。和MySQL相比，PostgreSQL、SQLServer、Oracle等这些数据库对Join支持更加全面一些，都支持Hash Join算法。总体而言，传统数据库单机模式做Join的场景毕竟有限，也建议尽量减少使用Join。然而大数据领域就完全不同，Join是标配，OLAP业务根本无法离开表与表之间的关联，对Join的支持成熟度一定程度上决定了系统的性能，夸张点说，’得Join者得天下’。</span></p><p style="--en-paragraph:true;"><br/></p><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用：</span></span></div><div><a href="http://hbasefly.com/2017/03/19/sparksql-basic-join/" rev="en_rl_none"><span style="font-size: 12pt;">http://hbasefly.com/2017/03/19/sparksql-basic-join/</span></a></div><div><a href="http://sharkdtu.com/posts/spark-sql-join.html" rev="en_rl_none"><span style="font-size: 12pt;">http://sharkdtu.com/posts/spark-sql-join.html</span></a></div><div><br/></div><h1><span style="color: #000000;">有的 join 其实属于 窄依赖 </span></h1><div><br/></div><ul><li><div><span style="font-size: 12pt;"><span style="font-weight: bold;">窄依赖（不发生 shuffle）</span>：父Rdd的分区最多只能被一个子Rdd的分区所引用，即一个父Rdd的分区对应一个子Rdd的分区，或者多个父Rdd的分区对应一个子Rdd的分区。即<span style="font-weight: bold;">一对一 或 多对一（儿子有多个父亲）</span>，如下图左边所示。</span></div></li></ul><div><br/></div><ul><li><div><span style="font-size: 12pt;"><span style="font-weight: bold;">宽依赖（发生shuffle）</span>：RDD的分区依赖于父RDD的多个分区或所有分区，即存在一个父RDD的一个分区对应一个子RDD的多个分区。1个父RDD分区对应多个子RDD分区，这其中又分两种情况：1个父RDD对应所有子RDD分区（未经协同划分的Join）或者1个父RDD对应非全部的多个RDD分区（如groupByKey），即<span style="font-weight: bold;">一对多（父亲有多个儿子）。</span></span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">（1）图中左半部分join：如果两个RDD在进行join操作时，一个RDD的partition仅仅和另一个RDD中已知个数的Partition进行join，那么这种类型的join操作就是窄依赖，例如图1中左半部分的join操作(join with inputs co-partitioned)；</span></div><div><br/></div><div><span style="font-size: 12pt;">（2）图中右半部分join：其它情况的join操作就是宽依赖,例如图1中右半部分的join操作(join with inputs not co-partitioned)，由于是需要父RDD的所有partition进行join的转换，这就涉及到了shuffle，因此这种类型的join操作也是宽依赖。</span></div><div><br/></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/Image.png" height="410" width="565"/><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">join with inputs co-partitions</span>：</span></div><div><span style="font-size: 12pt;">如果 两张表的 分区 是一一对应的， 相当于 <span style="font-weight: bold;">分区hash join</span> 的 第一步已经 天然做好了，因此 只要 两张表的 对应两个分区（相当于 两个子表 ）自己 做Join 即可，</span></div><div><span style="font-size: 12pt;">具体可以采用 hash Join ，若分区 内已经有序，还可以使用 sort merge Join 。</span></div><div><span style="font-size: 12pt;">在这种情况下，子RDD 的一个分区的 数据 不会 “可能来自于 所有的 父RDD” ，所以是窄依赖。</span></div><div><br/></div><h1>shuffle管理器</h1><div><br/></div><div><span style="font-size: 12pt;">在Spark 1.2以前，默认的 shuffle计算引擎 是HashShuffleManager。它有着一个非常严重的弊端，就是会产生大量的中间磁盘文件，进而由大量的磁盘IO操作影响了性能。因此在Spark 1.2以后的版本中，默认的 ShuffleManager 改成了 SortShuffleManager</span></div><div><br/></div><h2>HashShuffleManager</h2><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle write</span>：主要就是在一个stage结束计算之后，为了下一个stage可以执行shuffle类的算子（比如reduceByKey），而将每个task处理的数据按key进行“分类”。所谓“分类”，就是<span style="font-weight: bold;">对相同的key执行hash算法，从而将相同key都写入同一个磁盘文件中，而每一个磁盘文件都只属于下游stage的一个task</span>。在将数据写入磁盘之前，会先将数据写入内存缓冲中，当内存缓冲填满之后，才会溢写到磁盘文件中去。下一个stage的task有多少个，当前stage的每个task就要创建多少份磁盘文件。如图所示，下一个stage 一共有3个task ，当前的每一个task都要创建3个文件。可见，未经优化的<span style="font-weight: bold;">shuffle write操作所产生的磁盘文件的数量是极其惊人的。（MapReduce 也存在此问题）</span></span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle read</span>：此时该stage的每一个task就需要将上一个stage的计算结果中的所有相同key，从各个节点上通过网络都拉取到自己所在的节点上，然后进行key的聚合或连接等操作。由于shuffle write的过程中，task给下游stage的每个task都创建了一个磁盘文件，因此shuffle read的过程中，每个task只要从上游stage的所有task所在节点上，拉取属于自己的那一个磁盘文件即可。shuffle read的拉取过程是一边拉取一边进行聚合的。每个shuffle read task都会有一个自己的buffer缓冲，每次都只能拉取与buffer缓冲相同大小的数据，然后通过内存中的一个Map进行聚合等操作。聚合完一批数据后，再拉取下一批数据，并放到buffer缓冲中进行聚合操作。以此类推，直到最后将所有数据到拉取完，并得到最终的结果。</span></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/a8d32434d35045b4b05ef6bcc7ce4fba.jpeg" height="564" width="957"/><div><br/></div><div><span style="font-size: 12pt;">优化后的Hash Shuffle</span></div><div><span style="font-size: 12pt;">普通机制Hash Shuffle会产生大量的小文件(M * R），对文件系统的压力也很大，也不利于IO的吞吐量，后来做了优化（设置spark.shuffle.consolidateFiles=true开启，默认false），把在同一个core上的多个Mapper输出到同一个文件，这样文件数就变成core * R 个了。如下图所示：2个core 4个map task 3 个reduce task，会产生2*3=6个小文件。</span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/24e46dede4474c3d8d9349bb93579a4b.jpeg" height="736" width="957"/><div><br/></div><div><span style="font-size: 12pt;">Hash shuffle合并机制的问题：如果 Reducer 端的并行任务或者是数据分片过多的话则 Core * Reducer Task 依旧过大，也会产生很多小文件。进而引出了更优化的sort shuffle。</span></div><div><br/></div><h2>SortShuffleManager</h2><div><br/></div><h3>普通运行机制</h3><div><br/></div><div><span style="font-size: 12pt;">在该模式下，数据会先写入一个内存数据结构中，此时根据不同的shuffle算子，可能选用不同的数据结构。</span></div><ul><li><div><span style="font-size: 12pt;">如果是 reduceByKey 这种 <span style="font-weight: bold;">聚合类的shuffle算子，那么会选用Map数据结构，一边通过Map进行聚合，一边写入内存</span>；</span></div></li><li><div><span style="font-size: 12pt;">如果是join这种普通的shuffle算子，那么会选用Array数据结构，直接写入内存。</span></div></li></ul><div><span style="font-size: 12pt;">接着，每写一条数据进入内存数据结构之后，就会判断一下，是否达到了某个临界阈值。如果达到临界阈值的话，那么就会尝试将内存数据结构中的数据溢写到磁盘，然后清空内存数据结构。<span style="font-weight: bold;">在溢写到磁盘文件之前，会先根据key对内存数据结构中已有的数据进行排序</span>。排序过后，会分批将数据写入磁盘文件。默认的batch数量是10000条，也就是说，排序好的数据，会以每批1万条数据的形式分批写入磁盘文件。一个task将所有数据写入内存数据结构的过程中，会发生多次磁盘溢写操作，也就会产生多个临时文件。</span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">最后会将之前所有的临时磁盘文件都进行合并</span>，这就是merge过程，此时会将之前所有临时磁盘文件中的数据读取出来，然后依次写入最终的磁盘文件之中。此外，<span style="font-weight: bold;">由于一个当前task就只对应一个磁盘文件</span>，也就意味着该task为下游stage的task准备的数据都在这一个文件中，因此还会单独写一份<span style="font-weight: bold;">索引文件，其中标识了下游各个task的数据 在文件中的start offset与end offset</span>。</span></div><div><br/></div><div><span style="font-size: 12pt;">下游的 task 的数量 取决于 分区函数( eg. partitionBy , repartition ) 所设定的分区数目 ，这里的下游 相当于 MapReduce 中的 reduce 阶段 ，在reduce 阶段 ：一个分区对应一个 reduce task ，它自己去拉取 各个Map task 生成的属于自己的分区文件 ； </span></div><div><span style="font-size: 12pt;">这里的优化策略可以概括为，对于 一个 Map task，它本来要生成 多个分区文件，我们将它合并到一个文件中，并搭配一个索引文件，这样大大减少了文件数量。</span></div><div><br/></div><div><br/></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/C7C9849D-7F60-4F02-8F46-806CBB693D89.png"/><div><br/></div><h3>bypass 运行机制</h3><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/e46b3cd956dd4f1493fa6218d842be2d.jpeg" height="694" width="1080"/><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">触发条件：</span></div><ul><li><div><span style="font-size: 12pt;">shuffle map task 数量小于 spark.shuffle.sort.bypassMergeThreshold 参数设定值。</span></div></li></ul><div><span style="font-size: 12pt;">AND</span></div><ul><li><div><span style="font-size: 12pt;">join 类算子（由于在普通的运行机制下，对于聚合类算子，会预先进行聚合再写入文件，性能更优）</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">此时task会为每个reduce端的task都创建一个临时磁盘文件，并将数据按key进行hash然后根据key的hash值，将key写入对应的磁盘文件之中。当然，写入磁盘文件时也是先写入内存缓冲，缓冲写满之后再溢写到磁盘文件的。最后，同样会将所有临时磁盘文件都合并成一个磁盘文件，并创建一个单独的索引文件。</span></div><div><br/></div><div><span style="font-size: 12pt;">该过程的磁盘写机制其实跟未经优化的HashShuffleManager是一模一样的，因为都要创建数量惊人的磁盘文件，只是在最后会做一个磁盘文件的合并而已。因此少量的最终磁盘文件，也让该机制相对未经优化的HashShuffleManager来说，shuffle read的性能会更好。</span></div><div><br/></div><div><br/></div><h1>为什么 shuffle 的中间结果落磁盘 而不落在内存</h1><div><br/></div><p>在目前的 Spark 实现中，shuffle block 一定是落地到磁盘的，无法像普通 RDD 那样 cache 到本地内存或 Tachyon 中。想将 shuffle block cache 到内存中，应该主要是为了提速，但事实上并没有什么必要。</p><p><br/></p><p>首先，内存 cache 发挥作用的前提是被 cache 的数据会被反复使用。使用越频繁，相对来说收益越高。而 shuffle block 只有在下游 task 失败，进行容错恢复时才有重用机会，频次很低。值得注意的是，在不 cache 的情况下，针对同一个含 shuffle 的 RDD 执行多个 action，并不会重用 shuffle 结果。Shuffle block 是按 job ID + task ID + attempt ID 标识的，每个 action 都对应于一个独立的 job，因此无法重用。这里或许是 Spark 的一个可改进点。</p><p><br/></p><p>其次，从数据量上说，如果执行的是需要 shuffle 大数据量的 Spark job，内存容量不够，无论如何都需要落盘；如果执行的是小数据量的 Spark job，虽然 shuffle block 会落盘，但仍然还在 OS cache 内，而 shuffle block 一般都是在生成之后短时间内即被下游 task 取走，所以大部分情况下仍然还是内存访问。</p><p><br/></p><p>最后，将 shuffle block cache 在内存中的确有一个潜在好处，就是有机会直接在内存中保存原始的 Java 对象而避免序列化开销。但这个问题在新近的 Spark 版本中也有了比较好的解决方案。Tungsten project 中引入的 UnsafeRow 格式统一了内存和磁盘表示，已经最小化了序列化成本。</p><p><br/></p><h1>分区函数：HashPartitioner 和 RangePartitioner </h1><div><br/></div><div><span style="font-size: 12pt;">HashPartitioner的原理很简单，只是计算key的hashcode，然后对新分区的数目取余。所以HashPartitioner最重要的属性是新分区的数量。注意HashPartition不能支持key为数组类型。</span></div><div><br/></div><div><span style="font-size: 12pt;">HashPartitioner分区可能导致每个分区中数据量的不均匀。</span></div><div><br/></div><div><span style="font-size: 12pt;">RangePartitioner的原理会稍微复杂一些，会遍历rdd的所有分区数据，从每个分区都会采样，然后根据样本，生成新分区的边界值，这样就可以根据key把数据分布到对应的新分区。</span></div><div><br/></div><div><span style="font-size: 12pt;">Range分区尽量保证每个分区中数据量的均匀，将一定范围内的数映射到某一个分区内。分区与分区之间数据是有序的，但分区内的元素是不能保证顺序的。</span></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="https://zhmin.github.io/2019/01/06/spark-partitioner/" rev="en_rl_none"><span style="font-size: 12pt;">https://zhmin.github.io/2019/01/06/spark-partitioner/</span></a></div><div><a href="https://www.jianshu.com/p/d9fd44781a32" rev="en_rl_none"><span style="font-size: 12pt;">https://www.jianshu.com/p/d9fd44781a32</span></a></div><div><br/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="Spark 系列" scheme="https://xinrihui.github.io/categories/Spark-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="分布式批处理" scheme="https://xinrihui.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%89%B9%E5%A4%84%E7%90%86/"/>
    
    <category term="Spark" scheme="https://xinrihui.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost 源码分析 1</title>
    <link href="https://xinrihui.github.io/2022/12/05/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201/"/>
    <id>https://xinrihui.github.io/2022/12/05/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201/</id>
    <published>2022-12-05T07:12:33.000Z</published>
    <updated>2022-12-05T07:12:33.909Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2021-09-19 08:33:58 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 16:53:23 +0000"/><title>XGBoost 源码分析 1</title></head><body><div style="margin-top: 1.4em; margin-right: 0px; margin-bottom: 1.4em;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold;">1.XGBoost 入口代码框架</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">从命令行入口开始，毕竟C++直接的入口，容易理解:</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">1.</span> <a href="https://link.zhihu.com/?target=http%3A//cli_main.cc" style="font-size: 0px; text-shadow: none; color: transparent; font-family: a; font-stretch: normal; font-variant: normal; line-height: 0;">http://</a><span style="font-size: 12pt;">src/cli_main.cc</span> <span style="font-size: 12pt; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">是一个带错误处理的入口：</span></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/cli_main.cc">cli_main.cc</a></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="https://pic2.zhimg.com/80/v2-2c5edc4cff53b2284805c7d4f9fdf0ed_720w.jpg"/></div><div style="margin: 1.4em 0px;"><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">2. CLI::Run的核心就是干3件事， Train, DumpModel，Predict。咱目前只看Train</span></div></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="https://pic4.zhimg.com/80/v2-74c51fe3bb627913915e8f774300b0f3_720w.jpg"/></div><div style="margin: 1.4em 0px;"><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">3. Train干4件事情， Load数据， 初始化 Learner，循环训练和保存模型， 咱目前只看训练：UpdateOneIter</span></div></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/378E8E2D-74B6-411A-8B5D-D10BBBADEC7C.jpg" height="384" width="673"/></div></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">要注意，这里的num_round做的事情，其实就是Gradient Boost Trees最常见的套路。</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">每一轮的迭代会生成一颗新的树。</span></div><div style="margin: -0.8em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">通过GD来求解stagewise的参数：</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">4. UpdateOneIter 干了3件核心的事情</span></div><div><br/></div><div style="margin: 1.4em 0px;"><div><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/learner.cc">learner.cc</a></div><div><br/></div><div><span style="font-size: 16px;">class&nbsp;&nbsp;</span><span style="font-size: 12pt;">LearnerImpl</span></div><div><span style="font-size: 16px;">->&nbsp;&nbsp;</span> <span style="font-size: 12pt;">void UpdateOneIter(&nbsp;&nbsp;</span></div><div><br/></div></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/BA6D567A-6E00-46A9-B4A1-087A13B1D079.jpg" height="328" width="905"/></div><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">1）计算当前参数下，样本预测结果，用来计算误差。 （换句话说，如果神初始化，效果perfect，后续都不用训练了）</span></div><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">2）计算一阶和二阶梯度&nbsp;&nbsp;</span></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/9DBDAC7B-0377-4823-A97E-018FB27DA1AF.png" height="583" width="1258"/></div><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">可以看到不同的&nbsp;&nbsp;目标函数&nbsp;&nbsp;对应不同的&nbsp;&nbsp;梯度算法</span></div><div><br/></div><div><span style="font-size: 16px;">多分类的目标函数（multiclass_obj.cu）：</span></div><div><br/></div><div><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/multiclass_obj.cu">multiclass_obj.cu</a></div><div><br/></div><div><span style="font-size: 12pt;">class SoftmaxMultiClassObj</span></div><div><span style="font-size: 16px;">->&nbsp;&nbsp;</span><span style="font-size: 12pt;">void GetGradient(</span></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/2EDD157C-63F5-4865-960D-51DAA3776761.png" height="555" width="1243"/></div><div><br/></div><div><span style="font-size: 16px;">对应的 softmax&nbsp;&nbsp;求导公式为：</span></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/6ADE3353-9DC5-470B-90E0-56CFF55D44A8.png" height="253" width="547"/></div><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">3）Boost操作 ：DoBoost</span></div><div><span style="font-size: 16px;"><br/></span></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">到了DoBoost， 开始有不同的实现方式引入了：GBLine和GBTree的两种方式。 这里可以学习一下， 一个GradientBooster的基础类应该包括哪些核心函数：例如， DoBoost，PredictLeaf, PreditBatch, PredictInstance等等</span></div></div><div style="margin: 1.4em 0px;"><div><br/></div><div><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/gbtree.cc">gbtree.cc</a></div><div><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">void GBTree::DoBoost</span></div><div><br/></div></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/DF60DF5B-C906-4ED9-9084-BD2630F5C21D.jpg" height="1351" width="720"/></div><div style="margin: 1.4em 0px;"><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">对于线性的部分， Boost完了基本也是折线分类器， 相比Tree的非线性分类器，还是很难效果好。 所以默认也是GBTree.</span></div></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">在更深入GBTree之前， 咱大致了解一下XGBoost的代码基本框架，方便认知代码的组织。</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold; line-height: 1.6;">2.XGBoost 代码基本框架</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">核心代码结构里面，前面咱知道了，有个boost框架下， 有线性模型和树模型，然后再加上各种评价指标，构成了模型的核心内容。</span></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/2ADDEC87-7036-4230-8ECE-0FC6C7264EC9.jpg" height="400" width="263"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">在具体的实现上， XGBoost集成了DMLC的良好的注册使用机制。 使用了DMLC_REGISTRY_LINK_TAG宏对核心实现进行插件式管理。</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">这里有个常见的宏问题， 在宏里面一个#号，和两个##号是什么区别？为了加深大家的印象， 大家可以自行去了解。</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%201.resources/5D78C4CC-D2E4-4B5A-ACE3-1BD7B2F5BD06.png" height="54" width="675"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">有了线索，很容易看到，哪些实现进行了插件式管理。&nbsp;&nbsp;</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;"><br/></span></div><div style="margin: 1.4em 0px;"><span style="color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold;">引用</span></div><div style="margin: 1.4em 0px;"><a href="https://zhuanlan.zhihu.com/p/336939389">https://zhuanlan.zhihu.com/p/336939389</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;"><br/></span></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="XGBoost 系列" scheme="https://xinrihui.github.io/categories/XGBoost-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="xgboost" scheme="https://xinrihui.github.io/tags/xgboost/"/>
    
    <category term="源码分析" scheme="https://xinrihui.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost 源码分析 2</title>
    <link href="https://xinrihui.github.io/2022/12/05/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202/"/>
    <id>https://xinrihui.github.io/2022/12/05/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202/</id>
    <published>2022-12-05T07:12:33.000Z</published>
    <updated>2022-12-05T07:12:33.910Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2021-09-19 08:32:12 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 16:53:34 +0000"/><title>XGBoost 源码分析 2</title></head><body><div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold; line-height: 1.6;">3.树的更新机制</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">：</span></div><ul><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_colmaker</span></div></li></ul><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/updater_colmaker.cc">updater_colmaker.cc</a></div><ul><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_histmaker</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_quantile_hist</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_gpu_hist</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_prune</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_refresh</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_sync</span></div></li></ul><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/C9C8E35D-79F0-4DF4-B887-3A1870A04EF0.jpg" height="478" width="926"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">同时，从代码继承上来看， 除了剪枝prune，刷新refresh，同步sync之外， 有三种核心的实现 （这里没有把GPU的实现放在图里面）：</span></div><ul style="padding: 0px; margin: 1.4em 0px; display: table;"><li style="list-style-type:none;display:table-row;list-style:none;"><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•HistMaker, CQHistMaker</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•ColMaker</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•QuantileHistMaker, QuantileHistMock</span></div></li></ul><div style="margin: -0.8em 0px;"><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/074EC1D3-7E53-4061-AD13-4590C8AC8FFC.jpg" height="1402" width="1080"/></div><div><br/></div></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">那么， 具体这几个更新的核心差异是什么呢？咱看参数是怎么告诉咱的？</span></div><div style="margin: -0.8em 0px;"><br/></div><ul style="padding: 0px; margin: 1.4em 0px; display: table;"><li style="list-style-type:none;display:table-row;list-style:none;"><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•ColMaker：是精准模型</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•HistMaker：是近似模型</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•QuantileHistMaker：是Hist模型</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•GPUHistMaker：GPU近似模型</span></div></li></ul><div style="margin: -0.8em 0px;"><div><br/></div><div><br/></div><div><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/gbtree.cc">gbtree.cc</a></div><div><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">void GBTree::ConfigureUpdaters()&nbsp;&nbsp;</span></div><div><br/></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/D88E2ED6-9EDE-4340-9E30-95DA3CEBD68A.png" height="814" width="864"/></div></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;"><br/></span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">对应到论文的实现，精准贪心(kExact) 和 近似分位数( kApprox ) 算法.</span></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/CA30726C-652A-4D4E-8C17-102CA1F6D970.jpg" height="582" width="720"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">所以接下来， 我们只看精准实现ColMaker。前面咱提到，GBTree的DoBoost 是主要入口。其中最主要的实现是BoostNewTrees。这里对于多类情况， 每个类别都要生成一堆树。</span></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/gbtree.cc">gbtree.cc</a></div><div style="margin: -0.8em 0px;"><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">void GBTree::DoBoost</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/D8C6D1DC-8A99-4A4A-9B40-77CEE8CF49CB.png" height="775" width="1043"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold;">4.XGBoost ColMaker 实现</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">BoostNewTrees里面主要是生成并发的新树（个数为num_parallel_tree， 这个配置其实和随机森林的意味更接近，后续可以假定就是num_parallel_tree=1， new_trees就一棵树），然后更新两种默认的更新器， ColMaker 和 TreePruner (剪枝)。</span></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/gbtree.cc">gbtree.cc</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">void GBTree::BoostNewTrees</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/6926056C-DF78-404D-B70D-6BBFBF49FA4C.png" height="748" width="956"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/23398D86-B30E-4DCD-AFC3-12BAFEA76915.png" height="678" width="1266"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;">由上图可见7&nbsp;&nbsp;种&nbsp;&nbsp;</span><span style="font-size: 16px; font-weight: bold;">树的</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold; line-height: 1.6;">更新机制</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">然后，就看ColMaker的Update函数实现， 背后其实是 ColMaker::Builder 实现的。 最终依赖于Builder 的 EnumerateSplit实现：</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;">调用关系为：</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt;">TreeUpdater</span><span style="font-size: 16px;">:: Update() ->&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt;">TreeUpdater</span><span style="font-size: 12pt;">:: Builder ::</span><span style="font-size: 16px;">Update</span><span style="font-size: 12pt;">&nbsp;&nbsp; ->&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 16px;">&nbsp;&nbsp;</span><span style="font-size: 12pt;">TreeUpdater</span><span style="font-size: 12pt;">:: Builder :: findsplit&nbsp;&nbsp; ->&nbsp;&nbsp;</span><span style="font-size: 12pt;">UpdateSolution ->&nbsp;&nbsp;</span><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt;">TreeUpdater</span><span style="font-size: 12pt;">:: Builder ::</span><span style="font-size: 12pt;">&nbsp;&nbsp;</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">EnumerateSplit</span></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/updater_colmaker.cc">updater_colmaker.cc</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">void Update()</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/860AA39A-F928-4835-BF2C-1EDAA1969706.png" height="648" width="854"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">virtual void Update(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/43D554E4-2E53-47F9-8FDA-2742904CD4F6.png" height="664" width="835"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">class Builder ::</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">&nbsp;&nbsp;inline void FindSplit(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/974ACC56-E6B8-465B-AF9D-A754204132FE.png" height="831" width="1040"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">virtual void UpdateSolution(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/4148474B-ADDB-48F7-9081-6E146790AE2C.png" height="801" width="981"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">void EnumerateSplit(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/4A8C69E4-B6C9-488F-BC97-74778EE96FAE.png" height="822" width="928"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold; line-height: 1.6;">4.叶子节点分裂 (Split)</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">主要由TreeEvalutor 的 SplitEvaluator类负责完成</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="https://pic1.zhimg.com/80/v2-16faab48b7abe608b00bb734de7bacf4_720w.png"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">大体上咱又能够 把函数 和 对应的Paper公式相关起来了：</span></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/7A0EFC3D-6A81-4916-BD2F-BA3BB635873B.jpg" height="643" width="1440"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 16px; color: unset; font-family: unset; font-weight: bold;">4.1. 计算 split&nbsp;&nbsp;前 原节点的&nbsp;&nbsp;权重(叶子节点的值)&nbsp;&nbsp; 和&nbsp;&nbsp;增益 (gain)</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/updater_colmaker.cc">updater_colmaker.cc</a></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 16px; color: unset; font-family: unset;">&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">inline void InitNewNode</span></div><div style="margin: -0.8em 0px;"><div><br/></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/00B069E8-EB87-4FD6-BACA-35953ECF55B5.png" height="263" width="1013"/></div></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><div><br/></div></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">（1）拆分前 节点 的Gain</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">&nbsp;&nbsp;：</span></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/split_evaluator.h">split_evaluator.h</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">TreeEvaluator ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">SplitEvaluator ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">float CalcGain</span></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/57C939F7-5FCB-4EF5-9640-ED1DA0266C06.png" height="133" width="926"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 12pt; font-weight: bold;">CalcGainGivenWeight</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/1CAC83B1-296E-4969-9A40-AE0D4E612C01.png" height="379" width="1087"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/param_1.h">param_1.h</a></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 12pt; font-weight: bold;">inline T CalcGainGivenWeight</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/5C0CF495-F4F1-4ECB-B70E-45326D90B29D.png" height="201" width="941"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/938D9B25-7B42-4658-9D6C-1E335E929BE3.png" height="233" width="409"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">代码兼容了 L1(&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(18, 18, 18);">ThresholdL1&nbsp;&nbsp;</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">) 的情况，因此和&nbsp;&nbsp;公式不符</span></div><div style="margin: 1.4em 0px;"><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">（2）拆分前 节点的权重</span></div><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">权重计算，要注意，这里兼容了L1和L2的正则化，但是论文中只给了L2的情况。</span></div><div><br/></div><div><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/param.h">param.h</a></div><div><br/></div><div><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">inline T CalcWeight</span></div></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/3344E4F7-595E-457D-948D-85EBA932711F.png" height="379" width="872"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/EE720179-F78A-4612-B9A1-71791241DC7E.png" height="133" width="499"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/F03D9AAD-C308-4F5B-879F-0472BE632D8A.jpg" height="503" width="835"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold;">4.2. 计算&nbsp;&nbsp; Split后的 增益变化 loss_chg&nbsp;&nbsp;</span></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/updater_colmaker.cc">updater_colmaker.cc</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">void EnumerateSplit(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/E4ED2242-2AD0-4434-B39E-7D1E415F8945.png" height="452" width="977"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">inline void UpdateEnumeration</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/1A97EF58-3DC8-499A-8582-A6BB3B551610.png" height="632" width="1301"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/FD2B0B6A-AD70-4A59-A72B-28B2AA93E905.png" height="294" width="1048"/></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/split_evaluator.h">split_evaluator.h</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">class&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">TreeEvaluator ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(18, 18, 18); font-family: unset; font-weight: bold;">struct SplitEvaluator ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(18, 18, 18); font-family: unset; font-weight: bold;">double CalcSplitGain</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/8E08FA6D-D0E7-4081-B196-29065E2FF4E6.png" height="593" width="953"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/D6456F8B-2390-442B-84EF-8BF187F8390D.png" height="293" width="1048"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;">其中 GradStats&nbsp;&nbsp;记录了&nbsp;&nbsp;G&nbsp;&nbsp;和&nbsp;&nbsp;H ，即梯度的累加和</span></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; color: rgb(18, 18, 18); font-weight: bold;">引用</span></div><div style="margin: 1.4em 0px;"><a href="https://zhuanlan.zhihu.com/p/336939389" style="color: rgb(18, 18, 18);">https://zhuanlan.zhihu.com/p/336939389</a></div><div><br/></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="XGBoost 系列" scheme="https://xinrihui.github.io/categories/XGBoost-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="xgboost" scheme="https://xinrihui.github.io/tags/xgboost/"/>
    
    <category term="源码分析" scheme="https://xinrihui.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>提升方法推导(AdaBoost, GBDT, XGBoost)</title>
    <link href="https://xinrihui.github.io/2022/12/04/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC/"/>
    <id>https://xinrihui.github.io/2022/12/04/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC/</id>
    <published>2022-12-04T15:29:03.000Z</published>
    <updated>2022-12-05T07:25:18.445Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="created" content="2022-02-14 16:34:24 +0000"/><meta name="source-application" content="ios.clipper.evernote"/><meta name="updated" content="2022-12-04 15:27:47 +0000"/><title>提升方法推导</title></head><body><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-01.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-02.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-03.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-04.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-05.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-06.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-07.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-08.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-09.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-10.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-11.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-12.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-13.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-14.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-15.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-16.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-17.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-18.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-19.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-20.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-21.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-22.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-23.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-24.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-25.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-26.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-27.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-28.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-29.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-30.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-32.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-31.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-33.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-34.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-35.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-36.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-37.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-38.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-39.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-40.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-41.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-42.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-43.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-44.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-45.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-46.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-47.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-48.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-49.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-50.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-51.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-52.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-53.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-54.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-55.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-57.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-56.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-58.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-59.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-60.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-61.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-62.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-64.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-65.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-66.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-67.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-63.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-68.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-70.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%8E%A8%E5%AF%BC.resources/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95-69.jpg" height="1491" width="2386"/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="机器学习推公式系列" scheme="https://xinrihui.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A8%E5%85%AC%E5%BC%8F%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="机器学习" scheme="https://xinrihui.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="xgboost" scheme="https://xinrihui.github.io/tags/xgboost/"/>
    
    <category term="AdaBoost" scheme="https://xinrihui.github.io/tags/AdaBoost/"/>
    
    <category term="GBDT" scheme="https://xinrihui.github.io/tags/GBDT/"/>
    
  </entry>
  
  <entry>
    <title>MLP CNN RNN LSTM的推导（正向和反向传播）</title>
    <link href="https://xinrihui.github.io/2022/12/04/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89/"/>
    <id>https://xinrihui.github.io/2022/12/04/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89/</id>
    <published>2022-12-04T15:17:01.000Z</published>
    <updated>2022-12-05T07:19:16.496Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="created" content="2022-02-14 16:29:22 +0000"/><meta name="source-application" content="ios.clipper.evernote"/><meta name="updated" content="2022-02-14 16:30:48 +0000"/><title>MLP CNN RNN LSTM的推导（正向和反向传播）</title></head><body><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-01.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-02.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-03.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-04.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-05.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-06.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-07.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-08.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-10.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-09.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-11.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-12.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-13.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-14.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-15.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-16.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-17.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-18.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-19.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-20.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-21.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-22.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-23.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-24.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-25.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-26.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-27.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-28.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-29.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-30.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-31.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-32.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-33.jpg" height="1491" width="2386"/></div><div><img src="/Resources/MLP%20CNN%20RNN%20LSTM%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%88%E6%AD%A3%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%89.resources/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-34.jpg" height="1491" width="2386"/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="机器学习推公式系列" scheme="https://xinrihui.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A8%E5%85%AC%E5%BC%8F%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="MLP" scheme="https://xinrihui.github.io/tags/MLP/"/>
    
    <category term="CNN" scheme="https://xinrihui.github.io/tags/CNN/"/>
    
    <category term="RNN" scheme="https://xinrihui.github.io/tags/RNN/"/>
    
    <category term="LSTM" scheme="https://xinrihui.github.io/tags/LSTM/"/>
    
    <category term="机器学习" scheme="https://xinrihui.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Word2vec 推导</title>
    <link href="https://xinrihui.github.io/2022/12/04/Word2vec%20%E5%8E%9F%E7%90%86/"/>
    <id>https://xinrihui.github.io/2022/12/04/Word2vec%20%E5%8E%9F%E7%90%86/</id>
    <published>2022-12-04T15:17:01.000Z</published>
    <updated>2022-12-04T15:35:29.543Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2022-06-22 06:59:54 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2022-12-04 15:14:15 +0000"/><title>Word2vec 原理</title></head><body><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-01.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-02.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-03.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-04.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-05.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-06.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-07.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-08.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-09.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-10.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-11.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-12.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-13.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-14.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-15.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-16.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-17.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-18.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-19.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-20.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-21.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-22.jpg" height="1491" width="2386"/></div><div><img src="/Resources/Word2vec%20%E5%8E%9F%E7%90%86.resources/%E8%AF%8D%E5%90%91%E9%87%8F-23.jpg" height="1491" width="2386"/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="机器学习推公式系列" scheme="https://xinrihui.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A8%E5%85%AC%E5%BC%8F%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="机器学习" scheme="https://xinrihui.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="word2vec" scheme="https://xinrihui.github.io/tags/word2vec/"/>
    
  </entry>
  
  <entry>
    <title>降维（PCA 和 LDA）推导</title>
    <link href="https://xinrihui.github.io/2022/12/04/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC/"/>
    <id>https://xinrihui.github.io/2022/12/04/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC/</id>
    <published>2022-12-04T15:17:01.000Z</published>
    <updated>2022-12-05T07:25:18.430Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2022-06-22 08:31:46 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2022-12-04 15:12:48 +0000"/><title>降维（PCA 和 LDA）推导</title></head><body><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-01.jpg" height="1491" width="2386"/><br/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-02.jpg" height="1491" width="2386"/><br/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-03.jpg" height="1491" width="2386"/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-04.jpg" height="1491" width="2386"/><br/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-05.jpg" height="1491" width="2386"/><br/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-06.jpg" height="1491" width="2386"/><br/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-07.jpg" height="1491" width="2386"/><br/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-08.jpg" height="1491" width="2386"/><br/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-09.jpg" height="1491" width="2386"/><br/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-10.jpg" height="1491" width="2386"/><br/></div><div><img src="/Resources/%E9%99%8D%E7%BB%B4%EF%BC%88PCA%20%E5%92%8C%20LDA%EF%BC%89%E6%8E%A8%E5%AF%BC.resources/%E9%99%8D%E7%BB%B4-11.jpg" height="1491" width="2386"/><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="机器学习推公式系列" scheme="https://xinrihui.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A8%E5%85%AC%E5%BC%8F%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="机器学习" scheme="https://xinrihui.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="PCA" scheme="https://xinrihui.github.io/tags/PCA/"/>
    
    <category term="LDA" scheme="https://xinrihui.github.io/tags/LDA/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost原理 - 稀疏感知</title>
    <link href="https://xinrihui.github.io/2022/12/04/XGBoost%E5%8E%9F%E7%90%86%20-%20%E7%A8%80%E7%96%8F%E6%84%9F%E7%9F%A5/"/>
    <id>https://xinrihui.github.io/2022/12/04/XGBoost%E5%8E%9F%E7%90%86%20-%20%E7%A8%80%E7%96%8F%E6%84%9F%E7%9F%A5/</id>
    <published>2022-12-04T15:02:24.000Z</published>
    <updated>2022-12-04T15:07:41.608Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2022-12-04 14:56:46 +0000"/><meta name="source" content="yinxiang.superNote"/><meta name="updated" content="2022-12-04 15:00:02 +0000"/><title>XGBoost原理 - 稀疏感知</title></head><body><h1>1.稀疏感知 （ Sparsity-aware Split Finding ）</h1><div><br/></div><div>通常情况下，我们人为在处理缺失值 的时候大多会选用中位数、均值或是二者的融合来对数值型特征进行填补，使用出现次数最多的类别来填补缺失的类别特征。</div><div><br/></div><div>xgboost  对缺失值（np.nan）的处理与 稀疏矩阵的处理类似：</div><div><br/></div><div>xgboost 把 0 值 也当做缺失值，若样本中的 0 值不是因为 one-hot 产生的，而是这个特征 取值的范围包含0 （eg. 特征取值范围为 [-2,2] ） 则会出现问题（需要指定  xgboost  的缺失值 为 Nan，即不让 xgboost 把 0 当做缺失值） </div><div><br/></div><div>在寻找split point的时候，不会对该特征为missing的样本进行遍历统计，只对该列特征值为non-missing的样本上对应的特征值进行遍历，通过这个技巧来减少了 为稀疏离散特征 寻找split point的时间开销。</div><div><br/></div><div>在逻辑实现上，为了保证完备性，会分别处理将missing该特征值的样本分配到左叶子结点和右叶子结点的两种情形，计算增益后选择增益大的方向进行分裂即可。</div><div><br/></div><div>Xgboost对缺失值的处理具体看下面的算法流程：</div><div><br/></div><img src="/Resources/XGBoost%E5%8E%9F%E7%90%86%20-%20%E7%A8%80%E7%96%8F%E6%84%9F%E7%9F%A5.resources/6637FAD1-7F80-4543-815B-53660C96A65F.png" height="770" width="1011"/><div>首先需要注意到两个集合：</div><ul><li><div>一个是 I, 其包含所有的样本（包括 含缺失值的样本）</div></li><li><div>Ik  是不包含空缺值样本的集合。</div></li></ul><div><br/></div><div>在计算总的G和H时用的是I , 也就说空缺值 的一阶导数和二阶导数已经包含进去了。</div><div><br/></div><div>可以看到内层循环里面有两个 for  , 这两个 for 针对的集合就是 Ik  </div><div><br/></div><div>第一个for是从把特征取值从小到大排序，然后从小到大进行扫描，这个时候在计算GR的时候是用总的G 减去GL ,这意味着把空缺样本归到了右子结点。</div><div><br/></div><div>第二个for相反过来，把空缺样本归到了左子结点。</div><div><br/></div><div>只要比较这两次最大增益出现在第一个for中还是第二个for中就可以知道对于空缺值的分裂方向，即 节点分裂的默认方向 （下图中红线 所示）， 当模型做预测时，若预测样本出现 缺失值，则在树上 根据默认方向 往下走即可。</div><img src="/Resources/XGBoost%E5%8E%9F%E7%90%86%20-%20%E7%A8%80%E7%96%8F%E6%84%9F%E7%9F%A5.resources/B2781204-77FA-4E14-8AA6-EFC8529FDB74.png" height="454" width="1030"/><h1>2.高维稀疏(离散)向量 </h1><div><br/></div><h2>2.1 高维稀疏离散向量的存储</h2><div><br/></div><div>利用字典可以只存 非零值，例如 Compressed Sparse Column (CSC)  </div><div><br/></div><div>详见 本笔记本：系统设计1：分块并行、缓存优化和Blocks for Out-of-core</div><div><br/></div><div><br/></div><h2>2.2 类别特征编码</h2><div><br/></div><div>大部分模型无法直接处理类别型数据的，即离散特征。但是，决策树中的分类树ID3, C4.5,  Cart 可以处理类别型数据。对于类别特征，可以采用以下 2种编码方式：</div><div><br/></div><div>（1）数值编码</div><div><br/></div><div>有的类别型特征 具有 大小关系（可比类型），</div><div><br/></div><div>eg1. 年龄特征 的 取值范围为 [ 童年 少年 中年 老年 ] ， 那么我把 四个特征值分别编码为 [ 0,1,2,3] 是可行的，因为 小于 中年 可以是   [童年, 少年]</div><div><br/></div><div>eg.2 信贷情况 ，特征的所有取值为[一般, 好, 非常好]</div><div><br/></div><div>eg.3 电影评分等级，特征的所有取值为[1, 2, 3, 4, 5]</div><p style="--en-paragraph:true;text-align:start;"><br/></p><div>（2）one-hot 编码（稀疏编码）</div><div><br/></div><div>大部分的类别型特征没有大小关系（不可比类型）</div><div><br/></div><div>例如 ：运动品牌 特征，特征的所有取值为 [ 耐克，阿迪，李宁 ]。若将 这 3个特征值分别编码为（0,1,2）是不对的，因为这样已经不公平的定义了三者之间的距离，阿迪和耐克的距离是1，而李宁和耐克的距离是2，这样会导致模型错误地划分特征空间。</div><div><br/></div><div>正确的划分方法是，将 1个特征拆成 3个特征， 即  feature1= 是否是耐克 ，feature2= 是否是阿迪，feature3=是否是李宁，这相当于把低维的特征空间映射到高维 （one-hot 编码）：</div><div><br/></div><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:520px;" width="520px"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>feature1</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>feature2</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>feature3</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>耐克</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>0</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>0</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>阿迪</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>0</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>0</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>李宁</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>0</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>0</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1</div></td></tr></tbody></table><div><br/></div><div>（3）特征交叉（组合）</div><div><br/></div><div><br/></div><h2> 2.3 数值类型特征的处理</h2><div><br/></div><div>1.归一化（normalization） 让模型收敛</div><div><br/></div><div>2.分桶改变特征值的分布</div><div><br/></div><div>比如图 5 就显示了 Sparrow Recsys 中编号在前 1000 的电影平均评分分布。你可以很明显地看到，由于人们打分有“中庸偏上”的倾向，因此评分大量集中在 3.5 的附近，而且越靠近 3.5 的密度越大。这对于模型学习来说也不是一个好的现象，因为特征的区分度并不高。</div><div><br/></div><div><br/></div><a href="/Resources/XGBoost%E5%8E%9F%E7%90%86%20-%20%E7%A8%80%E7%96%8F%E6%84%9F%E7%9F%A5.resources/59FCAE60-F204-4B92-81A3-58C01F92BFB4.webp">59FCAE60-F204-4B92-81A3-58C01F92BFB4.webp</a><div><br/></div><div>                            图5 电影的平均评分分布</div><div><br/></div><div><br/></div><div>这该怎么办呢？我们经常会用分桶的方式来解决特征值分布极不均匀的问题。所谓“分桶（Bucketing）”，就是将样本按照某特征的值从高到低排序，然后按照桶的数量找到分位数，将样本分到各自的桶中，再用桶 ID 作为特征值。</div><div><br/></div><div>对于数值型特征的处理方法还远不止于此，在经典的 YouTube 深度推荐模型中，我们就可以看到一些很有意思的处理方法。比如，在处理观看时间间隔（time since last watch）和视频曝光量（#previous impressions）这两个特征的时，YouTube 模型对它们进行归一化后，又将它们各自处理成了三个特征（图 6 中红框内的部分），分别是原特征值 x，特征值的平方x^2，以及特征值的开方，这又是为什么呢？</div><div><br/></div><div><br/></div><div><br/></div><a href="/Resources/XGBoost%E5%8E%9F%E7%90%86%20-%20%E7%A8%80%E7%96%8F%E6%84%9F%E7%9F%A5.resources/97ED9E74-F65F-4A1D-AD93-6D330D852151.webp">97ED9E74-F65F-4A1D-AD93-6D330D852151.webp</a><div><br/></div><div>无论是平方还是开方操作，改变的还是这个特征值的分布，这些操作与分桶操作一样，都是希望通过改变特征的分布，让模型能够更好地学习到特征内包含的有价值信息。但由于我们没法通过人工的经验判断哪种特征处理方式更好，所以索性把它们都输入模型，让模型来做选择。</div><div><br/></div><h2>2.4 高维稀疏带来的问题</h2><div><br/></div><div>如果类别过多，如商品ID，在one-hot处理后数据会变得过于稀疏，大大增加了训练集的大小，浪费计算资源。另外，对于线上系统，我们追求低延迟和高吞吐量，因此 在保证模型效果不变的前提下，模型推理时 用的特征越少越好，解决思路有：</div><div><br/></div><div>（1） 降维（PCA,  LDA）</div><div><br/></div><div>（2）Embedding </div><div>         </div><div>        eg1. word2vec 就是将 高维稀疏的one hot 向量 映射到 低维稠密空间 </div><div>        </div><div>        eg2. 推荐系统中 Item的Embedding 和 user 的Embedding</div><div><br/></div><div>（3）使用 LR 或者 MLP 并加上 L1 正则化，在训练时，L1 正则化 会使得 某些特征的权重变为0，效果与降维相同</div><div><br/></div><div>（4）使用 决策树 模型 做特征筛选，挑出 能让 信息熵 下降最多的特征</div><div><br/></div><div>（5）Lightgbm 针对高维特征的问题提出了 互斥特征捆绑算法（Exclusive Feature Bundling，EFB），对稀疏特征进行无损合并。</div><div><br/></div><div><br/></div><h2>2.5 xgboost 真的不 适合 高维稀疏特征么</h2><div><br/></div><div>1.对一个 类别特征，它的取值范围是 [ 0,1,2,..., 100w ]，样本一共10w 条</div><div>    </div><ul><li><div>若直接 对它做数值编码 ，此时只有1维特征，考虑 xgboost 找切分点的 次数为：100w</div></li></ul><div>    </div><ul><li><div>若将其 one-hot 化，此时特征维度变为100w维， 对于 每一个维度大部分特征值都为0（只有 几个样本的值为1）， 因为 xgboost 的稀疏感知， 0不会作为切分点，所以对每一个维度xgboost 找切分点的 次数为1  ， 整体找切分点的 次数同样为：100w</div></li></ul><div>    </div><div>    因此，对类别特征进行稀疏编码后 不会增加 xgboost 训练的代价</div><div><br/></div><div>2.xgboost 适合 稀疏（离散）的特征，它怕的是 浮点运算，因为CPU 适合做逻辑计算而不是浮点运算；而 神经网络由于 GPU 对矩阵运算（浮点运算）的加速，更适合连续（稠密）的特征。</div><div><br/></div><div>3.神经网络的结构特点不利于稀疏特征向量的处理</div><div><br/></div><div>这个问题涉及到整个 Embedding 技术的意义。</div><div>一方面，如果我们深入到神经网络的梯度下降学习过程就会发现，特征过于稀疏会导致整个网络的收敛非常慢，因为每一个样本的学习只有极少数的权重会得到更新，这在样本数量有限的情况下会导致模型不收敛。</div><div>另一个方面，One-hot 类稀疏特征的维度往往非常地大，可能会达到千万甚至亿的级别，如果直接连接进入深度学习网络，那整个模型的参数数量会非常庞大，这对于一般公司的算力开销来说都是吃不消的。</div><div>因此，我们往往会先通过 Embedding 把原始稀疏特征稠密化，然后再输入复杂的深度学习网络进行训练，这相当于把原始特征向量跟上层复杂深度学习网络做一个隔离。</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><h1>引用</h1><div><br/></div><div><a href="https://tech.meituan.com/2019/08/15/problems-caused-by-missing-xgboost-values-and-their-in-depth-analysis.html" rev="en_rl_none">https://tech.meituan.com/2019/08/15/problems-caused-by-missing-xgboost-values-and-their-in-depth-analysis.html</a></div><div><a href="https://www.jianshu.com/p/d07f0b0726da" rev="en_rl_none">https://www.jianshu.com/p/d07f0b0726da</a></div><div><a href="https://zhuanlan.zhihu.com/p/366952043" rev="en_rl_none">https://zhuanlan.zhihu.com/p/366952043</a></div><div><a href="https://www.zhihu.com/question/336110178/answer/823523924" rev="en_rl_none">https://www.zhihu.com/question/336110178/answer/823523924</a></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="XGBoost 系列" scheme="https://xinrihui.github.io/categories/XGBoost-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="机器学习" scheme="https://xinrihui.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="xgboost" scheme="https://xinrihui.github.io/tags/xgboost/"/>
    
    <category term="源码分析" scheme="https://xinrihui.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost 源码分析 3</title>
    <link href="https://xinrihui.github.io/2022/12/04/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%203/"/>
    <id>https://xinrihui.github.io/2022/12/04/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%203/</id>
    <published>2022-12-04T14:46:34.000Z</published>
    <updated>2022-12-04T15:07:41.593Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2021-09-19 08:46:03 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2021-10-11 02:00:54 +0000"/><title>XGBoost 源码分析 3</title></head><body><div><span style="font-weight: bold;">5.DMatrix 实现</span></div><div><br/></div><div>1.读取训练数据</div><div><br/></div><div>src/cli_main.cc -&gt; void CLITrain() {</div><div><br/></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%203.resources/85B91CEC-3288-4A0F-AFD1-2C0663DF573B.png" height="529" width="1015"/></div><div><br/></div><div>2.Load 函数</div><div><br/></div><div>src/data/data.cc -&gt; DMatrix::Load(</div><div><br/></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%203.resources/08DD226F-27E3-4CB0-868A-69DBCF0116F3.png" height="724" width="1198"/></div><div><br/></div><div><br/></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%203.resources/CA404C32-DE7D-4011-A371-04C991B4F1E5.png" height="221" width="1099"/></div><div><br/></div><div>3.Create 函数</div><div><br/></div><div>src/data/data.cc -> &nbsp;&nbsp;DMatrix::Create(</div><div><br/></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%203.resources/B5BCD1C4-0974-4484-8215-A185A2C68ADC.png" height="222" width="1003"/></div><div><br/></div><div>4.SimpleDMatrix 函数</div><div><br/></div><div>src/data/simple_dmatrix.cc -&gt; SimpleDMatrix::SimpleDMatrix()</div><div><br/></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%203.resources/5C697217-6D01-4AC9-BBCF-B67D435FFA40.png" height="615" width="1037"/></div><div><br/></div><div><br/></div><div>带注释的源码详见 github</div><div><a href="https://github.com/Xinrihui/xgboost-code-review">https://github.com/Xinrihui/xgboost-code-review</a></div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://blog.csdn.net/matrix_zzl/article/details/78699605">https://blog.csdn.net/matrix_zzl/article/details/78699605</a></div><div><a href="https://blog.csdn.net/matrix_zzl/article/details/78705753?spm=1001.2014.3001.5501">https://blog.csdn.net/matrix_zzl/article/details/78705753?spm=1001.2014.3001.5501</a></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="XGBoost 系列" scheme="https://xinrihui.github.io/categories/XGBoost-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="xgboost" scheme="https://xinrihui.github.io/tags/xgboost/"/>
    
    <category term="源码分析" scheme="https://xinrihui.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>xgboost 源码调试</title>
    <link href="https://xinrihui.github.io/2022/12/04/xgboost%20%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95/"/>
    <id>https://xinrihui.github.io/2022/12/04/xgboost%20%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95/</id>
    <published>2022-12-04T14:46:31.000Z</published>
    <updated>2022-12-04T15:07:41.612Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2021-09-20 04:32:19 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="https://xgboost.readthedocs.io/en/latest/build.html#building-on-windows"/><meta name="updated" content="2021-10-10 14:29:42 +0000"/><title>xgboost 源码调试</title></head><body><div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-weight: bold; font-size: 12pt;">1.代码下载</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">下载github代码：</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">git clone --recursive</span> <a href="https://github.com/dmlc/xgboost" style="font-size: 12pt;">https://github.com/dmlc/xgboost</a></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="color: unset; font-family: unset; font-size: 12pt;">加上参数–recursive，会把xgboost依赖的submodule都clone下来，并放在xgboost主目录下。</span></div><div><span style="color: unset; font-family: unset; font-size: 12pt;">xgboost依赖以下4个模块：</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">dmlc-core：用于支撑DMLC机器学习项目的公共代码库</span></div><div><span style="font-size: 12pt;">rabit：封装了高度可依赖的Allreduce与Broadcast接口，用于分布式消息同步</span></div><div><span style="font-size: 12pt;">nccl：优化后的多GPU通信基础库</span></div><div><span style="font-size: 12pt;">cub：CUDA编程相关库</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-weight: bold; font-size: 12pt;">2.编译项目</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">mkdir build</span></div><div><span style="font-size: 12pt;">cd build</span></div><div><span style="font-size: 12pt;">cmake .. -G"Visual Studio 14 2015 Win64"</span></div><div><span style="font-size: 12pt;"># for VS15: cmake .. -G"Visual Studio 15 2017" -A x64# for VS16: cmake .. -G"Visual Studio 16 2019" -A x64</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">生成 .sln&nbsp;&nbsp;后缀的项目文件 (xgboost.sln)</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">3.使用 visual studio&nbsp;&nbsp;打开项目</span> <span style="font-size: 12pt;">(&nbsp;&nbsp; xgboost.sln&nbsp;&nbsp;)</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">（1）从 release&nbsp;&nbsp;模式 切换到 debug&nbsp;&nbsp;模式</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">（Relese版本无法看debug信息）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">解决方案管理器 -&gt;</span></div><div><span style="font-size: 12pt;">(右键点击目标)项目--&gt;属性--&gt;配置管理器--&gt;活动解决方案配置--&gt;新建--&gt;Debug</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">项目--&gt;属性--&gt;配置管理器--&gt;活动解决方案平台--&gt;X64</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">项目 --&gt; 属性 --&gt; C/C++ --&gt; 常规 --&gt; 调试信息格式 --&gt; 程序数据库 (/Zi) 。</span></div><div><span style="font-size: 12pt;">项目 --&gt; 属性 --&gt; C/C++ --&gt; 常规 --&gt; 优化 --&gt; 优化 --&gt; 已禁用 (/Od)。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/xgboost%20%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95.resources/101A99A1-D311-42B9-8C63-FBC385222E08.png" height="748" width="1627"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">注意：是每个项目都要右键点击属性修改（如果有C/C++这个选项的话，因为有的项目点击属性后没有C++或者连接器，那就不用改了)</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">（2）添加 include 路径，解决代码中 #include&nbsp;&nbsp;找不到报错的问题</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">项目 --&gt; 属性 --&gt; C/C++ --&gt; 附加包含目录。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">增加了三项：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$(SolutionDir)..\include\</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$(SolutionDir)..\dmlc-core\include\</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$(SolutionDir)..\rabit\include\</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-weight: bold; font-size: 12pt;">4.运行 CLI (C++接口 )&nbsp;&nbsp;的demo&nbsp;&nbsp;</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">（1）进入 xgboost\demo\CLI\binary_classification&nbsp;&nbsp;目录</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">cmd下运行 python&nbsp;&nbsp;脚本 生成数据</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">python mapfeat.py</span></div><div><span style="font-size: 12pt;">python mknfold.py agaricus.txt 1</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">其中mushroom.conf是要作为cli_main.cc的主函数参数传入的（其中数据路径的参数改成绝对路径不加引号）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">（2） 右键xgboost项目-&gt;属性-&gt;配置属性-&gt;调试-&gt;命令行参数：mushroom.conf的绝对路径</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">调试命令行设置：项目 --&gt; 属性 --&gt;调试--&gt;命令行参数 。输入配置文件所在路径："E:\Machine Learning Projects\Libs\xgboost\xgboost\demo\CLI\binary_classification\mushroom.conf"</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="color: rgb(255, 0, 0); font-size: 12pt;">注意路径必须采用&nbsp;&nbsp;双引号&nbsp;&nbsp;包起来：</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/xgboost%20%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95.resources/7BDDB362-CAA8-4C75-AB76-947B6327A326.png" height="684" width="1108"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">（3）程序中打断点，debug运行xgboost项目，注意只运行 runxgboost&nbsp;&nbsp;项目，不要 debug&nbsp;&nbsp;解决方案中的其他项目，即&nbsp;&nbsp;右键解决方案 ->&nbsp;&nbsp;属性，然后选择&nbsp;&nbsp;单项目启动（runxgboost）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/xgboost%20%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95.resources/ED2F91F2-40B3-4958-B7D4-BF55B1A08B19.png" height="684" width="1106"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">（4）点击调试按钮之后，出现File not found，导致调试终止</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">这里指的是agaricus.txt 文件找不到。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">解决方法：将agaricus.txt&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;agaricus.txt.test&nbsp;&nbsp;&nbsp;&nbsp;agaricus.txt.train 三个文件全都拷贝到和xgboost.sln同级目录即可即可</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-weight: bold; font-size: 12pt;">5.问题</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">1.&nbsp;&nbsp;问题：fatal error C1083: 无法打开包括文件: “xgboost/data.h”</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">这种错误就是找不到data.h文件，一般是inclue路径没设置对。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">2.&nbsp;&nbsp;问题：LINK : fatal error LNK1561: 必须定义入口点 .&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">每一个应用程序(.exe文件)都需要一个程序入口点，就是main()函数，所以，自然，如果一个.exe文件没有main()函数，那么编译时，编译器就会报错：LINK 1561。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="color: unset; font-family: unset; font-size: 12pt;">如果是.exe.文件，就需要检查自己的程序中是否有main()函数，没有的话，就要加上这个main()函数；</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">如果不需要编写.exe应用程序，那自然就可以将程序编译为静态链接库、或者动态链接库。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">解决方法：项目 --&gt; 属性 --&gt;常规--&gt;配置类型。</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">库项目 dmlccore、 rabit 、objxgboost 、xgboost 设置为&nbsp;&nbsp;动态库（可以进入调试）</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">入口项目 runxgboost 设置为.exe&nbsp;&nbsp;</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">即不是&nbsp;&nbsp;程序入口 也不是&nbsp;&nbsp;库&nbsp;&nbsp;的项目可以&nbsp;&nbsp;配置为 “生成文件”</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/xgboost%20%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95.resources/1995CC35-558B-412D-B9BA-6589B45EAD2D.png" height="684" width="1106"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">3.问题： fatal error LNK1104: 无法打开文件“.........................\xgboost\build\objxgboost.dir\Debug\c_api.obj”</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">解决方法：在目录里搜“c_api.obj”，然后建立文件夹“.........................\xgboost\build\objxgboost.dir\Debug，然后将“c_api.obj”所在的目录中所有的文件都拷贝到“.........................\xgboost\build\objxgboost.dir\Debug 。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">4.&nbsp;&nbsp;问题：点击调试按钮之后，出现File not found，导致调试终止</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">报错信息：E:\\Machine Learning Projects\\Libs\\xgboost\\xgboost\\src\\data\\data.cc:765: Encountered parser error</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">这里指的是agaricus.txt 文件找不到。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">解决方法：将agaricus.txt&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;agaricus.txt.test&nbsp;&nbsp;&nbsp;&nbsp;agaricus.txt.train 三个文件全都拷贝到和 xgboost.sln 同级目录即可</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">5.问题：在项目A调试时 进入不了&nbsp;&nbsp;另一个 项目B的代码</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">（1）B 必须设置为&nbsp;&nbsp;动态链接库</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">（2）在 配置属性-&gt;C/C++-&gt;常规-&gt;调试信息格式 选择 ：用于“编辑并继续”的程序数据库(/ZI)</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/xgboost%20%E6%BA%90%E7%A0%81%E8%B0%83%E8%AF%95.resources/C9A908CC-6C26-4B5F-B15C-8AB9F29D51F6.png" height="684" width="1106"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-weight: bold; font-size: 12pt;">引用</span></div><div><a href="https://blog.csdn.net/matrix_zzl/article/details/78571349" style="font-size: 12pt;">https://blog.csdn.net/matrix_zzl/article/details/78571349</a></div><div><a href="https://xgboost.readthedocs.io/en/latest/build.html#building-on-windows" style="font-size: 12pt;">https://xgboost.readthedocs.io/en/latest/build.html#building-on-windows</a></div><div><a href="https://blog.csdn.net/zzzz_123123/article/details/103812161" style="font-size: 12pt;">https://blog.csdn.net/zzzz_123123/article/details/103812161</a><span style="font-size: 12pt;">（ windows&nbsp;&nbsp;下）</span></div><div><a href="https://github.com/dmlc/xgboost/tree/master/demo/CLI/binary_classification" style="font-size: 12pt;">https://github.com/dmlc/xgboost/tree/master/demo/CLI/binary_classification</a></div><div><font style="font-size: 12pt;"><br/></font></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="XGBoost 系列" scheme="https://xinrihui.github.io/categories/XGBoost-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="xgboost" scheme="https://xinrihui.github.io/tags/xgboost/"/>
    
    <category term="源码分析" scheme="https://xinrihui.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>小灰灰信息检索系统 - 附录 文件的存储管理</title>
    <link href="https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%20%E9%99%84%E5%BD%95%20%E6%96%87%E4%BB%B6%E7%9A%84%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/"/>
    <id>https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%20%E9%99%84%E5%BD%95%20%E6%96%87%E4%BB%B6%E7%9A%84%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/</id>
    <published>2022-12-04T14:27:29.000Z</published>
    <updated>2022-12-04T14:29:16.418Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-01-27 10:04:02 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 14:05:04 +0000"/><title>小灰灰信息检索系统 - 附录 文件的存储管理</title></head><body><div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：文件存储使用定长字段还是使用 变长字段 配 分隔符+换行符</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">变长字段 配 分隔符+换行符</span></div><ul><li><div><span style="font-size: 12pt;">字段的内容中 不能存在 分隔符 和 换行符，否则 切分行 和 切分 字段  的时候 会出错；</span></div></li></ul><div><span style="font-size: 12pt;">可以使用 </span> <span style="font-size: 12pt; font-weight: bold;">定界符</span><span style="font-size: 12pt;">（delimiter）来 界定字段的内容，并对 字段内容中的 特殊字符 进行转义处理，CSV 文件的规则为：</span></div><div><br/></div><div><span style="font-size: 12pt;">（1） 每条记录占一行 ，用换行符（\r\n）分隔；行中的字段 以逗号为分隔符，逗号前后的空格会被忽略</span></div><div><span style="font-size: 12pt;">（2）字段中包含有 逗号 、换行符 中的任意 一个 ，该字段 必须用</span> <span style="font-size: 12pt; font-weight: bold;">双引号（定界符）</span> <span style="font-size: 12pt;">括起来</span></div><div><span style="font-size: 12pt;">（3）字段前后包含有空格，该字段必须用 双引号括起来</span></div><div><span style="font-size: 12pt;">（4）字段中的双引号 用两个双引号 表示（转义）</span></div><div><br/></div><div><span style="font-size: 12pt;">我们在 csv 文件 中 填写的内容如下：    </span></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td height="18" style="height: 13.8pt; width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">1001</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">    abc</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">  ,abc  "c"  </span></div></td></tr><tr><td height="18" style="height: 13.8pt; width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">1002</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;"> a,b</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td></tr></tbody></table><div><span style="font-size: 12pt;">实际的 csv 文件存储为：</span></div><div><span style="font-size: 12pt;">1001,    abc,"  ,abc  ""c""  "</span></div><div><span style="font-size: 12pt;">1002," a,b",</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%20%E9%99%84%E5%BD%95%20%E6%96%87%E4%BB%B6%E7%9A%84%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86.resources/A79FCE2F-86FC-4B31-92C7-6E5997FABF2A.png" height="128" width="838"/><br/></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">灵活性好，字段的长度 可以任意变化 ，但是 一般 数据库在 建表时 会给 字段 设定一个 字节长度的上限 （与数据库的 块的大小有关）</span></div></li><li><div><span style="font-size: 12pt;">直接查看 文件内容  十分方便</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">定长字段 </span></div><ul><li><div><span style="font-size: 12pt;">字段的内容 可以是任意字符</span></div></li><li><div><span style="font-size: 12pt;">灵活性较差，字段定义的过大 将浪费存储空间，字段定义的过短，可能以后放不下；可以采用</span> <span style="font-size: 12pt; font-weight: bold;">字段的字节长度（定长）+字段内容</span><span style="font-size: 12pt;"> 来存储 长度变化非常大的字段</span></div></li><li><div><span style="font-size: 12pt;">没有 分隔符 + 换行符， 直接查看 文件的内容 不便 </span></div></li><li><div><span style="font-size: 12pt;">每一行定长，行中的每一个字段都定长，可以快速的通过文件指针 取到 指定的行 和指定的字段，eg. 第10行中的 第1个字段。</span></div></li></ul><div><span style="font-size: 12pt;">        而 采用变长字段 则肯能 要把 整个文件读入内存 才能找到 指定的行和字段。 </span></div><div><span style="font-size: 12pt;">        因此，关系数据库 采用 定长字段 而 NoSQL  eg. hive 采用 变长字段 </span></div><div><span style="font-size: 12pt;"><br/></span></div><div><br/></div><hr/><div><br/></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：如何在文本中存储小数类型的字段</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">使用 保留的小数位数 + 不带 小数点的 字节数组 表示</span></div></li></ul><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">小数位数Int（1B）</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">小数内容 Int（8B）</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">2</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">12345</span></div></td></tr></tbody></table><div><span style="font-size: 12pt;">读取的时候 ，补上小数点即可： 123.45</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">使用 字符串 表示：</span></div></li></ul><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/></colgroup><tbody><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">小数 string（16B）</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">123.45</span></div></td></tr></tbody></table><div><span style="font-size: 12pt;">综上，在文本中 以字节存储  只有两种类型可选：（1）整数类型 ，1B 可以表示 0-256 范围的整数 ；（2）字符类型，1B 表示一个 字符（以ASCII 编码）   </span></div></div><hr/><hr/><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="从零开始搭建搜索引擎" scheme="https://xinrihui.github.io/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
    <category term="倒排索引" scheme="https://xinrihui.github.io/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    
    <category term="bm25" scheme="https://xinrihui.github.io/tags/bm25/"/>
    
    <category term="tf-idf" scheme="https://xinrihui.github.io/tags/tf-idf/"/>
    
  </entry>
  
  <entry>
    <title>小灰灰信息检索系统 - 5.查询</title>
    <link href="https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%205.%E6%9F%A5%E8%AF%A2/"/>
    <id>https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%205.%E6%9F%A5%E8%AF%A2/</id>
    <published>2022-12-04T14:27:28.000Z</published>
    <updated>2022-12-04T14:29:16.412Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-01-27 10:28:18 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 13:59:55 +0000"/><title>小灰灰信息检索系统 - 5.查询</title></head><body><div><div><div><span style="font-size: 12pt; color: unset; font-family: unset;">前面三个阶段的处理，只是为了最后的查询做铺垫。因此，现在我们就要利用之前产生的几个文件，来实现最终的用户搜索功能。</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">doc_id.bin：记录网页链接和编号之间的对应关系。</span></div></li><li><div><span style="font-size: 12pt;">term_id.bin：记录单词和编号之间的对应关系。</span></div></li><li><div><span style="font-size: 12pt;">index.bin：倒排索引文件，记录每个单词编号以及对应包含它的网页编号列表。</span></div></li><li><div><span style="font-size: 12pt;">term_offsert.bin：记录每个单词编号在倒排索引文件中的偏移位置。</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">这四个文件中，除了倒排索引文件（index.bin）比较大之外，其他的都比较小。为了方便快速查找数据，我们将其他三个文件都加载到内存中，并且组织成散列表这种数据结构。</span></div><div><br/></div><div><span style="font-size: 12pt;">当用户在搜索框中，输入某个查询文本的时候，我们先对用户输入的文本进行分词处理。假设分分词之后，我们得到 k 个单词。</span></div><div><br/></div><div><span style="font-size: 12pt;">我们拿这 k 个单词，去 term_id.bin 对应的散列表中，查找对应的单词编号。经过这个查询之后，我们得到了这 k 个单词对应的单词编号。</span></div><div><br/></div><div><span style="font-size: 12pt;">我们拿这 k 个单词编号，去 term_offset.bin 对应的散列表中，查找每个单词编号在倒排索引文件中的偏移位置。经过这个查询之后，我们得到了 k 个偏移位置。</span></div><div><br/></div><div><span style="font-size: 12pt;">我们拿这 k 个偏移位置，去倒排索引（index.bin）中，查找 k 个单词对应的包含它的网页编号列表。经过这一步查询之后，我们得到了 k 个网页编号列表。</span></div><div><br/></div><div><span style="font-size: 12pt;">我们针对这 k 个网页编号列表，统计每个网页编号出现的次数。具体到实现层面，我们可以借助散列表来进行统计。统计得到的结果，我们按照出现次数的多少，从小到大排序。出现次数越多，说明包含越多的用户查询单词（用户输入的搜索文本，经过分词之后的单词）。</span></div><div><br/></div><div><span style="font-size: 12pt;">经过这一系列查询，我们就得到了一组排好序的网页编号。我们拿着网页编号，去 doc_id.bin 文件中查找对应的网页链接，分页显示给用户就可以了。</span></div><div><br/></div><div><span style="font-size: 16px;"><br/></span></div><hr/><div><span style="font-size: 16px;"><br/></span></div><div><span style="font-size: 12pt; font-weight: bold;">1.方案A</span><span style="font-size: 12pt; font-weight: bold;">（续上述方案A）：</span></div><div><br/></div><div><span style="font-size: 12pt;">查询层 即将 使用的 前面 准备的文件</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">doc_raw.bin：原始网页的 文件</span></div></li><li><div><span style="font-size: 12pt;">doc_raw_offset.bin ：记录 每一个文档的 ID 和它在 doc_raw.bin 中的 偏移位置</span></div></li><li><div><span style="font-size: 12pt;">doc_raw_offset.bin ： 记录 每一个 文档ID 和它对应的 url ，根据 文档ID 查找得到 文档的url</span></div></li><li><div><span style="font-size: 12pt;">term_id.bin：记录单词 和 编号之间的对应关系</span></div></li><li><div><span style="font-size: 12pt;">inver_term_id.bin： 记录 单词编号 和 单词的关系</span></div></li><li><div><span style="font-size: 12pt;">index.bin：倒排索引文件，记录每个单词编号以及对应包含它的网页编号列表</span></div></li><li><div><span style="font-size: 12pt;">term_offsert.bin：记录每个单词编号在倒排索引文件中的偏移位置</span></div></li><li><div><span style="font-size: 12pt;">doc_termsNums.bin: 文档的词项 总数文件 ,每一个文档的  词项的总数 （可以作为 文档的长度）</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">（1）用户查询解析 ，提取关键词项后  在倒排索引中检索关键词项，取得 候选网页文档</span></div><div><br/></div><ol><li><div><span style="font-size: 12pt;">当用户在搜索框中，输入某个查询文本的时候，我们先对用户输入的文本进行分词处理 后，并过滤 stop_words后 得到 k 个 词项（关键词）。</span></div></li><li><div><span style="font-size: 12pt;">拿这 k 个单词，去 term_id.bin 对应的散列表中，查找对应的单词编号。</span></div></li><li><div><span style="font-size: 12pt;">拿这 k 个单词编号，去 term_offset.bin 对应的散列表中，查找每个单词编号在倒排索引文件中的偏移位置。</span></div></li><li><div><span style="font-size: 12pt;">拿这 k 个偏移位置，去倒排索引 index.bin 中，查找 k 个单词 对应的包含 它的网页编号列表。最后 我们得到了  n 个 候选 网页文档 集合。</span></div></li></ol><div><br/></div><div><span style="font-size: 12pt;">倒排索引</span></div><div><span style="font-size: 12pt;">termA -&gt; doc1, doc2 , doc3</span></div><div><span style="font-size: 12pt;">termB  -&gt; doc2, doc4</span></div><div><span style="font-size: 12pt;">termC  -&gt; doc5</span></div><div><br/></div><div><span style="font-size: 12pt;">用户 查询的 关键 词项：{ termA , termB}</span></div><div><span style="font-size: 12pt;">候选网页文档 集合 :  {doc1, doc2 , doc3, doc4 }</span></div><div><br/></div><div><span style="font-size: 12pt;">（2）对 候选文档集合 利用 信息检索模型（向量空间模型） 进行打分并排序</span></div><div><br/></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%205.%E6%9F%A5%E8%AF%A2.resources/0639DAF8-2A83-4A91-A786-1329F4569DF8.png" height="436" width="571"/><br/></div><div>（《信息检索导论》-&gt; chapter7 -&gt;7.1）</div><div><br/></div><div>遍历每一个查询词，对查询词对应的 倒排记录表（posting list）中的每一个 ( 文档 , tf 值 ) 对 的 tf 值累加到 文档的分数向量(Scores) 中</div><div><br/></div><div>算法结束后，文档分数 Scores = [<span style="font-size: 12pt;">W1, </span><span style="font-size: 12pt;">W2, </span><span style="font-size: 12pt;">W3, </span> <span style="font-size: 12pt;">W4</span>]</div><div>其中，</div><div><span style="font-size: 12pt;">对 doc1 的打分为：</span></div><div><span style="font-size: 12pt;">W1= w( termA ,doc1) + w( termB , doc1 )   （ termB 未在 doc1 中出现过 ，第二项为 0 ）</span></div><div><br/></div><div><span style="font-size: 12pt;">对 doc2 的打分为：</span></div><div><span style="font-size: 12pt;">W2= w( termA ,doc2) + w( termB , doc2 ) </span></div><div><br/></div><div><span style="font-size: 12pt;">其中 w ( term , doc) 可以 有多种选择 ，如 tf-idf 和 BM25</span></div><div><br/></div><div><br/></div><ul><li><div><span style="font-size: 12pt; font-weight: bold;">TF-IDF</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">w( termA ,doc1) = termA </span><span style="font-size: 12pt; color: rgb(255, 0, 0);">在doc1 中的词频</span> <span style="font-size: 12pt; color: rgb(255, 0, 0);">TF</span><span style="font-size: 12pt;">  *  termA  的逆文档频率 IDF</span></div><div><br/></div><div><span style="font-size: 12pt;">*注意：此处的 词频为 该词在 文档中的频率 而不是 该词在整个语料库中的频率</span></div><div><br/></div><div><span style="font-size: 12pt;">逆文档频率（IDF）=log（ 语料库文档总数/（包含该词的文档数+1）），之所以要+1是为了防止分母为0。由此可见，当一个词被越多的文档包含，则IDF值就越小，也就是所这个词很常见，不是最重要的能区分文章特性的关键词。</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt; font-weight: bold;">BM25</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">给定一个查询Q和一篇文档d，d对Q的BM25得分公式为：</span></div><div><br/></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%205.%E6%9F%A5%E8%AF%A2.resources/8EC98291-3A72-4F0E-87E0-A8D280271E2F.png" height="563" width="962"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">第一个公式 是外部公式，一个查询Q可能包含多个词项，比如“苹果手机”就包含“苹果”和“手机”两个词项，我们需要分别计算“苹果”和“手机”对某个文档d的贡献分数w(t,d)，然后将他们加起来就是整个文档d相对于查询Q的得分。</span></div><div><br/></div><div><span style="font-size: 12pt;">第二个公式 就是计算某个词项t在文档d中的得分，它包括三个部分：</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">第一个部分 是词项t在查询Q中的得分，比如查询“中国人说中国话”中“中国”出现了两次，此时 qtf=2，说明这个查询希望找到的文档和“中国”更相关，“中国”的权重应该更大，但是通常情况下，查询Q都很短，而且不太可能包含相同的词项，所以这个因子是一个常数，我们在实现的时候可以忽略。</span></div></li></ul><div><br/></div><ul><li><div><span style="font-size: 12pt;">第二部分 类似于 TFIDF 模型中的 TF 项。也就是说某个 词项t 在 文档d 中出现次数越多，则 t 越重要，但是文档长度越长，tf也倾向于变大，所以使用文档长度除以平均长度：</span> <span style="font-size: 12pt; color: rgb(255, 0, 0);">ld / avg_l</span><span style="font-size: 12pt;">  起到某种归一化的效果，k1 和 b 是可调参数。</span></div></li></ul><div><br/></div><ul><li><div><span style="font-size: 12pt;">第三部分 类似于 TFIDF 模型中的 IDF 项。也就是说虽然“的”、“地”、“得”等停用词在某文档d中出现的次数很多，但是他们在很多文档中都出现过，所以这些词对d的贡献分并不高，接近于0；反而那些很稀有的词如”糖尿病“能够很好的区分不同文档，这些词对文档的贡献分应该较高。</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">所以根据BM25公式，我们可以很快计算出不同 文档t 对 查询Q 的得分情况，然后按得分高低排序给出结果。</span></div><div><br/></div></div><div><br/></div><div><br/></div><hr/><div><br/></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：在结果显示的时候 增加 摘要信息和网页快照。</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">摘要信息</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">增加 summary.bin 和 summary_offset.bin。在抽取网页文本信息后，取出前 80-160 个字作为摘要，写入到 summary.bin，并将偏移位置写入到 summary_offset.bin。</span></div><div><br/></div><div><span style="font-size: 12pt;">summary.bin 格式：</span></div><div><span style="font-size: 12pt;">doc_id \t summary_size \t summary \r\n\r\n</span></div><div><span style="font-size: 12pt;">summary_offset.bin 格式：</span></div><div><span style="font-size: 12pt;">doc_id \t offset \r\n</span></div><div><span style="font-size: 12pt;">Google 搜索结果中显示的摘要是搜索词附近的文本。如果要实现这种效果，可以保存全部网页文本，构建搜索结果时，在网页文本中查找搜索词位置，截取搜索词附近文本。</span></div><div><br/></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">网页快照</span></div></li></ul><div><span style="font-size: 12pt;">可以把 doc_raw.bin 当作快照，增加 doc_raw_offset.bin 记录 doc_id 在 doc_raw.bin 中的偏移位置。</span></div><div><span style="font-size: 12pt;">doc_raw_offset.bin 格式：</span></div><div><span style="font-size: 12pt;">doc_id \t offset \r\n</span></div><div><br/></div><div><br/></div><div><br/></div></div><hr/><hr/><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="从零开始搭建搜索引擎" scheme="https://xinrihui.github.io/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
    <category term="倒排索引" scheme="https://xinrihui.github.io/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    
    <category term="bm25" scheme="https://xinrihui.github.io/tags/bm25/"/>
    
    <category term="tf-idf" scheme="https://xinrihui.github.io/tags/tf-idf/"/>
    
  </entry>
  
  <entry>
    <title>小灰灰信息检索系统 - 4.建立倒排索引</title>
    <link href="https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%204.%E5%BB%BA%E7%AB%8B%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    <id>https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%204.%E5%BB%BA%E7%AB%8B%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/</id>
    <published>2022-12-04T14:27:27.000Z</published>
    <updated>2022-12-04T14:29:16.426Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-01-27 09:53:22 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 13:59:03 +0000"/><title>小灰灰信息检索系统 - 4.建立倒排索引</title></head><body><div><div><div><div><br/></div><div><span style="font-size: 12pt;">索引阶段主要负责将分析阶段产生的临时索引，构建成倒排索引。倒排索引（ Inverted index）中记录了每个单词以及包含它的网页列表。</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%204.%E5%BB%BA%E7%AB%8B%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.resources/6115A876-5314-42A6-9327-C5A433C1E8D3.jpg" height="665" width="1142"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">我们刚刚讲到，在临时索引文件中，记录的是单词跟每个包含它的文档之间的对应关系。那如何通过临时索引文件，构建出倒排索引文件呢？</span></div><div><br/></div><div><span style="font-size: 12pt;">解决这个问题的方法有很多。考虑到</span> <span style="font-size: 12pt; font-weight: bold;">临时索引文件很大</span><span style="font-size: 12pt;">，</span><span style="font-size: 12pt; font-weight: bold;">无法一次性加载到内存中</span><span style="font-size: 12pt;">，搜索引擎一般会选择使用</span> <span style="font-size: 12pt; font-weight: bold;">多路归并排序</span> <span style="font-size: 12pt;">的方法来实现。</span></div><div><br/></div><div><span style="font-size: 12pt;">因为临时索引很大，所以一般基于内存的排序算法就没法处理这个问题了。我们可以用之前讲到的归并排序的处理思想，将其分割成多个小文件，先对每个小文件独立排序，最后再合并在一起。当然，实际的软件开发中，我们其实可以直接利用  MapReduce 来处理。</span></div><div><br/></div><div><span style="font-size: 12pt;">临时索引文件排序完成之后，相同的单词就被排列到了一起。</span><span style="font-size: 12pt; font-weight: bold;">我们只需要顺序地遍历排好序的临时索引文件，就能将每个单词对应的网页编号列表找出来，然后把它们存储在倒排索引文件中</span><span style="font-size: 12pt;">。</span></div><div><br/></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%204.%E5%BB%BA%E7%AB%8B%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.resources/AC885451-0DA1-4E7E-AD7E-7C3AA32FE133.jpg" height="711" width="1142"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">除了倒排文件之外，我们还需要一个文件，来记录每个单词编号在倒排索引文件中的偏移位置。我们把这个文件命名为 term_offset.bin。这个文件的作用是，帮助我们快速地查找某个单词编号在倒排索引中存储的位置，进而快速地从倒排索引中读取单词编号对应的网页编号列表。</span></div><div><br/></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%204.%E5%BB%BA%E7%AB%8B%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.resources/AAF23CE0-CE6E-4BC2-9CB4-E804E7503CDE.jpg" height="553" width="1142"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">经过索引阶段的处理，我们得到了两个有价值的文件，</span></div><div><span style="font-size: 12pt;">它们分别是</span> <span style="font-size: 12pt; font-weight: bold;">倒排索引文件（index.bin）</span><span style="font-size: 12pt;">和 记录单词编号在索引文件中的</span> <span style="font-size: 12pt; font-weight: bold;">偏移位置的文件（term_offset.bin）</span><span style="font-size: 12pt;">。</span></div><div><br/></div><hr/><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：如何构建基础的倒排索引  并 在此基础上增加tf-idf</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">1.基础的倒排索引构建</span></div><div><br/></div><div><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">1.1基于多路归并排序（方案A）</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">把 临时索引文件 拆分为 多个小文件，对每个 小文件在内存中 按照 term_id 进行排序，最后再将 这几个排好序的小文件  进行一次 基于磁盘的 多路归并 排序。</span></div><div><br/></div><div><span style="font-size: 12pt;">排序后的 临时索引 的文件（ sorted_tmp_index.bin）设计结构如下： </span></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">地址</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">0-3</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">4 -7</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">8-11</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">12-15</span></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">域，占字节数</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">term_id1（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">doc_id1（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">term_id1（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">doc_id2（4B）</span></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">值</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">1</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">1</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">1</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">2</span></div></td></tr></tbody></table><div><br/></div><div><br/></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%204.%E5%BB%BA%E7%AB%8B%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.resources/AC885451-0DA1-4E7E-AD7E-7C3AA32FE133.jpg" height="711" width="1142"/><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">1.2 基于 spark 排序</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">（方案B）</span></div><div><br/></div><div><span style="font-size: 12pt;">1.把 整个 临时索引文件 存入 HDFS 中</span></div><div><br/></div><div><span style="font-size: 12pt;">2.利用 spark 直接 对 整个 临时索引文件 进行 排序</span></div><div><br/></div><div><span style="font-size: 12pt;">但是 spark 的读取文件的 API  sc.textFile()  的 内部实现是： </span></div><div><span style="font-size: 12pt;">（1） 对大文件进行切片，这些文件切片 交由 不同的 计算节点 进行处理；</span></div><div><br/></div><div><span style="font-size: 12pt;">（2） 在 计算 节点上，对在自己这里的 文件切片 以行为最小单位 进行解析，每一行 形成一个 K-V 对，然后进行接下来的计算 ；</span></div><div><br/></div><div><span style="font-size: 12pt;">而我们 上述 临时索引文件（tmp_index.bin）的 设计 并没有采用 使用 分隔符 和 换行符 的方案，而是采用了 定长（字节长度）字段 的 方案，如果要使用 spark ，则需要 修改 sc.textFile()  的实现</span></div><div><br/></div><div><span style="font-size: 12pt;">为了解决上述问题，我们 修改了 临时索引文件（tmp_index.bin）的结构 如下：</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%204.%E5%BB%BA%E7%AB%8B%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.resources/E57A10BF-3387-41D3-967F-AF7FDBB661C0.jpg" height="596" width="1142"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">使用换行符 ' \r\n' 来区分行，每一行代表了 一个 ( term_id , doc_id )，term_id 和 doc_id 用 分隔符 '\t' 进行区分</span></div><div><br/></div><div><span style="font-size: 12pt;">对比 新生成的 方便 spark 读取 的临时索引文件 tmp_index_spark.bin （65.3MB）和原来的 </span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">tmp_index.bin （53.9MB），大小还是变大了</span></div><div><br/></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">注意</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">：</span> <span style="font-size: 12pt;">pycharm 查看 超过 50MB 的文本会显示 不全，建议使用 notepad++</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><a href="http://dblab.xmu.edu.cn/blog/1708-2/" style="font-size: 12pt;">http://dblab.xmu.edu.cn/blog/1708-2/</a></div><div><a href="https://www.jianshu.com/p/a47b2452e4f6" style="font-size: 12pt;">https://www.jianshu.com/p/a47b2452e4f6</a></div><div><br/></div><div><span style="font-size: 12pt;">windows 下安装 spark 开发环境</span></div><div><a href="https://medium.com/big-data-engineering/how-to-install-apache-spark-2-x-in-your-pc-e2047246ffc3" style="font-size: 12pt;">https://medium.com/big-data-engineering/how-to-install-apache-spark-2-x-in-your-pc-e2047246ffc3</a></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.引入 TF-IDF=TF * IDF</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">公式：</span></div><div><span style="font-size: 12pt;">词频（TF）= 某词项 出现次数/ 文章中 词项总数 （  词频（TF）=某关键词出现次数 /文章中出现最多次数关键词的出现次数  ）</span></div><div><br/></div><div><span style="font-size: 12pt;">逆文档频率（IDF）= log（ 语料库文档总数 /（包含该词的文档数+1）），</span></div><div><br/></div><div><span style="font-size: 12pt;">（1）计算IDF需要一个语料库。</span></div><div><span style="font-size: 12pt;">（2）之所以要+1是为了防止分母为0。</span></div><div><span style="font-size: 12pt;">（3）当一个词被越多的文档包含，则 IDF 值就越小，也就是所这个词很常见，不是最重要的能区分文章特性的关键词。</span></div><div><br/></div><div><span style="font-size: 12pt;">TF-IDF 并没有考虑词语的语义信息，无法处理 一词多义 与 一义多词的情况。</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold; font-family: unset;">方案A：（续上述方案A）</span><br/></div><div><br/></div><div><span style="font-size: 12pt;">TF-IDF 放在倒排索引里 做第一级的排序 ，</span><span style="font-size: 12pt; font-weight: bold;">倒排索引文件（index.bin）</span><span style="font-size: 12pt;"> 的结构 如下：</span></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 158px;"/><col style="width: 162px;"/><col style="width: 130px;"/><col style="width: 170px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">地址</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">0-3</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 158px; padding: 8px;"><div><span style="font-size: 12pt;">4 -7</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 162px; padding: 8px;"><div><span style="font-size: 12pt;">8-11</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">12-15</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 170px; padding: 8px;"><div><span style="font-size: 12pt;">16-19</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">20-23</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><br/></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">域，占字节数</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">term_id（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 158px; padding: 8px;"><div><span style="font-size: 12pt;">doc_num（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 162px; padding: 8px;"><div><span style="font-size: 12pt;">doc_id1（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">term_num1（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 170px; padding: 8px;"><div><span style="font-size: 12pt;">doc_id2（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">term_num2（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><br/></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">值</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">1</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 158px; padding: 8px;"><div><span style="font-size: 12pt;">2</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 162px; padding: 8px;"><div><span style="font-size: 12pt;">1</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">2</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 170px; padding: 8px;"><div><span style="font-size: 12pt;">2</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">3</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><br/></div></td></tr></tbody></table><div><span style="font-size: 12pt;">其中 ，</span></div><ul><li><div><span style="font-size: 12pt;">doc_num 为 一共有 多少文档出现了 term_id 这个单词，可以利用它计算 IDF</span></div></li><li><div><span style="font-size: 12pt;">term_num1 为 term_id 在 doc_id1 中出现了 多少次，可以利用它计算 TF </span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">记录单词编号在 索引文件中的  </span><span style="font-size: 12pt; font-weight: bold;">偏移位置的文件（term_offset.bin）</span> <span style="font-size: 12pt;">，文件结构如下：</span></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 188px;"/></colgroup><tbody><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">地址</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">0-3</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 188px; padding: 8px;"><div><span style="font-size: 12pt;">4 -7</span></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">域，占字节数</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">term_id（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 188px; padding: 8px;"><div><span style="font-size: 12pt;">term_id_offset（4B）</span></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">值</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">1</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 188px; padding: 8px;"><div><span style="font-size: 12pt;">0</span></div></td></tr></tbody></table><div><br/></div><div><span style="font-size: 12pt;">为计算 TF ，需要 知道 每一个文档的  词项的总数 （可以作为 文档的长度），</span><span style="font-size: 12pt; font-weight: bold;">文档的词项 总数文件（</span> <span style="font-size: 12pt; font-weight: bold;">doc_termsNums</span><span style="font-size: 12pt; font-weight: bold;">.bin ）</span><span style="font-size: 12pt;">的结构如下：</span></div><div><span style="font-size: 12pt;">{ doc_id : num }</span></div><div><span style="font-size: 12pt;">在 未排序的临时索引 的文件（tmp_index.bin）中，第二列  doc_id  是有序的：</span></div><div><br/></div><div><span style="font-size: 12pt;">tmp_index.bin</span></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">term_id</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">doc_id</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">1</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">1</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">0</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">1</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">2</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">1</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">3</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">1</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">4</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">1</span></div></td></tr></tbody></table><div><span style="font-size: 12pt;">由此可得 doc1  的 总的词项数</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">方案B：（续上述方案B）</span></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><a href="https://blog.csdn.net/xuyaoqiaoyaoge/article/details/47172151" style="font-size: 12pt;">https://blog.csdn.net/xuyaoqiaoyaoge/article/details/47172151</a></div></div><div><br/></div><div><br/></div><hr/><div><br/></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：因为爬虫在不断爬取新的网页，如果 有新的文档 里包含了 词项1 ，则需要 更新 词项1 的 倒排记录 ，如何在不重写整个 </span><span style="font-size: 12pt; color: rgb(255, 0, 0);">倒排索引文件 的前提下，进行 </span><span style="font-size: 12pt; color: rgb(255, 0, 0);">更新？</span></div><div><br/></div><div><span style="font-size: 12pt;">（1）利用数据库 做 外存 的管理：将存储空间划分为页，记录 写入 固定大小的页中，数据库管理这些页，包括对 页进行索引、 页的分裂 和 合并（B+树）</span></div><div><br/></div><div><span style="font-size: 12pt;">（2）每一次都 将  单词1 对应的新的 倒排记录 追加在文件的末尾，并 更新 单词1 的偏移位置；</span></div><div><br/></div><div><span style="font-size: 12pt;">但是，上述 方案 会造成  倒排索引文件 的无效内容过多，浪费存储空间；</span></div><div><span style="font-size: 12pt;">由前文可知 更新文件中的特定的一行记录 不太现实， 此场景下 使用 数据库 十分合适； </span></div><div><span style="font-size: 12pt;">词项的 倒排表  会越来 越长，而且 一般使用 词项 进行 K-V 查找，所以  可以 使用 redis + hbase  来存储 倒排索引表 </span></div><div><br/></div></div><hr/><div><br/></div></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题： 如何 用 tf-idf 计算 两个 doc 的相似度</span></div><div><br/></div><div><span style="font-size: 12pt;">基于词的TF -IDF 使用 sklearn 的  TfidfVectorizer 包，</span></div><div><span style="font-size: 12pt;">每个句子是一个 BOW （词袋模型）向量，向量中的每一维是 某个词的 TF-IDF 值</span></div><div><br/></div><div><span style="font-size: 12pt;">求两个 句子 对应的 向量的 余弦 相似度，即为 两个 doc 的相似度</span></div><div><br/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="从零开始搭建搜索引擎" scheme="https://xinrihui.github.io/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
    <category term="倒排索引" scheme="https://xinrihui.github.io/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    
    <category term="bm25" scheme="https://xinrihui.github.io/tags/bm25/"/>
    
    <category term="tf-idf" scheme="https://xinrihui.github.io/tags/tf-idf/"/>
    
  </entry>
  
  <entry>
    <title>小灰灰信息检索系统 - 3.信息抽取和创建临时索引</title>
    <link href="https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%203.%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E5%92%8C%E5%88%9B%E5%BB%BA%E4%B8%B4%E6%97%B6%E7%B4%A2%E5%BC%95/"/>
    <id>https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%203.%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E5%92%8C%E5%88%9B%E5%BB%BA%E4%B8%B4%E6%97%B6%E7%B4%A2%E5%BC%95/</id>
    <published>2022-12-04T14:27:26.000Z</published>
    <updated>2022-12-04T14:29:16.421Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-01-27 09:37:29 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-02-14 11:43:31 +0000"/><title>小灰灰信息检索系统 - 3.信息抽取和创建临时索引</title></head><body><div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">网页爬取下来之后，我们需要对网页进行离线分析。分析阶段主要包括两个步骤，第一个是抽取网页文本信息，第二个是分词并创建临时索引。</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">抽取网页文本信息</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">网页是半结构化数据，里面夹杂着各种标签、JavaScript 代码、CSS 样式。对于搜索引擎来说，它只关心网页中的文本信息，也就是，网页显示在浏览器中时，能被用户肉眼看到的那部分信息。我们如何从半结构化的网页中，抽取出搜索引擎关系的文本信息呢？</span></div><div><br/></div><div><span style="font-size: 12pt;">我们之所以把网页叫作半结构化数据，是因为它本身是按照一定的规则来书写的。这个规则就是 HTML 语法规范。我们依靠 HTML 标签来抽取网页中的文本信息。这个抽取的过程，大体可以分为两步。</span></div><div><br/></div><div><span style="font-size: 12pt;">第一步是去掉 JavaScript 代码、CSS 格式以及下拉框中的内容（因为下拉框在用户不操作的情况下，也是看不到的）。也就是，，这三组标签之间的内容。我们可以 利用 AC 自动机这种 多模式串匹配算法，在网页这个大字符串中，一次性查找, ,</span></div><div><br/></div><div><span style="font-size: 12pt;">第二步是去掉所有 HTML 标签。这一步也是通过字符串匹配算法来实现的。过程跟第一步类似，我就不重复讲了。</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">分词并创建临时索引</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">经过上面的处理之后，我们就从网页中抽取出了我们关心的文本信息。接下来，我们要对文本信息进行分词，并且创建临时索引。</span></div><div><br/></div><div><span style="font-size: 12pt;">对于英文网页来说，分词非常简单。我们只需要通过空格、标点符号等分隔符，将每个单词分割开来就可以了。但是，对于中文来说，分词就复杂太多了。我这里介绍一种比较简单的思路，基于字典和规则的分词方法。</span></div><div><br/></div><div><span style="font-size: 12pt;">其中，字典也叫词库，里面包含大量常用的词语（我们可以直接从网上下载别人整理好的）。我们借助词库并采用</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">最长匹配规则</span><span style="font-size: 12pt;">，来对文本进行分词。所谓最长匹配，也就是匹配尽可能长的词语。我举个例子解释一下。</span></div><div><br/></div><div><span style="font-size: 12pt;">比如要分词的文本是“中国人民解放了”，我们词库中有“中国”“中国人”“中国人民”“中国人民解放军”这几个词，那我们就取最长匹配，也就是“中国人民”划为一个词，而不是把“中国”、“中国人“划为一个词。具体到实现层面，我们可以将词库中的单词，构建成 Trie 树结构，然后拿网页文本在 Trie 树中匹配。</span></div><div><br/></div><div><span style="font-size: 12pt;">每个网页的文本信息在分词完成之后，我们都得到一组单词列表。我们把单词与网页之间的对应关系，写入到 一个</span> <span style="font-size: 12pt; font-weight: bold;">临时索引文件&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">（tmp_Index.bin）</span><span style="font-size: 12pt;">中，这个临时索引文件（只有一个还很大）用来构建倒排索引文件。临时索引文件的格式如下：</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%203.%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E5%92%8C%E5%88%9B%E5%BB%BA%E4%B8%B4%E6%97%B6%E7%B4%A2%E5%BC%95.resources/3268835C-0062-494E-A430-B772A239F87B.jpg" height="596" width="1142"/></div><div><br/></div><div><span style="font-size: 12pt;">在临时索引文件中，我们存储的是单词编号，也就是图中的 term_id，而非单词本身。这样做的目的主要是为了节省存储的空间。</span></div><div><br/></div><div><span style="font-size: 12pt;">给单词编号的方式，跟给网页编号类似。我们维护一个&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">计数器</span><span style="font-size: 12pt;">，每当从网页文本信息中分割出一个新的单词的时候，我们就从计数器中取一个编号，分配给它，然后计数器加一。</span></div><div><br/></div><div><span style="font-size: 12pt;">在这个过程中，我们还需要使用散列表，记录已经编过号的单词。在对网页文本信息分词的过程中，我们拿分割出来的单词，先到散列表中查找，如果找到，那就直接使用已有的编号；如果没有找到，我们再去计数器中拿号码，并且将这个新单词以及编号添加到散列表中。</span></div><div><br/></div><div><span style="font-size: 12pt;">当所有的网页处理（分词及写入临时索引）完成之后，我们再将这个单词跟编号之间的对应关系，写入到磁盘文件中，并命名为 term_id.bin。</span></div><div><br/></div><div><span style="font-size: 12pt;">经过分析阶段，我们得到了两个重要的文件。它们分别是临时索引文件（tmp_index.bin）和 单词编号文件（term_id.bin）。</span></div><div><br/></div><hr/><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题 ：如何&nbsp;&nbsp;构建 临时索引文件</span></div><div><br/></div><div><span style="font-size: 12pt;">1.存储 临时索引 的文件（tmp_index.bin）设计结构如下：&nbsp;&nbsp;</span></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">地址</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">0-3</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">4 -7</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">8-11</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">12-15</span></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">域，占字节数</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">term_id1（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">doc_id1（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">term_id2（4B）</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">doc_id1（4B）</span></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">值</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">1</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">1</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">2</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div><span style="font-size: 12pt;">1</span></div></td></tr></tbody></table><div><br/></div><div><span style="font-size: 12pt;">2.单词编号&nbsp;&nbsp;文件不大（term_id.bin），&nbsp;&nbsp;可以 放入&nbsp;&nbsp;内存的 Hash&nbsp;&nbsp;表中，结构为：</span></div><div><span style="font-size: 12pt;">{&nbsp;&nbsp; term :&nbsp;&nbsp;term_id }</span></div><div><br/></div><div><span style="font-size: 12pt;">同理，逆单词编号 &nbsp;&nbsp;文件（inver_term_id.bin）&nbsp;&nbsp;的结构为：</span></div><div><span style="font-size: 12pt;">{&nbsp;&nbsp;term_id ：&nbsp;&nbsp;term }</span></div><div><br/></div><div><span style="font-size: 12pt;">其中&nbsp;&nbsp;单词id&nbsp;&nbsp;的计数器&nbsp;&nbsp;可以直接&nbsp;&nbsp;使用 hash&nbsp;&nbsp;表的&nbsp;&nbsp;长度</span></div><div><br/></div><div><span style="font-size: 12pt;">3.分词&nbsp;&nbsp;采用&nbsp;&nbsp;结巴中文分词&nbsp;&nbsp;</span><a href="https://github.com/fxsjy/jieba" style="font-size: 12pt;">https://github.com/fxsjy/jieba</a></div><div><br/></div><div><span style="font-size: 12pt;">要额外导入&nbsp;&nbsp;自己的&nbsp;&nbsp;词典，以便包含 jieba 词库里没有的词</span></div><div><span style="font-size: 12pt;">词典中 一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开</span></div><div><br/></div><div><span style="font-size: 12pt;">在爬取的原始网页的 文件（doc_raw.bin）中，每一个百度百科文档的 第一行为&nbsp;&nbsp;这个词条页&nbsp;&nbsp;的词条，所以可以把&nbsp;&nbsp;这个词条&nbsp;&nbsp;加入词典（baidubaikeDic.txt），词频 根据&nbsp;&nbsp;经验&nbsp;&nbsp;都取 10000</span></div><div><br/></div><div><span style="font-size: 12pt;">使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典，但是我们采用&nbsp;&nbsp;先形成&nbsp;&nbsp;词典再进行分词的方式，因为在&nbsp;&nbsp;该词条页的文本中&nbsp;&nbsp;极有可能&nbsp;&nbsp;有别的词条，因而 需要被正确地分词。</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">4.解析&nbsp;&nbsp;文档内容时，先过滤&nbsp;&nbsp;不可见的&nbsp;&nbsp;非法字符</span></div><div><br/></div><div><br/></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="从零开始搭建搜索引擎" scheme="https://xinrihui.github.io/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
    <category term="倒排索引" scheme="https://xinrihui.github.io/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    
    <category term="bm25" scheme="https://xinrihui.github.io/tags/bm25/"/>
    
    <category term="tf-idf" scheme="https://xinrihui.github.io/tags/tf-idf/"/>
    
  </entry>
  
  <entry>
    <title>小灰灰信息检索系统 - 2.解析网页文档</title>
    <link href="https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3/"/>
    <id>https://xinrihui.github.io/2022/12/04/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3/</id>
    <published>2022-12-04T14:27:25.000Z</published>
    <updated>2022-12-04T14:29:16.428Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-01-27 07:53:07 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 14:00:44 +0000"/><title>小灰灰信息检索系统 - 2.解析网页文档</title></head><body><div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">1.基础方法</span></div><div><br/></div><div><span style="font-size: 12pt;">常见的python网页解析工具有：re正则匹配、python自带的html.parser模块、第三方库 BeautifulSoup 和 lxml</span></div><div><br/></div><div><span style="font-size: 12pt;">（1）模糊匹配</span></div><div><span style="font-size: 12pt;">　re正则表达式 即为字符串式的模糊匹配模式；</span></div><div><br/></div><div><span style="font-size: 12pt;">（2）结构化解析</span></div><div><span style="font-size: 12pt;">BeatufiulSoup、html.parser与lxml为“结构化解析”模式，他们都以DOM树结构为标准，进行标签结构信息的提取。</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/CDC6BC4F-628A-4CE6-BAEA-42AF07A0A6C0.png" height="348" width="885"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">DOM树 ：文档对象模型（Document Object Model） 它的 树形标签结构见下图：</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/E6B135BD-C94A-4957-934F-743ECD7B0898.png" height="392" width="913"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">网页解析器 会将下载的整个HTML文档当成一个Doucment对象，利用 对象的上下级标签 对网页内容进行 遍历 和信息提取。</span></div><div><br/></div><div><span style="font-size: 12pt;">整体流程如下：</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/61F3A8BB-2D8E-4CC9-9B41-74F5CE646D44.png" height="459" width="882"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">（1）创建BeautifulSoup对象（即DOM对象）</span></div><div><br/></div><div><span style="font-size: 12pt;">from bs4 import BeatifulSoup</span></div><div><span style="font-size: 12pt;"># 根据HTML网页字符串结构创建BeatifulSoup对象。</span></div><div><span style="font-size: 12pt;">soup = BeautifulSoup(html_doc,                      #HTML文档字符串</span></div><div><span style="font-size: 12pt;">                         'html.parser',                  #HTML解析器</span></div><div><span style="font-size: 12pt;">                         from_encoding = 'utf-8'         #HTML文档编码</span></div><div><span style="font-size: 12pt;">                          )</span></div><div><br/></div><div><span style="font-size: 12pt;">（2）搜索节点（find_all,find）</span></div><div><span style="font-size: 12pt;">　　</span></div><div><span style="font-size: 12pt;">       搜索节点方法：</span></div><div><span style="font-size: 12pt;">　　soup.find_all()  --- 查找所有符合查询条件的标签节点，并返回一个列表。</span></div><div><span style="font-size: 12pt;">　　soup.find()      --- 查找符合符合查询条件的第一个标签节点。</span></div><div><br/></div><div><span style="font-size: 12pt;"> 实例1：搜索所有&lt;a&gt;标签</span></div><div><span style="font-size: 12pt;"> soup.find_all('a')</span></div><div><span style="font-size: 12pt;">　　　</span></div><div><span style="font-size: 12pt;">实例2：查找所有标签符合标签名为a，链接符合 /view/123.html的节点</span></div><div><span style="font-size: 12pt;">M1：</span></div><div><span style="font-size: 12pt;"> soup.find_all('a', href = '/view/123.html')</span></div><div><span style="font-size: 12pt;">M2：</span></div><div><span style="font-size: 12pt;"> soup.find_all('a', href =</span> <a href="http://re.compile(r'/view/" style="font-size: 12pt;">re.compile(r'/view/</a><span style="font-size: 12pt;">\d+\.html'))</span></div><div><br/></div><div><span style="font-size: 12pt;">实例3：查找所有标签为名为a，class属性为abc，文字为python的节点　</span></div><div><span style="font-size: 12pt;"> soup.findall('a', class_= 'abc', string = 'python')</span></div><div><br/></div><div><span style="font-size: 12pt;">(3) 访问节点信息</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/A94F42C8-C73E-4417-9896-2DB5DC6E6798.png" height="312" width="950"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">1) 获取节点名称  node.name</span></div><div><span style="font-size: 12pt;">　　　　</span></div><div><span style="font-size: 12pt;">2)获取查找到的a节点的href属性</span></div><div><span style="font-size: 12pt;">node['href']</span></div><div><span style="font-size: 12pt;">　或者</span></div><div><span style="font-size: 12pt;">node.get('href')</span></div><div><span style="font-size: 12pt;">　　　　</span></div><div><span style="font-size: 12pt;">3）获取查找到的a节点的字符串内容</span></div><div><span style="font-size: 12pt;">node.get_text()</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/" style="font-size: 12pt;">https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/</a></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.高级方法</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.1 爬取 瀑布流 型网页 中的元素</span></div><div><br/></div><div><span style="font-size: 12pt;">看一下瀑布流型的网页是如何翻页的：</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/F86A62CE-9976-4BD4-8DBB-FA840838CFA9.png" height="815" width="1512"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">点击加载更多页面下方会加载更多的商品（有些网址是往下滚动的时候自动加载，原理一样），但是浏览器地址栏的网址不会改变，</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">那么怎么才能找出类似翻页的规律呢？</span></div><div><br/></div><div><span style="font-size: 12pt;">chrome 游览器  F12 打开网页的 源码 出现如下页面，选择Network一栏，点击之前看到的</span> <span style="font-size: 12pt; font-weight: bold;">加载更多</span> <span style="font-size: 12pt;">进行商品加载，在Network的 XHR一栏会依次出现数个元素，查看元素的 Header </span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/80E34218-3E88-4DF3-9C9A-FAC2C58E14E0.png" height="510" width="1376"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">chrome  查看HTTP 请求的详情 方法：</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/0F1C4D1D-A77A-4AD4-994A-2A07747B8471.png" height="622" width="968"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">Header  中的 找到Request URL的值，发现规律：</span></div><div><a href="http://www.dunkhome.com/products/load_more?c_id=&amp;brand_id=&amp;keyword=&amp;sort=&amp;activity_id=&amp;page=2" style="font-size: 12pt;">http://www.dunkhome.com/products/load_more?c_id=&amp;brand_id=&amp;keyword=&amp;sort=&amp;activity_id=&amp;page=2</a></div><div><a href="http://www.dunkhome.com/products/load_more?c_id=&amp;brand_id=&amp;keyword=&amp;sort=&amp;activity_id=&amp;page=3" style="font-size: 12pt;">http://www.dunkhome.com/products/load_more?c_id=&amp;brand_id=&amp;keyword=&amp;sort=&amp;activity_id=&amp;page=3</a></div><div><a href="http://www.dunkhome.com/products/load_more?c_id=&amp;brand_id=&amp;keyword=&amp;sort=&amp;activity_id=&amp;page=4" style="font-size: 12pt;">http://www.dunkhome.com/products/load_more?c_id=&amp;brand_id=&amp;keyword=&amp;sort=&amp;activity_id=&amp;page=4</a></div><div><br/></div><div><span style="font-size: 12pt;">每点击 “加载更多”一次，链接变动一次（链接 最后的 page=2 ，page=3，page=4），可以将其看成翻页的页面变化规律。</span></div><div><span style="font-size: 12pt;">利用这个链接变化规律做循环，就能 模拟 持续翻页 并找到 我们要的图片</span></div><div><br/></div><div><span style="font-size: 12pt;">点击 其中一个 URL ，效果如下：</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/421F85C3-5F31-4658-9318-0BAFCC2F48E1.png" height="532" width="1099"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">找其中的 图片链接，发现都在src="(.*?).jpg字段里面，提取出来，进行下载即可</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><a href="https://blog.csdn.net/malvas/article/details/89965210" style="font-size: 12pt;">https://blog.csdn.net/malvas/article/details/89965210</a></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.2 爬取 需要 post 才能拿到的元素</span></div><div><br/></div><div><span style="font-size: 12pt;">我们把 百度百科 分为 索引页面 和 词条页面</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">索引页面的第0级  </span> <a href="https://baike.baidu.com/" style="font-size: 12pt;">https://baike.baidu.com/</a></div></li></ul><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/DD8A5160-367F-4232-96EC-63BEC997AF79.png" height="903" width="1920"/><br/></div><div><span style="font-size: 12pt;">在  分类 tag 下面有大类的 学科，我们 选择 进入 科学类</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;"> 索引页面的第1级 </span> <a href="https://baike.baidu.com/science" style="font-size: 12pt;">https://baike.baidu.com/science</a></div></li></ul><div><br/></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/6B1F422D-DD70-44FF-9C3F-21B725FE6A15.png" height="845" width="1657"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">在页面的 底部有 各个细分的学科，我们选择 航空航天 ：</span></div><div><br/></div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">索引页面的第2级  </span> <a href="https://baike.baidu.com/wikitag/taglist?tagId=76572" style="font-size: 12pt;">https://baike.baidu.com/wikitag/taglist?tagId=76572</a></div></li></ul><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/CC959F9E-A63D-4B07-B84C-6E5AAB57FE43.png" height="653" width="1673"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">这是  百度百科 索引页 的最后一层 ，可见 其采用了 瀑布流的形式来 展示元素 。</span></div><div><span style="font-size: 12pt;">再往下一层就是 具体的 词条的页面了 ，例如 歼-20 的词条页：</span> <a href="https://baike.baidu.com/item/%E6%AD%BC-20/1555348" style="font-size: 12pt;">https://baike.baidu.com/item/%E6%AD%BC-20/1555348</a></div><div><br/></div><div><span style="font-size: 12pt;">目前，github 上开源的 百科爬虫 都只能支持 词条页面的爬取，而无法爬取索引页面。</span></div><div><span style="font-size: 12pt;">例如 ， </span> <a href="https://github.com/jasonhavenD/Baike" style="font-size: 12pt;">https://github.com/jasonhavenD/Baike</a><span style="font-size: 12pt;"> 这个项目 使用 一个已有的 词条字典列表，然后通过  拼接的方式 ，（读取词条列表中的词条，与 百度百科的前缀 进行拼接） 得到到 词条页的URL（见下图）。</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/D8F66050-770B-4BB8-AD45-A41BEF1650AE.png" height="37" width="426"/><br/></div><div><span style="font-size: 12pt;">但是，最关键的 问题是 我们要如何 才能拿到 百度百科的 词条字典 列表。显然，还是得去爬取 百度百科的索引列表。</span></div><div><br/></div><div><span style="font-size: 12pt;">因此，我们要构建 一个 可以爬取索引页面 和 词条页面的爬虫，无需 预先准备词条字典，一站式解决 百度百科所有词条页面的爬取 。</span></div><div><br/></div><div><span style="font-size: 12pt;">不同分类的 第 1 级索引的 形式  不同，</span></div><div><span style="font-size: 12pt;"> 第2级索引 的形式也不一样，大部分并没有像  </span> <a href="https://baike.baidu.com/wikitag/taglist?tagId=76572" style="font-size: 12pt;">https://baike.baidu.com/wikitag/taglist?tagId=76572</a><span style="font-size: 12pt;"> 这样的瀑布流 </span></div><div><br/></div><div><span style="font-size: 12pt;">例如：</span></div><div><span style="font-size: 12pt;">第1级索引 </span> <a href="http://baike.baidu.com/jingji" style="font-size: 12pt;">http://baike.baidu.com/jingji</a></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/1779F05B-D26A-4228-ADF1-C8028A9D0B55.png" height="525" width="1200"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">第2级索引：</span> <a href="http://baike.baidu.com/fenlei/%E7%BB%8F%E6%B5%8E%E5%AD%A6" style="font-size: 12pt;">http://baike.baidu.com/fenlei/%E7%BB%8F%E6%B5%8E%E5%AD%A6</a></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/B9415A51-C90A-428A-BCD8-1B5FA2890443.png" height="756" width="1513"/><br/></div><div><span style="font-size: 12pt;">在第2级索引 下面有一个 分页展示的 tag ，可以直接通向词条 页面</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/7105A7DB-CF19-4E4A-99DD-148B65A5CEA1.png" height="730" width="1307"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">在 第1级 索引中，完全可能 跳 到 具体的 词条页面：</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/97B51CC2-20CF-432F-98B7-17B1B32A15A3.png" height="702" width="1254"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">基于上述的观察，我们设计了 如下的策略 爬取 百度百科的内容：</span></div><div><br/></div><div><span style="font-size: 12pt;">1.根据 URL 是否有 item 来判断 是否 为词条页（</span> <a href="https://baike.baidu.com/item/%E6%AD%BC-20/1555348" style="font-size: 12pt;">https://baike.baidu.com/item/歼-20/1555348</a> <span style="font-size: 12pt;">），若为词条页，则 将其保存下来，并不 对其中的内容 解析出新的 URL</span></div><div><span style="font-size: 12pt;">2.对于 非词条页   ，我们要  对其中的内容 解析出新的 URL：</span></div><ul><li><div><span style="font-size: 12pt;">根据 URL 是否有 wikitag判断（ </span><a href="https://baike.baidu.com/wikitag/taglist?tagId=76572" style="font-size: 12pt;">https://baike.baidu.com/wikitag/taglist?tagId=76572</a><span style="font-size: 12pt;"> ） 其中 索引页中 是否 有 瀑布流 ，并对瀑布流 中的元素进行解析，得到 词条页的URL </span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;"> 利用 postman  工具 爬取 百度百科的 瀑布流元素，见下面视频：</span></div><div><a href="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/bandicam%202020-05-17%2010-59-46-660.mp4">bandicam 2020-05-17 10-59-46-660.mp4</a></div><div><span style="font-size: 12pt;">参考：</span></div><div><a href="https://www.cnblogs.com/birds-zhu/p/11175564.html" style="font-size: 12pt;">https://www.cnblogs.com/birds-zhu/p/11175564.html</a></div><div><a href="https://www.zhihu.com/question/60256922/answer/174211193" style="font-size: 12pt;">https://www.zhihu.com/question/60256922/answer/174211193</a></div><div><a href="https://www.zhihu.com/question/60256922/answer/174663698" style="font-size: 12pt;">https://www.zhihu.com/question/60256922/answer/174663698</a></div><div><br/></div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">根据 URL 是否有 fenlei 判断（</span><a href="http://baike.baidu.com/fenlei/%E7%BB%8F%E6%B5%8E%E5%AD%A6" style="font-size: 12pt;">http://baike.baidu.com/fenlei/%E7%BB%8F%E6%B5%8E%E5%AD%A6</a><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">） 其中 索引页中 是否 有翻页 ，并对 翻页 中的元素进行解析，</span><span style="font-size: 12pt;">得到 词条页的URL </span></div></li></ul><div><span style="font-size: 12pt; font-weight: bold;">    </span><span style="font-size: 12pt; font-weight: bold;">     </span><span style="font-size: 12pt;">翻页的按钮 在 网页上直接可得，见下图 中的 page 元素：</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/0EC17678-B5A7-4C28-BCA1-3DC87190081A.png" height="733" width="1809"/><br/></div><div><span style="font-size: 12pt;">       page 元素 中 包含了 下一页的 URL ，所以 直接使用 普通索引页的方法解析 即可</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">解析 普通索引页  ：找 page 中的 &lt;a &gt; &lt;/a&gt; 元素，找出其中的 URL </span></div></li></ul><div><span style="font-size: 12pt;">        </span></div><div><span style="font-size: 12pt; font-weight: bold;">2.3 </span><span style="font-size: 12pt; font-weight: bold;">异步</span><span style="font-size: 12pt; font-weight: bold;">请求</span><span style="font-size: 12pt; font-weight: bold;">网页 </span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">如果 同步请求网页 很容易发生 网络阻塞，此时程序会卡主，无法往下执行，</span></div><div><span style="font-size: 12pt;">为了让程序能够继续执行：</span></div><div><span style="font-size: 12pt;">1.请求 网页的时候 设置超时时间，若阻塞则放弃</span></div><div><span style="font-size: 12pt;">2.请求 网页（get , post） 使用异步的方式</span></div><div><br/></div><div><span style="font-size: 12pt;">（1）</span></div><div style="box-sizing: border-box; margin-top: 0px; margin-bottom: 0px; padding: 16px; overflow: auto; background-color: rgb(246, 248, 250); border-top-left-radius: 3px; border-top-right-radius: 3px; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><div><span style="font-size: 12pt; box-sizing: border-box; color: rgb(150, 152, 150); font-variant-caps: normal; font-variant-ligatures: normal;">#</span><span style="font-size: 12pt; box-sizing: border-box; color: rgb(150, 152, 150); font-variant-caps: normal; font-variant-ligatures: normal;"> wait for the first request to complete, if it hasn't already</span></div><div><span style="font-size: 12pt; color: rgb(36, 41, 46); font-variant-caps: normal; font-variant-ligatures: normal;">response_one </span><span style="font-size: 12pt; box-sizing: border-box; color: rgb(167, 29, 93); font-variant-caps: normal; font-variant-ligatures: normal;">=</span><span style="font-size: 12pt; color: rgb(36, 41, 46); font-variant-caps: normal; font-variant-ligatures: normal;"> future_one.result() 只到遇到这句话才等待,在这句话之前可以加入很多代码 程序不会被阻塞</span></div></div><div><span style="font-size: 12pt;">（2）</span></div><div style="box-sizing: border-box; margin-top: 0px; margin-bottom: 0px; word-wrap: normal; padding: 16px; overflow: auto; background-color: rgb(246, 248, 250); border-top-left-radius: 3px; border-top-right-radius: 3px; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px; word-break: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="box-sizing: border-box; word-wrap: normal; overflow: auto; background-color: rgb(246, 248, 250); word-break: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; border-radius: 3px; font-size: 12pt; color: rgb(36, 41, 46); font-variant-caps: normal; font-variant-ligatures: normal;">session</span> <span style="box-sizing: border-box; word-wrap: normal; overflow: auto; background-color: rgb(246, 248, 250); word-break: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; border-radius: 3px; font-size: 12pt; color: rgb(167, 29, 93); font-variant-caps: normal; font-variant-ligatures: normal;">=</span> <span style="box-sizing: border-box; word-wrap: normal; overflow: auto; background-color: rgb(246, 248, 250); word-break: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; border-radius: 3px; font-size: 12pt; color: rgb(36, 41, 46); font-variant-caps: normal; font-variant-ligatures: normal;">FuturesSession(</span><span style="box-sizing: border-box; word-wrap: normal; overflow: auto; background-color: rgb(246, 248, 250); word-break: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; border-radius: 3px; font-size: 12pt; color: rgb(237, 106, 67); font-variant-caps: normal; font-variant-ligatures: normal;">max_workers</span><span style="box-sizing: border-box; word-wrap: normal; overflow: auto; background-color: rgb(246, 248, 250); word-break: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; border-radius: 3px; font-size: 12pt; color: rgb(167, 29, 93); font-variant-caps: normal; font-variant-ligatures: normal;">=</span><span style="box-sizing: border-box; word-wrap: normal; overflow: auto; background-color: rgb(246, 248, 250); word-break: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; border-radius: 3px; font-size: 12pt; color: rgb(0, 134, 179); font-variant-caps: normal; font-variant-ligatures: normal;">10</span><span style="box-sizing: border-box; word-wrap: normal; overflow: auto; background-color: rgb(246, 248, 250); word-break: normal; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; border-radius: 3px; font-size: 12pt; color: rgb(36, 41, 46); font-variant-caps: normal; font-variant-ligatures: normal;">)</span></div><div><span style="font-size: 12pt;"> 并行度可以调到很高 比如 1000</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><br/></div><div><a href="https://github.com/ross/requests-futures" style="font-size: 12pt;">https://github.com/ross/requests-futures</a><span style="font-size: 12pt;"> </span></div><div><br/></div><div><br/></div><hr/><div><br/></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：实际爬取的 词条数目 与 百度百科 中统计的到词条数目不相符</span></div><div><img src="/Resources/%E5%B0%8F%E7%81%B0%E7%81%B0%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%20-%202.%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%E6%96%87%E6%A1%A3.resources/26C36448-8DE3-4805-9E54-B5741FCB5C7D.png" height="306" width="691"/><span style="font-size: 12pt;"> </span></div><div><br/></div><div><span style="font-size: 12pt;">实际爬取 ： 21380 个 词条页</span></div><div><br/></div><div><span style="font-size: 12pt;">采用记日志（ logging ）的方法，统计 因为网络阻塞 丢失的 词条页 的数量</span></div><div><br/></div><div><span style="font-size: 12pt;">以 科学百科信息科学分类 (共16018个)  为例：</span></div><div><span style="font-size: 12pt;">实际爬取： </span></div><div><span style="font-size: 12pt;">total num: 15839 </span></div><div><br/></div><div><span style="font-size: 12pt;">cost time: 3535.541276361 s （ 1 hour ）</span></div><div><br/></div><div><span style="font-size: 12pt;">文档ID 范围： 1-15839 </span></div><div><br/></div><div><span style="font-size: 12pt;">查看日志信息 spider.log，只有 一个 error</span></div><div><br/></div><div><span style="font-size: 12pt;">2020-06-11 23:33:57,658 ERROR    -----&lt;class 'socket.timeout'&gt;:</span> <a href="http://baike.baidu.com/item/%E5%A4%8D%E7%94%A8%E5%88%B6%E5%BC%8F%E8%BD%AC%E6%8D%A2/16688038-----" style="font-size: 12pt;">http://baike.baidu.com/item/%E5%A4%8D%E7%94%A8%E5%88%B6%E5%BC%8F%E8%BD%AC%E6%8D%A2/16688038</a></div><div><br/></div><div><span style="font-size: 12pt;">每次实际爬取的 数量 与 网络条件的好坏有很大关系，因此，考虑加入 异步 请求网页机制</span></div><div><br/></div></div><br/></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="从零开始搭建搜索引擎" scheme="https://xinrihui.github.io/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
    <category term="倒排索引" scheme="https://xinrihui.github.io/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    
    <category term="bm25" scheme="https://xinrihui.github.io/tags/bm25/"/>
    
    <category term="tf-idf" scheme="https://xinrihui.github.io/tags/tf-idf/"/>
    
  </entry>
  
</feed>
