<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小灰灰在青青草原</title>
  
  
  <link href="https://xinrihui.github.io/atom.xml" rel="self"/>
  
  <link href="https://xinrihui.github.io/"/>
  <updated>2023-03-10T07:00:08.949Z</updated>
  <id>https://xinrihui.github.io/</id>
  
  <author>
    <name>Xinrihui</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>分布式系统综述</title>
    <link href="https://xinrihui.github.io/2023/03/10/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0/"/>
    <id>https://xinrihui.github.io/2023/03/10/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0/</id>
    <published>2023-03-10T06:59:05.000Z</published>
    <updated>2023-03-10T07:00:08.949Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.4 (470194)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2023-03-10 06:56:56 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2023-03-10 06:57:12 +0000"/><title>分布式系统综述</title></head><body style="font-size: 14px;"><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-01.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-02.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-03.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-04.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-05.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-06.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-07.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-08.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-09.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-10.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-11.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-12.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-13.jpg" height="500" width="1000"/></div><div><img src="/Resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0.resources/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F-14.jpg" height="500" width="1000"/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="分布式数据库系列" scheme="https://xinrihui.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="分布式事务" scheme="https://xinrihui.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    
    <category term="两阶段提交" scheme="https://xinrihui.github.io/tags/%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/"/>
    
    <category term="三阶段提交" scheme="https://xinrihui.github.io/tags/%E4%B8%89%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/"/>
    
    <category term="paxo" scheme="https://xinrihui.github.io/tags/paxo/"/>
    
  </entry>
  
  <entry>
    <title>Attention 机制推导</title>
    <link href="https://xinrihui.github.io/2023/03/10/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC/"/>
    <id>https://xinrihui.github.io/2023/03/10/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC/</id>
    <published>2023-03-10T06:10:51.000Z</published>
    <updated>2023-03-10T06:13:06.300Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.4 (470194)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2023-03-10 06:03:55 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2023-03-10 06:07:25 +0000"/><title>Attention 机制推导</title></head><body style="font-size: 14px;"><div><img src="/Resources/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC.resources/attention%20%E6%9C%BA%E5%88%B6-1.jpg" height="500" width="1000"/></div><div><img src="/Resources/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC.resources/attention%20%E6%9C%BA%E5%88%B6-2.jpg" height="500" width="1000"/></div><div><img src="/Resources/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC.resources/attention%20%E6%9C%BA%E5%88%B6-3.jpg" height="500" width="1000"/></div><div><img src="/Resources/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC.resources/attention%20%E6%9C%BA%E5%88%B6-4.jpg" height="500" width="1000"/></div><div><img src="/Resources/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC.resources/attention%20%E6%9C%BA%E5%88%B6-5.jpg" height="500" width="1000"/></div><div><img src="/Resources/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC.resources/attention%20%E6%9C%BA%E5%88%B6-6.jpg" height="500" width="1000"/></div><div><img src="/Resources/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC.resources/attention%20%E6%9C%BA%E5%88%B6-7.jpg" height="500" width="1000"/></div><div><img src="/Resources/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC.resources/attention%20%E6%9C%BA%E5%88%B6-8.jpg" height="500" width="1000"/></div><div><img src="/Resources/Attention%20%E6%9C%BA%E5%88%B6%E6%8E%A8%E5%AF%BC.resources/attention%20%E6%9C%BA%E5%88%B6-9.jpg" height="500" width="1000"/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="transformer 系列" scheme="https://xinrihui.github.io/categories/transformer-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="transformer" scheme="https://xinrihui.github.io/tags/transformer/"/>
    
    <category term="nlp" scheme="https://xinrihui.github.io/tags/nlp/"/>
    
    <category term="深度学习" scheme="https://xinrihui.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Java Hash函数设计</title>
    <link href="https://xinrihui.github.io/2022/12/30/Java%20Hash%E5%87%BD%E6%95%B0%E8%AE%BE%E8%AE%A1/"/>
    <id>https://xinrihui.github.io/2022/12/30/Java%20Hash%E5%87%BD%E6%95%B0%E8%AE%BE%E8%AE%A1/</id>
    <published>2022-12-30T03:10:39.000Z</published>
    <updated>2023-03-10T05:58:08.445Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="created" content="2022-12-25 14:52:32 +0000"/><meta name="source-application" content="ios.clipper.evernote"/><meta name="updated" content="2022-12-25 14:52:32 +0000"/><title>Java Hash函数设计</title></head><body><div><img src="/Resources/Java%20Hash%E5%87%BD%E6%95%B0%E8%AE%BE%E8%AE%A1.resources/%E5%93%88%E5%B8%8C%E8%A1%A8-1.jpg" height="500" width="1000"/></div><div><img src="/Resources/Java%20Hash%E5%87%BD%E6%95%B0%E8%AE%BE%E8%AE%A1.resources/%E5%93%88%E5%B8%8C%E8%A1%A8-2.jpg" height="500" width="1000"/></div><div><img src="/Resources/Java%20Hash%E5%87%BD%E6%95%B0%E8%AE%BE%E8%AE%A1.resources/%E5%93%88%E5%B8%8C%E8%A1%A8-3.jpg" height="500" width="1000"/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="数据结构和算法" scheme="https://xinrihui.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="hash表" scheme="https://xinrihui.github.io/tags/hash%E8%A1%A8/"/>
    
    <category term="java" scheme="https://xinrihui.github.io/tags/java/"/>
    
    <category term="散列函数" scheme="https://xinrihui.github.io/tags/%E6%95%A3%E5%88%97%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>Phoenix 原理</title>
    <link href="https://xinrihui.github.io/2022/12/29/Phoenix%20%E5%8E%9F%E7%90%86/"/>
    <id>https://xinrihui.github.io/2022/12/29/Phoenix%20%E5%8E%9F%E7%90%86/</id>
    <published>2022-12-29T02:26:18.000Z</published>
    <updated>2022-12-29T02:26:47.661Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2022-12-29 02:21:35 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2022-12-29 02:23:39 +0000"/><title>Phoenix 原理</title></head><body><div><span style="font-weight: bold;">1.rowkey 与 主键的关系</span></div><div><br/></div><div>包括在 primary key  中的字段 会全部 放在 rowkey 中；</div><div><span style="font-weight: bold;">未包括在 rowkey  中的字段 会作为 hbase 的列</span>，可以 有多个 非primary key 字段，对应的是多个列；</div><div><br/></div><div>eg.</div><div><br/></div><div><img src="/Resources/Phoenix%20%E5%8E%9F%E7%90%86.resources/Image.png" height="513" width="1075"/><br/></div><div><br/></div><div>上述例子中 ，rowkey= name  , 那么 转换为  Phoenix 的表结构为</div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 203px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="background-color: rgb(252, 83, 86); border: 1px solid rgb(251, 17, 21); width: 203px; padding: 8px;"><div><span style="color: rgb(255, 255, 255);">name（</span><span style="color: rgb(255, 255, 255); font-weight: bold;">primary key</span><span style="color: rgb(255, 255, 255);">）</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>city </div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>phone </div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>phone </div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td></tr><tr><td style="width: 203px; padding: 8px; border: 1px solid;"><div>张三</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>北京</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>131****</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td></tr><tr><td style="width: 203px; padding: 8px; border: 1px solid;"><div>李四</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>上海</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>132***</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td></tr><tr><td style="width: 203px; padding: 8px; border: 1px solid;"><div>王五</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>广州</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>159***</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td></tr></tbody></table><div><br/></div><div><br/></div><div>其中，成为主键的 字段为 name ，非主键 字段为  city 和 phone </div><div><br/></div><div>select  name , city  from  personal_info  where  city='北京' ; （非主键 的查询 执行会很慢）</div><div><br/></div><div>可以看出 和 关系模型 一模一样。 </div><div>但是， 关系模型中的 表 的结构 往往是固定的，而 Phoenix  的表 可以 加入 很多个列</div><div><br/></div><div>eg.</div><div>volumn_table</div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 191px;"/><col style="width: 191px;"/></colgroup><tbody><tr><td style="background-color: rgb(252, 83, 86); border: 1px solid rgb(251, 17, 21); width: 130px; padding: 8px;"><div><span style="color: rgb(255, 255, 255);">基金账户</span></div></td><td style="background-color: rgb(252, 83, 86); border: 1px solid rgb(251, 17, 21); width: 130px; padding: 8px;"><div><span style="color: rgb(255, 255, 255);">交易账户</span></div></td><td style="background-color: rgb(252, 83, 86); border: 1px solid rgb(251, 17, 21); width: 130px; padding: 8px;"><div><span style="color: rgb(255, 255, 255);">基金代码</span></div></td><td style="width: 191px; padding: 8px; border: 1px solid;"><div>2020-06-01</div></td><td style="width: 191px; padding: 8px; border: 1px solid;"><div>2020-06-02</div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div>9800010</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>000101</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>226</div></td><td style="width: 191px; padding: 8px; border: 1px solid;"><div>volumn：100</div></td><td style="width: 191px; padding: 8px; border: 1px solid;"><div>volumn：200</div></td></tr></tbody></table><div>字段 基金账户+ 交易账户 + 基金代码 作为联合 主键 ，每一个 日期字段 作为 列 不断 追加到 hbase 中</div><div><br/></div><div>select  FA ,  transactionAccount , fundcode , "2020-06-01"  from volumn_table where FA='9800010'</div><div><br/></div><div>还可以 进行模糊查询：</div><div><br/></div><div>select  FA ,  transactionAccount , fundcode , "2020-06-01"  from volumn_table where FA like'98%' limit 10</div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">2.分区</span></div><div><br/></div><div>（1）预分区</div><div>   </div><div>与 HBase预分区 相同，在建phoenix表时，可以精确的指定要根据什么值来做预分区 ：</div><div><br/></div><div>当可以提前知道 row key 的分布的时候，可以指定每个预分区的 region 的分割点，上面命令创建的表中，有 5 个 Region</div><div><br/></div><div>create table testlocal</div><div>(id integer primary key,</div><div>name varchar,</div><div>age integer,</div><div>address varchar) split on (10, 20, 30, 40);</div><div><br/></div><div>Region 1 : row key 的前两位是 min~10</div><div><br/></div><div>Region 2 : row key 的前两位是 10~20</div><div><br/></div><div>Region 3 : row key 的前两位是 20~30</div><div><br/></div><div>Region 4 : row key 的前两位是 30~40</div><div><br/></div><div>Region 5 : row key 的前两位是 40~max</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div>（2）加盐 分区</div><div><br/></div><div>加盐能解决 HBASE读写热点问题，例如:单调递增rowkey数据的持续写入，使得负载集中在某一个RegionServer上引起的热点问题。</div><div><br/></div><div>在创建表的时候指定属性值：SALT_BUCKETS，其值表示所分buckets(region)数量， 范围是1~256。</div><div><br/></div><div>CREATE TABLE SALT_TABLES (a_key VARCHAR PRIMARY KEY, a_col VARCHAR) <span style="font-weight: bold;">SALT_BUCKETS</span> = 20;</div><div><br/></div><div><img src="/Resources/Phoenix%20%E5%8E%9F%E7%90%86.resources/21D7FFA1-7309-438A-B26B-E92639B68566.png" height="736" width="1060"/></div><div><br/></div><div><br/></div><div>加盐的过程就是在原来key的基础上增加一个byte作为前缀,计算公式如下：</div><div>    new_row_key = (++index % BUCKETS_NUMBER) + original_key</div><div><br/></div><div>下图展示了 自增rowkey 通过加盐 被打散写入到各个region中的过程：</div><div><img src="/Resources/Phoenix%20%E5%8E%9F%E7%90%86.resources/5D0ECEDA-CD62-4FDD-BDF3-726DEC811D0B.png" height="337" width="505"/></div><div><br/></div><div>当可用 <span style="font-weight: bold;">block cache</span> （ 见  《分布式存储和数据库》-&gt; HBase 原理1 ） 的大小 小于表数据大小时，较优的slated bucket是和region server数量相同，这样可以得到更好的读写性能。</div><div><br/></div><div>当表的数量很大时，基本上会忽略blcok cache的优化收益，大部分数据仍然需要走磁盘IO。比如对于10个region server集群的大表，可以考虑设计 64~128个 slat buckets。</div><div><br/></div><div>因为数据 被散列在 多个桶中，所以返回的数据 的 rowkey 不会像 未采用 slated bucket 那样是 有序的，如果要求返回的数据 有序，可以将 phoenix.query.rowKeyOrderSaltedTable 设置为 ture </div><div><br/></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">问题：为什么 采用  SALT_BUCKETS 会加速 phoenix 的 bulkload 导入 数据</span></div><div><br/></div><div>SALT_BUCKETS 即 Hash 分桶，桶即 region , 多个 桶 利用 MapReduce 并发写（在多个节点），写入效率大大提升。</div><div>但是 在查询时，由于 region 的划分 并没有规律，所以在  所有的  region 都要进行 搜索，这也符合 region 划分的散列原则 ，可以避免数据热点</div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://www.cnblogs.com/hbase-community/p/8727674.html">https://www.cnblogs.com/hbase-community/p/8727674.html</a></div><div><a href="https://blog.csdn.net/silentwolfyh/article/details/51613317">https://blog.csdn.net/silentwolfyh/article/details/51613317</a></div><div><a href="http://phoenix.apache.org/salted.html">http://phoenix.apache.org/salted.html</a></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="分布式数据库系列" scheme="https://xinrihui.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="HBase" scheme="https://xinrihui.github.io/tags/HBase/"/>
    
    <category term="Phoenix" scheme="https://xinrihui.github.io/tags/Phoenix/"/>
    
  </entry>
  
  <entry>
    <title>HBase 性能优化</title>
    <link href="https://xinrihui.github.io/2022/12/29/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <id>https://xinrihui.github.io/2022/12/29/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</id>
    <published>2022-12-29T02:26:18.000Z</published>
    <updated>2023-03-10T15:20:33.399Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2020-12-29 02:46:01 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="https://www.cnblogs.com/smartloli/p/9425343.html"/><meta name="updated" content="2022-12-29 02:18:18 +0000"/><title>hbase 性能优化</title></head><body><div><div><div>&nbsp;&nbsp;</div><div><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">1.内存 调优</span></div><div><b style="font-size: 12pt;"><br/></b></div><div><span style="font-size: 12pt; font-weight: bold;">1.1 调大 JVM 的堆内存</span></div><div><b style="font-size: 12pt;"><br/></b></div><div><span style="font-size: 12pt;">（1）修改$HBASE_HOME/conf/hbase-env.sh，</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">export HBASE_HEAPSIZE=8G</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">这个参数会影响所有HBase实例，包括Master和Region。这样的话</span><span style="font-size: 12pt; color: unset; font-family: unset;">Master和RegionServer都会占用8GB。不过我建议大家用Master和</span><span style="font-size: 12pt; color: unset; font-family: unset;">RegionServer专有的参数来分别设定他们的内存大小。</span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/45D2C9E6-6244-4C9A-B009-C8C2DD36ACF7.png" height="59" width="753"/></span></div><div><b style="font-size: 12pt;"><br/></b></div><div><span style="font-size: 12pt;">现在有一台16GB的机器，上面有MapReduce服务、</span><span style="font-size: 12pt; color: unset; font-family: unset;">RegionServer和DataNode（这三位一般都是装在一起的），那么建议按</span><span style="font-size: 12pt; color: unset; font-family: unset;">照如下配置设置内存：</span></div><div><b style="font-size: 12pt;"><br/></b></div><div><span style="font-size: 12pt;">2GB：留给系统进程。</span></div><div><span style="font-size: 12pt;">8GB：MapReduce服务。平均每1GB分配 6个Map slots + 2个</span><span style="font-size: 12pt; color: unset; font-family: unset;">Reduce slots。</span></div><div><span style="font-size: 12pt;">4GB：HBase的RegionServer服务。</span></div><div><span style="font-size: 12pt;">1GB：TaskTracker。</span></div><div><span style="font-size: 12pt;">1GB：DataNode。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">如果同时运行MapReduce的话，RegionServer将是除了MapReduce以</span><span style="font-size: 12pt; color: unset; font-family: unset;">外使用内存最大的服务。如果没有MapReduce的话，RegionServer可以</span><span style="font-size: 12pt; color: unset; font-family: unset;">调整到大概一半的服务器内存。</span></div><div><b style="font-size: 12pt;"><br/></b></div><div><b style="font-size: 12pt;"><br/></b></div><div><b style="font-size: 12pt;"><br/></b></div><div><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">1.2 BlockCache&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">读请求先到Memstore中查数据，查不到就到BlockCache中查，再查不到就会到磁盘上读，并把读的结果放入BlockCache。由于BlockCache采用的是LRU策略，因此BlockCache达到上限 (heapsize&nbsp;&nbsp;*&nbsp;&nbsp;hfile.block.cache.size&nbsp;&nbsp;*&nbsp;&nbsp;0.85) 后，会启动淘汰机制，淘汰掉最老的一批数据。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">一个Regionserver上有一个BlockCache和N个Memstore，它们的大小之和不能大于等于heapsize&nbsp;&nbsp;*&nbsp;&nbsp;0.8，否则HBase不能启动。对于注重读响应时间的系统，可以将&nbsp;&nbsp;BlockCache设大些，比如设置BlockCache=0.4，Memstore=0.39，以加大缓存的命中率。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">可以通过在hbase-site.xml配置以下属性来实现：</span></div><div><span style="font-size: 12pt;">* hfile.block.cache.size，默认0.4，用来提高读性能</span></div><div><span style="font-size: 12pt;">* hbase.regionserver.global.memstore.size，默认0.4，用来提高写性能</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">为了提高读性能，这里我们可以将BlockCache的占比设置大一些，Memstore 的占比设置小一些（总占比保持在0.8即可）。</span></div><div><span style="font-size: 12pt;">另外，BlockCache的策略选择也是很重要的，不同的策略对于读性能来说影响不大，但是对于GC的影响却比较明显，在设置 hbase.bucketcache.ioengine 属性为 offheap时，GC表现的很优秀。缓存结构如下图所示：</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/7ACBF8B4-BD93-4063-B2A9-73E25BE19C8B.png" height="700" width="838"/></span></div><div><span style="font-size: 12pt;">JVM 的堆内存 和 堆外内存的 大小可以 在 hbase-env.sh 中配置。因为 栈内存很小 所以 JVM 不用配置 栈内存的大小。&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">设置BlockCache可以在 hbase-site.xml 文件中，配置如下属性：</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">&lt;!-- 分配的内存大小尽可能的多些，前提是不能超过 (机器实际物理内存-JVM内存) --&gt;</span></div><div><span style="font-size: 12pt;"><property>&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<name>hbase.bucketcache.size</name>&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<value>16384</value></span></div><div><span style="font-size: 12pt;">&lt;/property&gt;</span></div><div><span style="font-size: 12pt;">&lt;property&gt;</span></div><div><span style="font-size: 12pt;">&lt;name&gt;hbase.bucketcache.ioengine&lt;/name&gt;</span></div><div><span style="font-size: 12pt;">&lt;value&gt;offheap&lt;/value&gt;</span></div><div><span style="font-size: 12pt;">&lt;/property&gt;</span></div><div><span style="font-size: 12pt;"><br/></span></div><div style="margin: 10px auto; padding: 0px; text-indent: 0px; letter-spacing: normal; orphans: 2; text-align: left; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);"><span style="text-indent: 0px; letter-spacing: normal; orphans: 2; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">设置块内存大小，可以参考入下表格：</span></span></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 352px;"/><col style="width: 282px;"/><col style="width: 130px;"/></colgroup><tbody style="margin: 0px; padding: 0px;"><tr style="padding: 0px;"><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">标号</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 352px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">描述</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 282px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">计算公式或值</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">结果</span></div></td></tr><tr style="padding: 0px;"><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">A</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 352px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">物理内存选择：on-heap(JVM)+off-heap(Direct)</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 282px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">单台物理节点内存值，单位MB</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">262144</span></div></td></tr><tr style="padding: 0px;"><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">B</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 352px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">HBASE_HEAPSIZE('-Xmx)</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 282px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">单位MB</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">20480</span></div></td></tr><tr style="padding: 0px;"><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">C</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 352px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">-XX:MaxDirectMemorySize，off-heap允许的最大内存值</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 282px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">A-B</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">241664</span></div></td></tr><tr style="padding: 0px;"><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">Dp</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 352px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">hfile.block.cache.size 和hbase.regionserver.global.memstore.size总和不要超过0.8</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 282px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">读取比例占比*0.8</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">0.5*0.8=0.4</span></div></td></tr><tr style="padding: 0px;"><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">Dm</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 352px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">JVM Heap允许的最大BlockCache（MB）</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 282px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">B*Dp</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">20480*0.4=8192</span></div></td></tr><tr style="padding: 0px;"><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">Ep</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 352px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">hbase.regionserver.global.memstore.size设置的最大JVM值</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 282px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">0.8-Dp</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">0.8-0.4=0.4</span></div></td></tr><tr style="padding: 0px;"><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">F</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 352px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">用于其他用途的off-heap内存，例如DFSClient</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 282px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">推荐1024到2048</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">2048</span></div></td></tr><tr style="padding: 0px;"><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">G</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 352px; padding: 8px;"><div style="font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">BucketCache允许的off-heap内存</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 282px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">C-F</span></div></td><td style="border-collapse: collapse; border: 1px solid rgb(192, 192, 192); width: 130px; padding: 8px;"><div style="font-size: 14px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">241664-2048=239616</span></div></td></tr></tbody></table><div><br/></div><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">引用</span></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><a href="https://www.cnblogs.com/smartloli/p/9425343.html" style="font-size: 12pt;">https://www.cnblogs.com/smartloli/p/9425343.html</a></span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">1.2.1&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">LRUBlock Cache</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">首当其冲的肯定就是完全基于JVM heap的LRU方案了。在0.92版本&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">之前只有这种BlockCache的实现方案。LRU就是Least Recently Used，</span><span style="font-size: 12pt;">即近期最少使用算法的缩写。读出来的block会被放到BlockCache中待</span><span style="font-size: 12pt; color: unset; font-family: unset;">下次查询使用。当缓存满了的时候，会根据LRU的算法来淘汰block。</span><span style="font-size: 12pt; color: unset; font-family: unset;">LRUBlockCache 被分为三个区域，</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">目前BlockCache的堆内内存方案就只有LRUBlockCache，而且你还</span><span style="font-size: 12pt; color: unset; font-family: unset;">关不掉它，只能调整它的大小。</span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">相关参数为：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/A61CCA7B-7C6F-41FB-B882-1D94ACFDE2E2.png" height="27" width="613"/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">设置 hfile.block.cache.size 的时候要注意在HBase的内存使用上有一个规则那就是 Memstor+ BlockCache 的内存占用比例不能超过0.8（即80%），否则就要报错。因为必须要留20%作为机动空间。用配置项来说明：</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/124E4ED6-34AB-4967-BAD8-87A13EFB89A7.png" height="28" width="638"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">值得一提的是，这两个配置项的默认值都是0.4，也就是说默认项</span><span style="font-size: 12pt; color: unset; font-family: unset;">的总和就已经达到了他们俩可以占用的内存比例上限了，所以基本没事</span><span style="font-size: 12pt; color: unset; font-family: unset;">就不用去加大这两个配置项，你调大哪一个，都必须相应地调小另外一</span><span style="font-size: 12pt; color: unset; font-family: unset;">个。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">但是LRUBlockCache有什么坏处呢？</span><span style="font-size: 12pt; color: unset; font-family: unset;">完全基于JVM Heap的缓存，势必带来一个后果：随着内存中对象越</span><span style="font-size: 12pt; color: unset; font-family: unset;">来越多，每隔一段时间都会引发一次Full GC。凡是做了几年Java的人</span><span style="font-size: 12pt; color: unset; font-family: unset;">听到Full GC都会浑身一颤。在Full GC的过程中，整个JVM完全处于停</span><span style="font-size: 12pt; color: unset; font-family: unset;">滞状态，有的时候长达几分钟</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">1.2.2&nbsp;&nbsp;</span><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">Bucket Cache</span></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">JVM对</span><span style="font-size: 12pt; color: unset; font-family: unset;">堆（Heap）的管理很完善，会自动地回收对象，而不是像C语言一样要</span><span style="font-size: 12pt; color: unset; font-family: unset;">手动去回收，这就是大家从C语言转到Java的众多理由之一。这部分内</span><span style="font-size: 12pt;">存叫堆内内存（on-heap memory）。堆外内存（off-heap memory）是</span><span style="font-size: 12pt; color: unset; font-family: unset;">不属于JVM管理的内存范围，说白了，就是原始的内存区域了。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">堆外内</span><span style="font-size: 12pt; color: unset; font-family: unset;">存的大小可以通过-XX:MaxDirectMe morySize=60MB这样来设置。可是</span><span style="font-size: 12pt; color: unset; font-family: unset;">用堆外内存肯定没有像用堆内内存那么好用啊，因为这就是一片原始的</span><span style="font-size: 12pt; color: unset; font-family: unset;">荒野，没有什么管理机制，那为什么要用它呢？</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">最大的好处就是：回收堆外内存的时候JVM几乎不会停顿，这样再</span><span style="font-size: 12pt; color: unset; font-family: unset;">也不用怕回收的时候业务系统卡住了。既然堆外内存回收的时候不会</span><span style="font-size: 12pt; color: unset; font-family: unset;">卡，为什么大家不都去用它呀？这是因为堆外 内存的缺点几乎比它带</span><span style="font-size: 12pt; color: unset; font-family: unset;">来的好处还大：</span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">因为在堆外内存存储的数据都是很原始的数据，如果是一个对</span><span style="font-size: 12pt; color: unset; font-family: unset;">象，比如先序列化之后才能存储，所以不能存储太复杂的对象。</span></div></li><li><div><span style="font-size: 12pt;">堆外内存并不是在JVM的管理范围，所以当内存泄露的时候很不</span><span style="font-size: 12pt; color: unset; font-family: unset;">好排查问题。</span></div></li><li><div><span style="font-size: 12pt;">堆外内存由于用的是系统内存，当你用的太大的时候，物理内存</span><span style="font-size: 12pt; color: unset; font-family: unset;">有可能爆掉，或者直接开启了虚拟内存，也就是直接影响到了硬</span><span style="font-size: 12pt; color: unset; font-family: unset;">盘的使用。</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">BucketCache借鉴了SlabCache的创意，也用上了堆外内存。不过它</span><span style="font-size: 12pt; color: unset; font-family: unset;">是这么用的：</span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">BucketCache一上来就分配了</span><span style="font-size: 12pt; color: unset; font-family: unset;">14种区域。注意：我这里说的是14种区域，并不是14块区域。这</span><span style="font-size: 12pt; color: unset; font-family: unset;">14种区域分别放的是大小为4KB、8KB、16KB、32KB、40KB、</span><span style="font-size: 12pt; color: unset; font-family: unset;">48KB、56KB、64KB、96KB、128KB、192KB、256KB、384KB、</span><span style="font-size: 12pt; color: unset; font-family: unset;">512KB的Block。而且这个种类列表还是可以手动通过设置&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">hbase.bucketcache.bucket.sizes 属性来定义（种类之间用逗号</span><span style="font-size: 12pt; color: unset; font-family: unset;">分隔，想配几个配几个，不一定是14个！），这14种类型可以分</span><span style="font-size: 12pt; color: unset; font-family: unset;">配出很多个Bucket</span></div></li><li><div><span style="font-size: 12pt;">BucketCache的存储不一定要使用堆外内存，是可以自由在3种存</span><span style="font-size: 12pt; color: unset; font-family: unset;">储介质直接选择：堆（heap）、堆外（offheap）、文件</span><span style="font-size: 12pt; color: unset; font-family: unset;">（file）。通过设置hbase.bucketcache.ioengine为heap、</span><span style="font-size: 12pt; color: unset; font-family: unset;">offfheap或者file来配置。</span></div></li><li><div><span style="font-size: 12pt;">每个Bucket的大小上限为最大尺寸的block * 4，比如可以容纳</span><span style="font-size: 12pt; color: unset; font-family: unset;">的最大的Block类型是512KB，那么每个Bucket的大小就是 512KB</span><span style="font-size: 12pt; color: unset; font-family: unset;">* 4 = 2048KB。</span></div></li><li><div><span style="font-size: 12pt;">系统一启动BucketCache就会把可用的存储空间按照每个Bucket</span><span style="font-size: 12pt; color: unset; font-family: unset;">的大小上限均分为多个Bucket。如果划分完的数量比你的种类还</span><span style="font-size: 12pt; color: unset; font-family: unset;">少，比如比14（默认的种类数量）少，就会直接报错，因为每一</span><span style="font-size: 12pt; color: unset; font-family: unset;">种类型的Bucket至少要有一个Bucket。</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">BucketCache实现起来的样子就像如图8-12所示（每个区域的大小</span><span style="font-size: 12pt; color: unset; font-family: unset;">都是512 * 4）。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/AC705B76-BB0E-4D65-AA43-1BB6E7811D8D.png" height="363" width="567"/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">BucketCache还有一个特别的长处，那就是它自己来划分内存空</span><span style="font-size: 12pt; color: unset; font-family: unset;">间、自己来管理内存空间，Block放进去的时候是考虑到offset偏移量</span><span style="font-size: 12pt; color: unset; font-family: unset;">的（具体可以看源码的BucketAllocator），所以内存碎片少，发生GC&nbsp;&nbsp;</span><span style="font-size: 12pt;">的时间很短。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">大家不要忘记了还有SSD硬盘，最开始设计这种策</span><span style="font-size: 12pt; color: unset; font-family: unset;">略的初衷就是想把SSD作为一层比传统机械硬盘更快的缓存层来使用，</span><span style="font-size: 12pt; color: unset; font-family: unset;">所以你可以把file这种类型等同于SSD-file。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">BucketCache相关配置项如下：</span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">hbase.bucketcache.ioengine：使用的存储介质，可选值为&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">heap、offheap、file。不设置的话，默认为offheap。</span></div></li><li><div><span style="font-size: 12pt;">hbase.bucketcache.combinedcache.enabled：是否打开 <span style="font-size: 12pt; font-weight: bold;">组合模</span></span><span style="font-size: 12pt; color: unset; font-family: unset;"><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">式</span>（CombinedBlockCache），默认为true，</span></div></li><li><div><span style="font-size: 12pt;">hbase.bucketcache.size：BucketCache所占的大小。</span><span style="font-size: 12pt; color: unset; font-family: unset;">如果设置为0.0~1.0，则代表了占堆内存的百分比。</span><span style="font-size: 12pt; color: unset; font-family: unset;">如果是大于1的值，则代表实际的BucketCache的大小，单位为MB。&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">默认值为0.0，即关闭BucketCache</span></div></li><li><div><span style="font-size: 12pt;">hbase.bucketcache.bucket.sizes：定义所有Block种类，默认</span><span style="font-size: 12pt; color: unset; font-family: unset;">为14种，种类之间用逗号分隔。单位为B，每一种类型必须是</span><span style="font-size: 12pt; color: unset; font-family: unset;">1024的整数倍，否则会报异常：java.io.IOException: Invalid&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">HFile block magic。默认值为：4、8、16、32、40、48、56、</span><span style="font-size: 12pt; color: unset; font-family: unset;">64、96、128、192、256、384、512。</span></div></li><li><div><span style="font-size: 12pt;">-XX:MaxDirectMemorySize：这个参数不是在hbase-site.xml中&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">配置的，而是JVM启动的参数。如果你不配置这个参数，JVM会按&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">需索取堆外内存；如果你配置了这个参数，你可以定义JVM可以&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">获得的堆外内存上限。显而易见的，这个参数值必须比&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">hbase.bucketcache.size大。</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">组合模式</span></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">在BucketCache的时代，也不是单纯地使用BucketCache，但是这回不是一二级缓存的结合；而是另一种模式，叫组合模式（CombinedBlockCahce）。具体地说就是把不同类型的Block分别放到LRUCache和BucketCache中。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">Index Block和Bloom Block会被放到LRUCache中。Data Block被直接放到BucketCache中，所以数据会去LRUCache查询一下，然后再去BucketCache中查询真正的数据。其实这种实现是一种更合理的二级缓存，数据从一级缓存到二级缓存最后到硬盘，数据是从小到大，存储介质也是由快到慢。考虑到成本和性能的组合，比较合理的介质是：LRUCache使用内存-&gt;BuckectCache使用SSD-&gt;HFile使用机械硬盘。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">关于LRUBlockCache和BucketCache单独使用谁比较强，曾经有人做</span><span style="font-size: 12pt; color: unset; font-family: unset;">过一个测试，并写了一篇报告出来，标题为Comparing BlockCache&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">Deploys，结论是：</span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">因为BucketCache自己控制内存空间，碎片比较少，所以GC时间&nbsp;&nbsp;</span><span style="font-size: 12pt;">大部分都比LRUCache短。</span></div></li><li><div><span style="font-size: 12pt;">在缓存全部命中的情况下，LRUCache的吞吐量是BucketCache的</span><span style="font-size: 12pt; color: unset; font-family: unset;">两倍；在缓存基本命中的情况下，LRUCache的吞吐量跟&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">BucketCache基本相等。</span></div></li><li><div><span style="font-size: 12pt;">读写延迟，IO方面两者基本相</span><span style="font-size: 12pt; color: unset; font-family: unset;">等。</span></div></li><li><div><span style="font-size: 12pt;">缓存全部命中的情况下，LRUCache比使用fiile模式的&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">BucketCache CPU占用率低一倍，但是跟其他情况下差不多。</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">从整体上说LRUCache的性能好于BucketCache，但由于Full GC的存</span><span style="font-size: 12pt; color: unset; font-family: unset;">在，在某些时刻JVM会停止响应，造成服务不可用。所以适当的搭配</span><span style="font-size: 12pt; color: unset; font-family: unset;">BucketCache可以缓解这个问题。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">1.3 GC 调优</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">随着内存的加大，有一个不容忽视的问题也出现了，那就是JVM的</span><span style="font-size: 12pt; color: unset; font-family: unset;">堆内存越大，Full GC的时间越久。Full GC有时候可以达到好几分钟。</span><span style="font-size: 12pt; color: unset; font-family: unset;">在Full GC的时候JVM会停止响应任何的请求，整个JVM的世界就像是停</span></div><div><span style="font-size: 12pt;">止了一样，所以这种暂停又被叫做Stop-The-World（STW）。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">当ZooKeeper像往常一样通过心跳来检测RegionServer节点是否存</span><span style="font-size: 12pt; color: unset; font-family: unset;">活的时候，发现已经很久没有接收到来自RegionServer的回应，会直接</span><span style="font-size: 12pt; color: unset; font-family: unset;">把这个RegionServer标记为已经宕机。等到这台RegionServer终于结束</span><span style="font-size: 12pt; color: unset; font-family: unset;">了Full GC后，去查看ZooKeeper的时候会发现原来自己已经“被宕</span><span style="font-size: 12pt; color: unset; font-family: unset;">机”了，为了防止脑裂问题的发生，它会自己停止自己。这种场景称为</span><span style="font-size: 12pt; color: unset; font-family: unset;">RegionServer自杀，它还有另一个美丽的名字叫朱丽叶暂停，而且这问</span><span style="font-size: 12pt; color: unset; font-family: unset;">题还挺常见的，早期一直困扰着HBase开发人员。所以我们一定要设定</span><span style="font-size: 12pt; color: unset; font-family: unset;">好GC回收策略，避免长时间的Full GC发生，或者是尽量减小Full GC的</span><span style="font-size: 12pt; color: unset; font-family: unset;">时间。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">由于数据都是在RegionServer里面的，Master只是做一些管理操</span><span style="font-size: 12pt; color: unset; font-family: unset;">作，所以一般内存问题都出在RegionServer上。接下来主要用</span><span style="font-size: 12pt; color: unset; font-family: unset;">RegionServer来讲解参数配置</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">JVM提供了4种GC回收</span></div><ul><li><div><span style="font-size: 12pt;">串行回收器（SerialGC）。</span></div></li><li><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">并行回收器（ParallelGC）</span>，主要针对年轻带进行优化（JDK 8&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">默认策略）。</span></div></li><li><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">并发回收器</span>（ConcMarkSweepGC，简称CMS），主要针对年老带进</span><span style="font-size: 12pt; color: unset; font-family: unset;">行优化。</span></div></li><li><div><span style="font-size: 12pt;">G1GC回收器，主要针对大内存（32GB以上才叫大内存）进行优</span><span style="font-size: 12pt; color: unset; font-family: unset;">化。</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">1.3.1 ParallelGC和CMS的组合方案</span></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">并行收回器的性能虽然没有串行回收器那么好，但是Full GC时间</span><span style="font-size: 12pt; color: unset; font-family: unset;">较短。对于RegionServer来说，Full GC是致命的，就算性能下降一些</span><span style="font-size: 12pt; color: unset; font-family: unset;">也没有关系，所以我们最好使用并行回收器。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">并发回收器主要是减少老年代的暂停时间，可以保证应用不停止的</span><span style="font-size: 12pt; color: unset; font-family: unset;">情况下进行收集。但是它也有缺点，那就是每次都会留下一些“浮动垃</span><span style="font-size: 12pt; color: unset; font-family: unset;">圾”。这些浮动垃圾只能在下次垃圾回收的时候被回收，不过这些我们</span><span style="font-size: 12pt; color: unset; font-family: unset;">也可以忍受。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">基于以上描述比较符合HBase的配置是：</span></div><ul><li><div><span style="font-size: 12pt;">年轻带使用并行回收器ParallelGC。</span></div></li><li><div><span style="font-size: 12pt;">年老带使用并发回收器ConcMarkSweepGC。</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">修改的方式还是修改$HBASE_HOME/conf/hbase-env.sh，</span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/8889B69B-175F-4056-AF5B-928A781EB61B.png" height="44" width="689"/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">1.3.2 G1 GC方案</span></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">如果你的JDK版本大于1.7.0_04（JDK7 update4），并且你的&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">RegionServer内存大于4GB&nbsp;&nbsp;</span><span style="font-size: 12pt;">可以考虑使用G1GC策略，这是JDK 7新</span><span style="font-size: 12pt; color: unset; font-family: unset;">加入的策略。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">这种策略专门适用于堆内存很大的情况。引入G1GC策略的原因是，</span><span style="font-size: 12pt; color: unset; font-family: unset;">就算采用了CMS策略，我们还是不能避免Full GC。因为在以下两种情况</span><span style="font-size: 12pt; color: unset; font-family: unset;">下，CMS还是会触发Full GC：</span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">在CMS工作的时候，有一些对象要从年轻代移动到老年代，但是</span><span style="font-size: 12pt; color: unset; font-family: unset;">此时老年代空间不足了，此时只能触发Full GC，然后引发&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">STW（Stop The World）暂停，JVM又开始不响应任何请求了。</span></div></li><li><div><span style="font-size: 12pt;">当被回收掉的内存空间太碎太细小，导致新加入老年代的对象放</span><span style="font-size: 12pt; color: unset; font-family: unset;">不进去，只好触发Full GC来整理空间，JVM还是会进入不响应任</span><span style="font-size: 12pt; color: unset; font-family: unset;">何请求的状态。</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">G1GC策略通过把堆内存划分为多个Region，然后对各个Region单独</span><span style="font-size: 12pt; color: unset; font-family: unset;">进行GC，这样整体的Full GC可以被最大限度地避免（Full GC还是不可</span><span style="font-size: 12pt; color: unset; font-family: unset;">避免的，我们只是尽力延迟Full GC的到来时间），而且这种策略还可</span><span style="font-size: 12pt; color: unset; font-family: unset;">以通过手动指定MaxGCPauseMillis参数来控制一旦发生Full GC的时候</span><span style="font-size: 12pt; color: unset; font-family: unset;">的最大暂停时间，避免时间太长造成RegionServer自杀。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">有一些简单的方式可以决</span><span style="font-size: 12pt; color: unset; font-family: unset;">定使用哪种策略：</span></div><ul><li><div><span style="font-size: 12pt;">RegionServer内存小于4GB，就不需要考虑G1GC策略</span><span style="font-size: 12pt; color: unset; font-family: unset;">了，直接用-XX:+UseParNewGC-XX:+UseConcMarkSweepGC。</span></div></li><li><div><span style="font-size: 12pt;">RegionServer内存大于32GB，建议使用G1GC策略</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">eg.</span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0); font-family: unset;">问题：通过jstat命令发现 regionserver进程 full GC非常的频繁，甚至发现full GC的次数比young gc的次数还要多。full gc严重导致region server不稳定，经常运行几天后regionserver会死掉。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">原因：通过分析gc log以及实时观察，发现主要是读频发的时候，young区的S1，S2会很快到达100%，导致新的对象快速进入old区，此外，old区full gc不能有效快速回收内存，导致old去的内存一直维持在高位（总是高于设定的CMSInitiatingOccupancyFraction），所以导致old gc比young gc还多。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">尝试办法：由于young区在hbase读频繁的时候很快被填满，所以很自然的尝试便是增大young区的大小。但是大了以后产生了两个负面效果，一是young gc时间变长了，二是还是不能解决read的时候young区被快速填满的问题。这时意识到，单纯通过GC调参来解决full gc频繁问题的思路行不通了。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">优化后的GC配置：</span></div><div><span style="font-size: 12pt;">export HBASE_MASTER_OPTS="$HBASE_MASTER_OPTS $HBASE_JMX_BASE -Xmx2000m -Xms2000m -Xmn750m -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:-CMSIncrementalMode -XX:CMSInitiatingOccupancyFraction=70"</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">export HBASE_REGIONSERVER_OPTS="$HBASE_REGIONSERVER_OPTS $HBASE_JMX_BASE -Xmx16000m -Xms16000m -Xmn7000m -XX:MaxDirectMemorySize=5g -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:-CMSIncrementalMode -XX:CMSInitiatingOccupancyFraction=75 -Xloggc:${HOME}/hdp_data/hbase/rs.log-`date +'%Y%m%d%H%M'` -verbose:gc -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCApplicationConcurrentTime -XX:SurvivorRatio=2 -XX:+PrintTenuringDistribution"</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">引用</span></span></div><div><span style="font-size: 12pt;"><a href="https://www.cnblogs.com/superhedantou/p/5424682.html" style="font-size: 12pt;">https://www.cnblogs.com/superhedantou/p/5424682.html</a></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">2.数据的 压缩 与 编码</span></font></div></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">2.1 压缩</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase在写入数据块到HDFS之前会首先对数据块进行压缩，再落盘，从而可以减少磁盘空间使用量。而在读数据的时候首先从HDFS中加载出block块之后进行解压缩，然后再缓存到BlockCache，最后返回给用户。写路径和读路径分别如下：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/C26F6AF6-0D1E-412D-AA8E-52645832AD04.png" height="166" width="737"/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">（1） 资源使用情况：压缩最直接、最重要的作用即是减少数据硬盘容量，理论上snappy压缩率可以达到5:1，但是根据测试数据不同，压缩率可能并没有理论上理想；压缩/解压缩无疑需要大量计算，需要大量CPU资源；根据读路径来看，数据读取到缓存之前block块会先被解压，缓存到内存中的block是解压后的，因此和不压缩情况相比，内存前后基本没有任何影响。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">（2） 读写性能：因为数据写入是先将kv数据值写到缓存，最后再统一flush的硬盘，而压缩是在flush这个阶段执行的，因此会影响flush的操作，对写性能本身并不会有太大影响；而数据读取如果是从HDFS中读取的话，首先需要解压缩，因此理论上读性能会有所下降；如果数据是从缓存中读取，因为缓存中的block块已经是解压后的，因此性能不会有任何影响；一般情况下大多数读都是热点读，缓存读占大部分比例，压缩并不会对读有太大影响。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">目前 HBase 可以支持的压缩方式有 GZ（GZIP）、LZO、LZ4 以及 Snappy。它们之间的区别如下：</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">GZ：用于冷数据压缩，与 Snappy 和 LZO 相比，GZIP 的压缩率更高，但是更消耗 CPU，解压/压缩速度更慢。</span></div></li><li><div><span style="font-size: 12pt;">Snappy 和 LZO：用于热数据压缩，占用 CPU 少，解压/压缩速度比 GZ 快，但是压缩率不如 GZ 高。</span><span style="font-size: 12pt; color: unset; font-family: unset;">&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">Snappy 与 LZO 相比，Snappy 整体性能优于 LZO，Snappy 压缩率比 LZO 更低，但是解压/压缩速度更快。</span></div></li><li><div><span style="font-size: 12pt;">LZ4 与 LZO 相比，LZ4 的压缩率和 LZO 的压缩率相差不多，但是LZ4的解压/压缩速度更快。</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">各种压缩各有不同的特点，我们需要根据业务需求（解压和压缩速率、压缩率等）选择不同的压缩格式。</span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/795B553B-D0FF-4173-B498-F6D2B432152A.png" height="139" width="744"/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">多数情况下，选择Snappy或LZ0是比较好的选择，因为它们的压缩开销底，能节省空间。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">2.2 编码 （</span><span style="font-size: 12pt; font-weight: bold;">Data Block Encoding Types）</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">HFile中，包含了好几个部分（</span><span style="font-size: 12pt;"><a href="https://blog.cloudera.com/apache-hbase-i-o-hfile/" style="font-size: 12pt;">https://blog.cloudera.com/apache-hbase-i-o-hfile/</a></span><span style="font-size: 12pt;">）．我们这里只关心HFile里的Data Block．</span></div><div><span style="font-size: 12pt;">HFile在存储每一个Row时，不是把这一条Row的全部Family/Column整合成在一起，保存起来的</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">RowKey | Family:Column1 -&gt; value | Family:Column2 -&gt; value</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">它是把这条Row，根据Column拆分成好几个KeyValue，保存起来的，如下:</span></div><div><span style="font-size: 12pt;">RowKey/Family:Column1 -&gt; value</span></div><div><span style="font-size: 12pt;">RowKey/Family:Column2 -&gt; value</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">我们可以看到，RowKey需要重复保存很多次，而且Family:Column这个往往都是非常相似的，它也需要保存很多次．这对磁盘非常不友好．当Family:Column越多时，就需要占用越多不必要的磁盘空间．</span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">读数据时&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">我们的Block越小，能放到BlockCache中的数据就越多，命中率就越高，对Scan就越友好。</span></div><div><span style="font-size: 12pt;">Block Encoding&nbsp;&nbsp;</span><span style="font-size: 12pt;">通过减少HBase keyvalue中重复的部分来压缩数据。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">HBase还提供了数据编码功能。和压缩一样，数据在落盘之前首先会对KV数据进行编码；但又和压缩不同，数据块在缓存前并没有执行解码，因此即使后续命中缓存的查询也是编码的数据块，需要解码后才能获取到具体的KV数据。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/CDB1B182-21AE-40C3-8DFE-5FDE778E19AC.png" height="168" width="723"/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">（1） 资源使用情况：和压缩一样，编码最直接、最重要的作用也是减少数据硬盘容量，但是压缩率一般没有数据压缩的压缩率高，理论上只有5:2；编码/解码一般也需要大量计算，需要大量CPU资源；根据读路径来看，数据读取到缓存之前block块并没有被解码，缓存到内存中的block是编码后的，因此和不编码情况相比，相同数据block快占用内存更少，即内存利用率更高。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">（2） 读写性能：和数据压缩相同，数据编码也是在数据flush到hdfs阶段执行的，因此并不会直接影响写入过程；前面讲到，数据块是以编码形式缓存到blockcache中的，因此同样大小的blockcache可以缓存更多的数据块，这有利于读性能。另一方面，用户从缓存中加载出来数据块之后并不能直接获取KV，而需要先解码，这却不利于读性能。可见，数据编码在内存充足的情况下会降低读性能，而在内存不足的情况下需要经过测试才能得出具体结论。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><img src="http://www.aboutyun.com/data/attachment/forum/201607/03/101847fv2y77y2ybvqiyl3.png"/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">prefix_tree压缩算法在不同的block size下性能都比较稳定，而另外两种压缩算法的查找性能会随着blocksize直线下降。对于我们默认的64K的block大小，性能相差40+倍。详见&nbsp;&nbsp;</span><span style="font-size: 12pt;"><a href="https://www.iteye.com/blog/zjushch-1843793" style="font-size: 12pt;">https://www.iteye.com/blog/zjushch-1843793</a></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">HBase中提供了五种Data Block Encoding Types，具体有:</span></div><div><span style="font-size: 12pt;">* NONE（不编码）</span></div><div><span style="font-size: 12pt;">* PREFIX</span></div><div><span style="font-size: 12pt;">* DIFF</span></div><div><span style="font-size: 12pt;">* FAST_DIFF</span></div><div><span style="font-size: 12pt;">* PREFIX_TREE（Trie tree）</span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">PREFIX</span></div></li></ul><div><span style="font-size: 12pt;">一般来说，同一个Block中的Key(KeyValue中的Key，不仅包含RowKey，还包含Family:Column)，都很相似．它们往往只是最后的几个字符不同．</span></div><div><span style="font-size: 12pt;">例如，KeyA是RowKey:Family:Qualifier0，跟它相邻的下一个KeyB可能是&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">RowKey:Family:Qualifier1．</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">在PREFIX中，相对于NONE，会额外添加一列，表示当前key(KeyB)和它前一个key(KeyA)，相同的前缀的长度(记为PrefixLength)．在上面的例子中，如果KeyA是这个Block中的第一个key，那它的PrefixLength就是0．而KeyB的PrefixLength是23．</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">很明显，如果相邻Key之间，完全没有共同点，那PREFIX显然毫无用处，还增加了额外的开销．</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">当使用NONE这种Block Encoding时，如下图所示:</span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/742BFEB0-B769-46BC-A60A-1A93B80C2DDE.png" height="412" width="969"/></span></div><div><span style="font-size: 12pt;">如果采用PREFIX这种Block Encoding，那就是这样子了:</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/BA8CF5A3-9916-4F01-9FAD-9A83476F1E20.png" height="359" width="980"/></span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">DIFF</span></div></li></ul><div><span style="font-size: 12pt;">DIFF是对PREFIX的一种改良．它把key看成很多个部分，对每部分进行压缩，提高效率．它添加了两个新的字段，timestamp和type．如果KeyB的ColumnFamily/key length/value length/type和KeyA相同，那么它就会在KeyB中被省略．</span><span style="font-size: 12pt; color: unset; font-family: unset;">另外，timestamp，存储的是相对于前一个Row的偏移量．</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">默认情况下，DIFF是不启用的．因为它会导致写数据，以及Scan数据更慢．但是，相对于PREFIX/NONE，它会在Block Cache中缓存更多数据．</span></div><div><span style="font-size: 12pt;">用DIFF压缩的block如下图所示:</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><img src="/Resources/hbase%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.resources/70F84DAC-A29B-439E-B810-775DE69D3815.png" height="262" width="989"/></span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">FAST_DIFF</span></div></li></ul><div><span style="font-size: 12pt;">FAST_DIFF跟DIFF非常相似，所不同的是，它额外增加了一个字段，表示RowB是否跟RowA完全一样，如果是的话，那数据就不需要重复保存了．</span></div><div><span style="font-size: 12pt;">如果在你的场景下，Key很长，或者有很多Column，那么推荐使用FAST_DIFF．</span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">PREFIX_TREE</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">PREFIX_TREE是0.96中引入的．它大致跟PREFIX,DIFF,FAST_DIFF相同，但是它可以让随机读操作，比其它的几种更快．当然，代价是，MemStore写入到HFile时，需要进行更加复杂的Encoding操作，所以会更慢</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">它增加了一个叫做tree的字段．这个字段会保存指向这一Row中，全部Cell的索引．这对压缩更加友好．</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">详见</span></div><div><span style="font-size: 12pt;"><a href="https://issues.apache.org/jira/browse/HBASE-4676" style="font-size: 12pt;">https://issues.apache.org/jira/browse/HBASE-4676</a></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">修改</span> <span style="font-size: 12pt;">DATA_BLOCK_ENCODING 步骤</span><span style="font-size: 12pt;">：</span></div><div><span style="font-size: 12pt;">修改表的属性，此为压缩编码。</span></div><div><span style="font-size: 12pt;">alter 'test', {NAME =&gt; 'f', COMPRESSION =&gt; 'lz4', DATA_BLOCK_ENCODING =&gt;'DIFF'}</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">压缩编码并不会立即生效，需要major_compact，此会耗时较长，注意在业务低峰期进行。</span></div><div><span style="font-size: 12pt;">major_compact 'test'</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">2.3 实验&nbsp;&nbsp;</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">数据：6000w条记录，一个列族，每个列族10个列，单条记录总共1K大小；</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">硬件：单RegionServer，3G BlockCache，CPU： 32&nbsp;&nbsp;&nbsp;&nbsp;Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">测试结果：</span></div><div><span style="font-size: 12pt;"><img src="http://www.aboutyun.com/data/attachment/forum/201607/03/101933n50f5rje75zlefje.png"/></span></div><div><span style="font-size: 12pt;"><img src="http://www.aboutyun.com/data/attachment/forum/201607/03/101942qx95xp4gaeeo2v3c.png"/></span></div><div><span style="font-size: 12pt;"><img src="http://www.aboutyun.com/data/attachment/forum/201607/03/101950h0b9c3ingxgggts1.png"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">设计原则：</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">1. 在任何场景下开启prefix_tree编码都是安全的</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">2. 在任何场景下都不要同时开启snappy压缩和prefix_tree编码</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">3. 通常情况下snappy压缩并不能比prefix_tree编码获得更好的优化结果，如果需要使用snappy需要针对业务数据进行实际测试</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font color="#FF0000" style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">一个性能很高的 hbase 的 压力测试</span></div><div><span style="font-size: 12pt;"><a href="https://www.cnblogs.com/163yun/p/9661570.html" style="font-size: 12pt;">https://www.cnblogs.com/163yun/p/9661570.html</a></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">引用</span></font></div><div><br/></div><div><span style="font-size: 12pt;"><a href="https://blog.csdn.net/weixin_43823423/article/details/101074648" style="font-size: 12pt;">https://blog.csdn.net/weixin_43823423/article/details/101074648</a></span></div><div><span style="font-size: 12pt;"><a href="https://www.jianshu.com/p/a62e49f749f3" style="font-size: 12pt;">https://www.jianshu.com/p/a62e49f749f3</a></span></div><div><span style="font-size: 12pt;"><a href="https://www.cnblogs.com/hbase-community/p/8915498.html" style="font-size: 12pt;">https://www.cnblogs.com/hbase-community/p/8915498.html</a></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><a href="https://blog.csdn.net/javastart/article/details/51820212" style="font-size: 12pt;">https://blog.csdn.net/javastart/article/details/51820212</a></span></div><div><span style="font-size: 12pt;"><a href="https://blog.csdn.net/javastart/category_6051883.html" style="font-size: 12pt;">https://blog.csdn.net/javastart/category_6051883.html</a></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">3.storefile 本地化 （</span><span style="font-size: 12pt; font-weight: bold;">locality）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">因为DataNode和RegionServer通常会部署在相同的机器上，所以会产生Locality这样的概念。</span></div><div><span style="font-size: 12pt;">HBase的Locality是通过HDFS的Block复制实现的。在复制Block时，HBase是这样选择副本的位置的：</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">第一个副本写到本地节点上；</span></div><div><span style="font-size: 12pt;">第二个副本写到另一个机架的随机节点上；</span></div><div><span style="font-size: 12pt;">第三个副本写到相同机架的一个随机选择的其他节点上；</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">如果还有更多的副本，这些副本将会写到集群上的随机节点上。</span><span style="font-size: 12pt; color: unset; font-family: unset;">在flush或compact后，HBase的Region实现了Locality。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">当一个RegionServer处在failover的情况下（rebalance 或 重启）时，可能会分配到一些没有本地StoreFiles的Region（因为此时没有可用的本地副本）。然而，有新数据再写入这些Region的时候，或者是对表进行compact的时候，StoreFiles将会被重写，这些Region也会再次变成 RegionServer的“local”Region。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">HBASE 的表的 region 管理页面上 的指标“Locality”，即为 Region保存在本地的StoreFile的百分比。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">hbase compaction主要是合并memstore flush到磁盘上的HFile文件。主要分minor compaction和major compaction。minor compaction只会合并很少的hfile，这个花费的时间也不是很长。而major compaction会合并指定table的所有的HFile，所以花费的时间也比较长，但是能够显著提高hbase的读性能。</span></div><div><span style="font-size: 12pt;">考虑到白天hbase集群的负载并不是很高，所以很自然想到就是做手工major compaction。写一个简单的脚本就好了。其实就一行语句：echo "major_compact 'tablename'" | hbase shell，然后通过crontab定时启动就好了。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">做了major compaction以后region server的block locality明显好转，hbase读的性能提升提升了50%以上</span>，晚上导表时间几乎缩短了一半。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">引用</span></span></div><div><span style="font-size: 12pt;"><a href="https://www.jianshu.com/p/4d3b8f5a2c3b" style="font-size: 12pt;">https://www.jianshu.com/p/4d3b8f5a2c3b</a></span></div><div><span style="font-size: 12pt;">《HBase&nbsp;&nbsp;不睡觉》</span></div><div><br/></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">4.其他问题</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="color: rgb(255, 0, 0);"><span style="font-size: 12pt;">问题1：导入数据时出现 region server 挂掉的现象，检查&nbsp;&nbsp;</span><span style="font-size: 12pt;">region server 的日志 发现OOM</span></font></div><div><br/></div><div><span style="font-size: 12pt;">解决：</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">调节 hbase-site.xml&nbsp;&nbsp; 中</span></div><div><span style="font-size: 12pt;">&lt;name&gt;hbase.regionserver.handler.count&lt;/name&gt;</span></div><div><span style="font-size: 12pt;">&lt;value&gt;180&lt;/value&gt;</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">180 太大了，这样在上传大文件或者scan大数据时，很容易OOM。</span><span style="font-size: 12pt; color: unset; font-family: unset;">默认10，可以适当调高，不能太大了，尤其需要上传或查询大表的场景</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><br/></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><br/></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="分布式数据库系列" scheme="https://xinrihui.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="HBase" scheme="https://xinrihui.github.io/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>hive 去重的三种方法 和 group by 原理</title>
    <link href="https://xinrihui.github.io/2022/12/29/hive%20%E5%8E%BB%E9%87%8D%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95%20%E5%92%8C%20group%20by%20%E5%8E%9F%E7%90%86/"/>
    <id>https://xinrihui.github.io/2022/12/29/hive%20%E5%8E%BB%E9%87%8D%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95%20%E5%92%8C%20group%20by%20%E5%8E%9F%E7%90%86/</id>
    <published>2022-12-29T02:15:20.000Z</published>
    <updated>2022-12-29T02:15:20.324Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-12-28 15:50:50 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-29 02:11:18 +0000"/><title>hive 去重的三种方法 和 group by 原理</title></head><body><div><span style="font-size: 12pt; font-weight: bold;">1.去重&nbsp;&nbsp;的三种方法</span></div><div><br/></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">table</span></div><div><span style="font-size: 12pt; box-sizing: border-box; outline: 0px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal;">name&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt; box-sizing: border-box; outline: 0px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal;">adx&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tran_id&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cost&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-size: 12pt; color: rgb(68, 68, 68);">timestamp</span></div><div><span style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal;">ck&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;125.168.10.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;33.00&nbsp;&nbsp;&nbsp;&nbsp;1407234660 </span></div><div><span style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal;">ck&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;187.18.99.00&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;33.32&nbsp;&nbsp;&nbsp;&nbsp;1407234661 </span></div><div><span style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal;">ck&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;125.168.10.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;33.24&nbsp;&nbsp;&nbsp;&nbsp;1407234661&nbsp;&nbsp; </span></div><div><span style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: rgb(68, 68, 68);">第三行的tran_id和第一行的重复了，所以需要将最后一行去掉。</span></div><div><br/></div><div><span style="font-size: 12pt; color: rgb(47, 47, 47); font-weight: bold;">方法1 distinct</span><span style="font-size: 12pt; color: rgb(47, 47, 47);">&nbsp;&nbsp;</span></div><div style="box-sizing: border-box; outline: 0px; margin: 0px 0px 16px; padding: 0px; overflow-x: auto; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box; outline: 0px; overflow-x: auto; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); font-size: 12pt; color: rgb(68, 68, 68); font-family: unset; line-height: 26px;">select&nbsp;&nbsp; t1.tran_id,t2.name,t2.cost&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="box-sizing: border-box; outline: 0px; overflow-x: auto; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(68, 68, 68); font-family: unset; line-height: 26px;">from&nbsp;&nbsp;</span><span style="font-size: 12pt; outline: 0px; overflow-x: auto; overflow-wrap: break-word; color: rgb(68, 68, 68); font-family: unset; line-height: 26px;">(select</span> <span style="font-size: 12pt; outline: 0px; overflow-x: auto; overflow-wrap: break-word; color: rgb(68, 68, 68); font-family: unset; font-weight: bold; line-height: 26px;">distinct</span> <span style="font-size: 12pt; outline: 0px; overflow-x: auto; overflow-wrap: break-word; color: rgb(68, 68, 68); font-family: unset; line-height: 26px;">tran_id from table) t1</span> <span style="font-size: 12pt; outline: 0px; overflow-x: auto; overflow-wrap: break-word; color: rgb(68, 68, 68); font-family: unset; line-height: 26px;">join table t2 on t1.tran_id=t2.tran_id</span></div><div style="box-sizing: border-box; outline: 0px; margin: 0px 0px 16px; padding: 0px; overflow-x: auto; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="box-sizing: border-box; outline: 0px; overflow-x: auto; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt;">（inner join 不一定 work&nbsp;&nbsp;因为&nbsp;&nbsp;左表有的key&nbsp;&nbsp;在&nbsp;&nbsp;右表有&nbsp;&nbsp;重复的key，这些key&nbsp;&nbsp;是 都要还是&nbsp;&nbsp;选一个&nbsp;&nbsp;取决于 数据库自身的定义 ）</span></div><div><span style="font-size: 12pt; color: rgb(47, 47, 47); font-weight: bold;">方法2&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(47, 47, 47); font-weight: bold;">groupby</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">无法 select 非 groupby&nbsp;&nbsp;字段</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">（1）使用&nbsp;&nbsp;聚合函数&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">select tran_id, max(</span><span style="box-sizing: border-box; outline: 0px; overflow-x: auto; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;">name), max(</span><span style="box-sizing: border-box; outline: 0px; overflow-x: auto; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;">cost)</span><span style="font-size: 12pt;">&nbsp;&nbsp; from table group by&nbsp;&nbsp;</span><span style="outline: 0px; overflow-wrap: break-word; font-size: 12pt; color: rgb(68, 68, 68);">tran_id</span></div><div><span style="outline: 0px; overflow-wrap: break-word; font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">（2）collect_set /&nbsp;&nbsp;</span> <span style="font-size: 12pt;">collect_list&nbsp;&nbsp;</span><span style="font-size: 12pt;">函数</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">collect_set，类似于mysql的group_concat函数，把每个分组的其他字段，按照逗号进行拼接，得到一个最终字符串</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">select tran_id,collect_set(</span><span style="box-sizing: border-box; outline: 0px; overflow-x: auto; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;">name</span><span style="font-size: 12pt;">)[0],collect_set(</span><span style="box-sizing: border-box; outline: 0px; overflow-x: auto; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(68, 68, 68); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 26px;">cost</span><span style="font-size: 12pt;">)[0]&nbsp;&nbsp; from table group by&nbsp;&nbsp;</span><span style="outline: 0px; overflow-wrap: break-word; font-size: 12pt; color: rgb(68, 68, 68);">tran_id</span><span style="font-size: 12pt;">;</span></div><div><br/></div><div><span style="font-size: 12pt;">distinct 需要将</span><span style="outline: 0px; overflow-wrap: break-word; font-size: 12pt; color: rgb(68, 68, 68);">tran_id</span><span style="font-size: 12pt;">列中的全部内容都存储在一个内存中，可以理解为一个hash结构，key为</span><span style="outline: 0px; overflow-wrap: break-word; font-size: 12pt; color: rgb(68, 68, 68);">tran_id</span><span style="font-size: 12pt;">的值，利用 hashset&nbsp;&nbsp;进行去重。</span></div><div><span style="font-size: 12pt;">而group by的方式是先将</span><span style="outline: 0px; overflow-wrap: break-word; font-size: 12pt; color: rgb(68, 68, 68);">tran_id</span><span style="font-size: 12pt;">排序。在group by时，某些数据库产品会根据数据列的情况智能地选择是使用排序去重还是hash去重，例如postgresql。</span></div><div><br/></div><div><span style="font-size: 12pt; color: rgb(47, 47, 47); font-weight: bold;">方法3&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">开窗函数:&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(47, 47, 47); font-weight: bold;">row_number()&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">over (</span><span style="font-size: 12pt; font-weight: bold;">partition by ....)&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">&nbsp;&nbsp;</span></div><div><br/></div><div><span style="font-size: 12pt;">select*</span></div><div><span style="font-size: 12pt;">from(</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;select *,row_number() over (partition by tran_id order by timestamp asc) num from table</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;) t</span></div><div><span style="font-size: 12pt;">where t.num=1;</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">先根据tran_id进行分组，并在分组内部按timestamp 降序排序，row_number()函数计算的值就表示某个tran_id组内部排序后的顺序编号（该编号在一个组内是连续并且唯一的) 。</span></div><div><span style="font-size: 12pt;">所以最后直接去每个分组内的第一个（num=1）即可。</span></div><div><br/></div><div><span style="font-size: 12pt;">group by可以实现同样的分组聚合功能，但sql语句不能写与分组聚合无关的字段，否则会报错，</span></div><div><span style="font-size: 12pt;">即group by 与over(partition by ......)主要区别为，带上group by的hive sql 语句只能显示与分组聚合相关的字段，而带上over(partition by ......)的hive sql语句能显示所有字段.。</span></div><div><br/></div><div><span style="font-size: 12pt;">在关系数据库中，group by key 会将 key&nbsp;&nbsp;相同的通过聚合函数&nbsp;&nbsp;合并为1行&nbsp;&nbsp;而&nbsp;&nbsp;&nbsp;&nbsp;partition by&nbsp;&nbsp;会将&nbsp;&nbsp;key&nbsp;&nbsp;相同的&nbsp;&nbsp;聚在一起而&nbsp;&nbsp;不会合并</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><a href="https://cloud.tencent.com/developer/news/188179" style="font-size: 12pt;">https://cloud.tencent.com/developer/news/188179</a></div><div><a href="https://blog.csdn.net/u014307117/article/details/50962999" style="font-size: 12pt;">https://blog.csdn.net/u014307117/article/details/50962999</a></div><div><a href="https://blog.csdn.net/yimingsilence/article/details/70140877" style="font-size: 12pt;">https://blog.csdn.net/yimingsilence/article/details/70140877</a></div><div><a href="https://www.cnblogs.com/0xcafedaddy/p/9102633.html" style="font-size: 12pt;">https://www.cnblogs.com/0xcafedaddy/p/9102633.html</a></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.&nbsp;&nbsp; distinct&nbsp;&nbsp; + groupby&nbsp;&nbsp;原理</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">SELECT * FROM logs;</span></div><div><br/></div><div><span style="font-size: 12pt;">uid&nbsp;&nbsp;&nbsp;&nbsp; name&nbsp;&nbsp; count </span></div><div><span style="font-size: 12pt;">a&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;苹果&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3</span></div><div><span style="font-size: 12pt;">a&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;橙子&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3</span></div><div><span style="font-size: 12pt;">a&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;烧鸡&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></div><div><span style="font-size: 12pt;">b&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;烧鸡&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3</span></div><div><br/></div><div><span style="font-size: 12pt;">根据count分组，计算独立用户数。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">SELECT count, COUNT(DISTINCT uid)&nbsp;&nbsp; FROM logs GROUPBY count;</span></div><div><br/></div><div><span style="font-size: 12pt;">count&nbsp;&nbsp;&nbsp;&nbsp;COUNT(DISTINCT uid)</span></div><div><span style="font-size: 12pt;">1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1 </span></div><div><span style="font-size: 12pt;">3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 </span></div><div><br/></div><div><img src="/Resources/hive%20%E5%8E%BB%E9%87%8D%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95%20%E5%92%8C%20group%20by%20%E5%8E%9F%E7%90%86.resources/7A01ACE9-7F3E-40CF-947B-7751481E6BA5.png" height="314" width="848"/></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">执行计划</span></div><div><img src="/Resources/hive%20%E5%8E%BB%E9%87%8D%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95%20%E5%92%8C%20group%20by%20%E5%8E%9F%E7%90%86.resources/0A349914-280F-40CB-B87A-21F61B6E84FF.png" height="467" width="347"/></div><div><br/></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">&nbsp;&nbsp;map&nbsp;&nbsp;阶段：</span></div><div><br/></div><div><span style="font-size: 12pt;">（1）在mapper&nbsp;&nbsp;中对表进行列的裁剪&nbsp;&nbsp;只保留 uid&nbsp;&nbsp;和 count&nbsp;&nbsp; ，</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">（2）map&nbsp;&nbsp;端的预聚合， group by operator 的&nbsp;&nbsp;key是&nbsp;&nbsp; ( count , uid ) ，把相同&nbsp;&nbsp;Key&nbsp;&nbsp;的元组&nbsp;&nbsp;写入&nbsp;&nbsp;同一个&nbsp;&nbsp;分区，一个分区中，重复的 key&nbsp;&nbsp;只保留一条</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;reduce 阶段：</span></div><div><br/></div><div><span style="font-size: 12pt;">（1）shuffle&nbsp;&nbsp;过程， group by&nbsp;&nbsp;operator 的&nbsp;&nbsp;key 是&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">count，</span><span style="font-size: 12pt;">把相同&nbsp;&nbsp;Key&nbsp;&nbsp;的元组 写入&nbsp;&nbsp;同一个&nbsp;&nbsp;分区，</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在&nbsp;&nbsp;某个&nbsp;&nbsp;Key&nbsp;&nbsp;对应的分组中，若有&nbsp;&nbsp;不一样的 uid ，则 说明 独立用户数增加1（由于&nbsp;&nbsp;分区中的&nbsp;&nbsp;元组一定有序，所以&nbsp;&nbsp;只要这一条记录&nbsp;&nbsp;与&nbsp;&nbsp;上一条不同则&nbsp;&nbsp;计数器&nbsp;&nbsp;加1） </span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;hive></span> <span style="font-size: 12pt; font-weight: bold;">explain select count, count(distinct uid) from logs group by count;</span></div><div><br/></div><div><span style="font-size: 12pt;">STAGE DEPENDENCIES:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;Stage-1 is a root stage</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;Stage-0 is a root stage</span></div><div><span style="font-size: 12pt;">STAGE PLANS:</span></div><div><br/></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;Stage: Stage-1</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Map Reduce</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Alias->Map Operator Tree:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logs</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TableScan//表扫描</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alias: logs</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Select Operator//列裁剪，取出uid，count字段就够了</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expressions:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: count</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:int</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: uid</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type: string</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputColumnNames: count, uid</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Group By Operator// 先来map聚集</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;aggregations:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: count(DISTINCT uid)//聚集表达式</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bucketGroup:false</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keys:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: count</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:int</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: uid</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type: string</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mode: hash//hash方式</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputColumnNames: _col0, _col1, _col2</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reduce Output Operator</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key expressions://输出的键</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: _col0//count</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:int</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: _col1//uid</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type: string</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sort order:++</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Map-reduce partition columns://这里是按group by的字段分区的</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: _col0//这里表示count</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:int</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tag:-1</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value expressions:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: _col2</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type: bigint</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;Reduce Operator Tree:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Group By Operator//第二次聚集</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;aggregations:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: count(DISTINCT KEY._col1:0._col0)//uid:count</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bucketGroup:false</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keys:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: KEY._col0//count</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:int</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mode: mergepartial//合并</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputColumnNames: _col0, _col1</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Select Operator//列裁剪</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expressions:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: _col0</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type:int</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expr: _col1</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;type: bigint</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputColumnNames: _col0, _col1</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;File Output Operator//输出结果到文件</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;compressed:false</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GlobalTableId:0</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;table:</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input format: org.apache.hadoop.mapred.TextInputFormat</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;Stage: Stage-0</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fetch Operator</span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;limit:-1</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">若不加 group by&nbsp;&nbsp;使用 distinct&nbsp;&nbsp;去重 ，</span></div><div><span style="font-size: 12pt;">则&nbsp;&nbsp;最后必须只有&nbsp;&nbsp;一个 reduce task ，也只有一个&nbsp;&nbsp;分区&nbsp;&nbsp;，因为&nbsp;&nbsp;如果&nbsp;&nbsp;去重的 key&nbsp;&nbsp;分布在多个分区中，显然无法完成去重</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.1 Count(Distinct) 去重统计</span></div><div><br/></div><div><span style="font-size: 12pt;">数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换：</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">案例实操</span></div><div><br/></div><div><span style="font-size: 12pt;">1.</span><span style="font-size: 12pt; color: unset; font-family: unset;">创建一张大表</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">hive (default)>&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">create table bigtable(id bigint, time bigint, uid string,&nbsp;&nbsp;&nbsp;&nbsp;keyword</span></div><div><span style="font-size: 12pt;">string, url_rank int, click_num int, click_url string) row format delimited</span></div><div><span style="font-size: 12pt;">fields terminated by '\t';</span></div><div><br/></div><div><span style="font-size: 12pt;">2．加载数据</span></div><div><span style="font-size: 12pt;">hive (default)> load data local inpath '/opt/module/datas/bigtable' into&nbsp;&nbsp;&nbsp;&nbsp;table&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">bigtable;</span></div><div><br/></div><div><span style="font-size: 12pt;">3．设置5个reduce个数</span></div><div><span style="font-size: 12pt;">set mapreduce.job.reduces = 5;</span></div><div><br/></div><div><span style="font-size: 12pt;">4．执行去重id查询</span></div><div><span style="font-size: 12pt;">hive (default)&gt; select count(distinct id) from bigtable;</span></div><div><br/></div><div><span style="font-size: 12pt;">Stage-Stage-1: Map: 1&nbsp;&nbsp;&nbsp;&nbsp;Reduce: 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cumulative CPU: 7.12 sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HDFS Read:&nbsp;&nbsp;&nbsp;&nbsp;120741990 HDFS Write: 7 SUCCESS</span></div><div><span style="font-size: 12pt;">Total MapReduce CPU Time Spent:</span> <span style="font-size: 12pt; font-weight: bold;">7 seconds</span> <span style="font-size: 12pt;">120 msec</span></div><div><span style="font-size: 12pt;">OK</span></div><div><span style="font-size: 12pt;">c0</span></div><div><span style="font-size: 12pt;">100001</span></div><div><span style="font-size: 12pt;">Time taken: 23.607 seconds, Fetched: 1 row(s)</span></div><div><br/></div><div><span style="font-size: 12pt;">5．采用GROUP by去重id</span></div><div><br/></div><div><span style="font-size: 12pt;">hive (default)>&nbsp;&nbsp; select count(id) from (select id from bigtable group by id)&nbsp;&nbsp;&nbsp;&nbsp;a;</span></div><div><br/></div><div><span style="font-size: 12pt;">Stage-Stage-1: Map: 1&nbsp;&nbsp;&nbsp;&nbsp;Reduce: 5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cumulative CPU: 17.53 sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HDFS Read:&nbsp;&nbsp;&nbsp;&nbsp;120752703 HDFS Write: 580 SUCCESS</span></div><div><span style="font-size: 12pt;">Stage-Stage-2: Map: 1&nbsp;&nbsp;&nbsp;&nbsp;Reduce: 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cumulative CPU: 4.29 sec&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HDFS Read: 9409&nbsp;&nbsp;&nbsp;&nbsp;HDFS Write: 7 SUCCESS</span></div><div><span style="font-size: 12pt;">Total MapReduce CPU Time Spent:</span> <span style="font-size: 12pt; font-weight: bold;">21 seconds</span> <span style="font-size: 12pt;">820 msec</span></div><div><span style="font-size: 12pt;">OK</span></div><div><span style="font-size: 12pt;">_c0</span></div><div><span style="font-size: 12pt;">100001</span></div><div><span style="font-size: 12pt;">Time taken: 50.795 seconds, Fetched: 1 row(s)</span></div><div><br/></div><div><span style="font-size: 12pt;">虽然会多用一个Job来完成，但在数据量大的情况下，这个绝对是值得的。</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><a href="http://fatkun.com/2013/01/hive-distinct.html" style="font-size: 12pt;">http://fatkun.com/2013/01/hive-distinct.html</a></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="hive 系列" scheme="https://xinrihui.github.io/categories/hive-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="分布式计算框架" scheme="https://xinrihui.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    
    <category term="hive" scheme="https://xinrihui.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>hive 连接</title>
    <link href="https://xinrihui.github.io/2022/12/29/hive%20%E8%BF%9E%E6%8E%A5/"/>
    <id>https://xinrihui.github.io/2022/12/29/hive%20%E8%BF%9E%E6%8E%A5/</id>
    <published>2022-12-29T02:15:20.000Z</published>
    <updated>2022-12-29T02:15:20.324Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-12-28 16:13:07 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-29 02:11:13 +0000"/><title>hive 连接</title></head><body><div><span style="color: rgb(47, 47, 47); font-weight: bold;">1.外连接 和 内连接</span></div><div><br/></div><div style="orphans: 2; widows: 2;"><span style="orphans: 2; widows: 2; font-size: 12pt; color: rgb(47, 47, 47);">内连接：两个表都有的才有；最大的表要放在最后面；</span></div><div style="orphans: 2; widows: 2;"><span style="orphans: 2; widows: 2; font-size: 12pt; color: rgb(47, 47, 47);">左连接：左侧表所有的行一定都有</span></div><div style="orphans: 2; widows: 2;"><span style="orphans: 2; widows: 2; font-size: 12pt;">半连接：Hive中使用semi join替代exist in加一个子查询</span></div><div><br/></div><div><span style="font-size: 12pt;">取各种集合：</span></div><div><a href="/Resources/hive%20%E8%BF%9E%E6%8E%A5.resources/F8D754F7-A29F-40FF-B801-8F77995EA7EC.webp">F8D754F7-A29F-40FF-B801-8F77995EA7EC.webp</a><br/></div><div><span style="font-size: 16px;"><b><br/></b></span></div><div/><div><br/></div><div><span style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">2.join 的优化</span></span></div><div><br/></div><div><span style="font-size: 12pt; color: rgb(47, 47, 47); font-weight: bold;">2.1 reduce Join </span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: rgb(47, 47, 47);">Reduce阶段完成join</span></div><div><br/></div><div><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">SELECT</span></div><div style="text-indent: 0px; padding-left: 6px; margin-left: 0px; list-style: decimal;"><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">a</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">.</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">id</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">,</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">a</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">.</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">dept</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">,</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">b</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">.</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">age</span></div><div style="text-indent: 0px; padding-left: 6px; margin-left: 0px; list-style: decimal;"><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">FROM a join b</span></div><div><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">ON</span> <span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">(</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">a</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">.</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">id</span> <span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">=</span> <span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">b</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">.</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 0, 255); line-height: 20px;">id</span><span style="text-indent: 0px; font-size: 12pt; color: rgb(0, 170, 0); line-height: 20px;">);</span></div><div><img src="/Resources/hive%20%E8%BF%9E%E6%8E%A5.resources/DAB0CDA4-6950-4B44-A84B-1437536F9E68.jpg" height="333" width="1240"/><br/></div><div><span style="font-size: 12pt;">纯 mapreduce 实现 join</span></div><div><a href="https://www.edureka.co/blog/mapreduce-example-reduce-side-join/" style="font-size: 12pt;">https://www.edureka.co/blog/mapreduce-example-reduce-side-join/</a></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.2 Map Join</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">Map阶段完成join</span></div><div><br/></div><div><span style="font-size: 12pt;">MapJoin通常用于一个很小的表和一个大表进行join的场景，具体小表有多小，由参数hive.mapjoin.smalltable.filesize来决定，该参数表示小表的总大小，默认值25M。在0.7版本之后，默认自动会转换Map Join，由参数hive.auto.convert.join来控制，默认为true。</span></div><div><br/></div><div><span style="font-size: 12pt;">在Hive0.11后，Hive默认启动该优化，也就是不在需要显示的使用MAPJOIN标记，其会在必要的时候触发该优化操作将普通JOIN转换成MapJoin，可以通过以下两个属性来设置该优化的触发时机</span></div><div style="margin: 0px; padding: 0px; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(254, 254, 242);"><div><span style="font-size: 12pt; color: rgb(0, 0, 0); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.45;">hive.mapjoin.smalltable.filesize</span></div></div><div><span style="font-size: 12pt;">默认值为2500000(25M),通过配置该属性来确定使用该优化的表的大小，如果表的大小小于此值就会被加载进内存中</span></div><div><br/></div><div><img src="/Resources/hive%20%E8%BF%9E%E6%8E%A5.resources/C4440761-5F18-40E7-BBDA-FF45EC5DB3FA.jpg" height="647" width="712"/><br/></div><div><br/></div><div><span style="font-size: 12pt;">（1）首先是Task A，它是一个Local Task（在客户端本地执行的Task），负责扫描小表b的数据，将其转换成一个HashTable的数据结构，并写入本地的文件中，之后将该文件加载到DistributeCache中。</span></div><div><span style="text-indent: 0px; font-size: 12pt; line-height: 30px;">（2）接下来是Task B，该任务是一个没有Reduce的MR，启动MapTasks扫描大表a,在Map阶段，根据 a的每一条记录去 和 DistributeCache中b表对应的HashTable关联，并直接输出结果。</span></div><div><span style="text-indent: 0px; font-size: 12pt; line-height: 30px;">（3）由于MapJoin没有Reduce，所以由Map直接输出结果文件，有多少个Map Task，就有多少个结果文件。</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.3 backet </span><span style="font-size: 12pt; font-weight: bold;">Join （ 分区 join）</span></div><div><br/></div><div><span style="font-size: 12pt;">如果两张表都是大表，依然可以使用map join 。</span></div><div><span style="font-size: 12pt;">Bucket map join需要待连接的两个表在连接字段上进行分桶（每个分桶对应hdfs上的一个文件），而且</span><span style="font-size: 12pt; font-weight: bold;">小表的桶数需要为大表桶数的倍数</span><span style="font-size: 12pt;">（类似spark 的 shuffle hash join）。建立分桶表的例子：</span></div><div style="box-sizing: border-box; overflow: auto; padding: 9.5px; margin: 0px 0px 10px; word-break: break-all; overflow-wrap: break-word; background-color: rgb(245, 245, 245); border: 1px solid rgb(204, 204, 204); border-radius: 4px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">CREATE TABLE my_user</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">(</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">uid INT,</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">name STRING</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">)</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">CLUSTERED BY (uid) into 32 buckets</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">STORED AS TEXTFILE;</span></div></div><div style="box-sizing: border-box; margin: 0px 0px 10px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(253, 253, 253, 0.9);"><span style="box-sizing: border-box; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(253, 253, 253, 0.9); font-size: 12pt; color: rgba(51, 51, 51, 0.9);">这样，my_user表就对应32个桶，数据根据uid的hash value 与32取余，然后被分发导不同的桶中。</span></div><div style="box-sizing: border-box; margin: 0px 0px 10px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(253, 253, 253, 0.9);"><span style="box-sizing: border-box; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(253, 253, 253, 0.9); font-size: 12pt; color: rgba(51, 51, 51, 0.9);">如果两个表在连接字段上分桶，则可以执行bucket map join了。具体的：</span></div><ol style="box-sizing: border-box; margin-top: 0px; margin-bottom: 10px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(253, 253, 253, 0.9);"><li style="box-sizing: border-box; margin: 3px 0px;"><div><span style="font-size: 12pt; color: rgba(51, 51, 51, 0.9); font-variant-caps: normal; font-variant-ligatures: normal;">设置属性</span><span style="font-size: 12pt; box-sizing: border-box; background-color: rgb(254, 251, 243); border-radius: 4px; box-shadow: rgba(0, 0, 0, 0.17) 0px 0px 1px; border: 1px solid rgba(102, 102, 102, 0.17); color: rgb(199, 37, 78); font-variant-caps: normal; font-variant-ligatures: normal;">hive.optimize.bucketmapjoin= true</span><span style="font-size: 12pt; color: rgba(51, 51, 51, 0.9); font-variant-caps: normal; font-variant-ligatures: normal;">控制hive 执行bucket map join；</span></div></li><li style="box-sizing: border-box; margin: 3px 0px;"><div><span style="font-size: 12pt; color: rgba(51, 51, 51, 0.9); font-variant-caps: normal; font-variant-ligatures: normal;">对小表的每个分桶文件建立一个hashtable，并分发到所有做连接的map端；</span></div></li><li style="box-sizing: border-box; margin: 3px 0px;"><div><span style="font-size: 12pt; color: rgba(51, 51, 51, 0.9); font-variant-caps: normal; font-variant-ligatures: normal;">map端接受了N（N为小表分桶的个数） 个小表的hashtable，做连接 操作的时候，只需要将小表的一个hashtable 放入内存即可，然后将大表的对应的split 拿出来进行连接，所以其内存限制为小表中最大的那个hashtable 的大小</span></div></li></ol><div><span style="font-size: 12pt;">小表桶数和大表桶数的关系： </span></div><div><span style="font-size: 12pt;">eg1. 小表和大表都分为10个桶（桶号0-9），把小表的0号 hashtable 放入内存中，和大表的0号桶做 hash join即可</span></div><div><span style="font-size: 12pt;">eg2. 小表10个桶（桶号0-9） 大表5个桶（桶号0-4），小表桶大表桶对应关系如下：</span></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">小表</span></div></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">大表</span></div></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">0</span></div></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">0</span></div></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">1</span></div></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">1</span></div></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">2</span></div></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">2</span></div></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">3</span></div></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><div><span style="font-size: 12pt;">3</span></div></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><span style="font-size: 12pt;">4</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><span style="font-size: 12pt;">4</span></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><span style="font-size: 12pt;">5</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><span style="font-size: 12pt;">0</span></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><span style="font-size: 12pt;">6</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><span style="font-size: 12pt;">1</span></div></td></tr><tr><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><span style="font-size: 12pt;">....</span></div></td><td style="border: 1px solid rgb(204, 204, 204); width: 130px; padding: 8px;"><div style="text-align: center;"><span style="font-size: 12pt;">....</span></div></td></tr></tbody></table><div><span style="font-size: 12pt;">很显然，小表的0、5号桶会和大表的0号桶做join </span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.4 sort merge bucket join ( </span><span style="font-size: 12pt; font-weight: bold;">排序</span><span style="font-size: 12pt; font-weight: bold;">分区 join )</span></div><div><br/></div><div><span style="font-size: 12pt; line-height: 1.45;">对于bucket map join中的两个表，如果每个桶内分区字段也是有序的，则还可以进行sort merge bucket map join。（类似于 spark 的 Sort Merge Join ）对于那个的建表语句为：</span></div><div><br/></div><div style="box-sizing: border-box; overflow: auto; padding: 9.5px; margin: 0px 0px 10px; word-break: break-all; overflow-wrap: break-word; background-color: rgb(245, 245, 245); border: 1px solid rgb(204, 204, 204); border-radius: 4px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">(</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">uid INT,</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">name STRING</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">)</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">CLUSTERED BY (uid) SORTED BY (uid) into 32 buckets</span></div><div><span style="font-size: 12pt; color: rgb(51, 51, 51); font-variant-caps: normal; font-variant-ligatures: normal; line-height: 1.42857;">STORED AS TEXTFILE;</span></div></div><div style="box-sizing: border-box; margin: 0px 0px 10px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(253, 253, 253, 0.9);"><span style="box-sizing: border-box; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(253, 253, 253, 0.9); font-size: 12pt; color: rgba(51, 51, 51, 0.9);">这样一来当两边bucket要做局部join的时候，只需要用类似 merge sort（归并排序）算法中的merge操作一样把两个bucket顺序遍历一遍即可完成，这样甚至都不用把一个bucket完整的加载成hashtable，而且可以做全连接操作。</span></div><div style="box-sizing: border-box; margin: 0px 0px 10px; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(253, 253, 253, 0.9);"><span style="box-sizing: border-box; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(253, 253, 253, 0.9); font-size: 12pt; color: rgba(51, 51, 51, 0.9);">进行sort merge bucket map join时，需要设置的属性为：</span></div><div><span style="font-size: 12pt;">set hive.optimize.bucketmapjoin= true;</span></div><div><span style="font-size: 12pt;">set hive.optimize.bucketmapjoin.sortedmerge = true;</span></div><div><span style="font-size: 12pt;">set hive.input.format = org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用：</span></div><div><a href="http://datavalley.github.io/2015/10/25/Hive%E4%B9%8BJOIN%E5%8F%8AJOIN%E4%BC%98%E5%8C%96" style="font-size: 12pt;">http://datavalley.github.io/2015/10/25/Hive%E4%B9%8BJOIN%E5%8F%8AJOIN%E4%BC%98%E5%8C%96</a></div><div><a href="https://blog.csdn.net/yjgithub/article/details/66972966" style="font-size: 12pt;">https://blog.csdn.net/yjgithub/article/details/66972966</a></div><div><a href="http://lxw1234.com/archives/2015/06/313.htm" style="font-size: 12pt; color: rgb(47, 47, 47); line-height: 1.45;">http://lxw1234.com/archives/2015/06/313.htm</a></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold; line-height: 1.45;">对比 spark SQL 的join 原理：</span></div><div><span style="font-size: 12pt;">见 spark 原理</span></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="hive 系列" scheme="https://xinrihui.github.io/categories/hive-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="分布式计算框架" scheme="https://xinrihui.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    
    <category term="hive" scheme="https://xinrihui.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>hive 存储格式</title>
    <link href="https://xinrihui.github.io/2022/12/29/hive%20%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/"/>
    <id>https://xinrihui.github.io/2022/12/29/hive%20%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/</id>
    <published>2022-12-29T02:15:20.000Z</published>
    <updated>2022-12-29T02:15:20.324Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-12-28 15:44:48 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="https://blog.csdn.net/hellozhxy/article/details/81905898"/><meta name="updated" content="2022-12-29 02:11:06 +0000"/><title>hive 存储格式</title></head><body><div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">1.数据类型</span></div><table style="margin-left: auto; margin-right: auto; border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 241px;"/><col style="width: 241px;"/><col style="width: 241px;"/><col style="width: 241px;"/></colgroup><tbody style="box-sizing: border-box; outline: 0px; border: 0px; overflow-wrap: break-word;"><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; background-color: rgb(239, 243, 245); border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 700; line-height: 22px;">分类</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; background-color: rgb(239, 243, 245); border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 700; line-height: 22px;">类型</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; background-color: rgb(239, 243, 245); border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 700; line-height: 22px;">描述</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; background-color: rgb(239, 243, 245); border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; color: rgb(51, 51, 51); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: 700; line-height: 22px;">字面量示例</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">原始类型</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">BOOLEAN</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">true/false</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">TRUE</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(247, 247, 247); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">TINYINT</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">1字节的有符号整数 -128~127</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">1Y</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">SMALLINT</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">2个字节的有符号整数，-32768~32767</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">1S</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(247, 247, 247); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">INT</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">4个字节的带符号整数</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">1</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">BIGINT</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">8字节带符号整数</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">1L</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(247, 247, 247); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">FLOAT</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">4字节单精度浮点数1.0</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">DOUBLE</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">8字节双精度浮点数</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">1.0</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(247, 247, 247); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">DEICIMAL</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">任意精度的带符号小数</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">1.0</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">STRING</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">字符串，变长</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">“a”,’b’</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(247, 247, 247); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">VARCHAR</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">变长字符串</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">“a”,’b’</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">CHAR</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">固定长度字符串</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">“a”,’b’</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(247, 247, 247); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">BINARY</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">字节数组</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">无法表示</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">TIMESTAMP</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">时间戳，纳秒精度</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">122327493795</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(247, 247, 247); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">DATE</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">日期</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">‘2016-03-29’</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">复杂类型</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">ARRAY</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">有序的的同类型的集合</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">array(1,2)</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(247, 247, 247); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">MAP</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">key-value,key必须为原始类型，value可以任意类型</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">map(‘a’,1,’b’,2)</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(255, 255, 255); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">STRUCT</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">字段集合,类型可以不同</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="background-color: rgb(255, 255, 255); font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">struct(‘1’,1,1.0), named_stract(‘col1’,’1’,’col2’,1,’clo3’,1.0)</span></div></td></tr><tr style="box-sizing: border-box; outline: 0px; background-color: rgb(247, 247, 247); overflow-wrap: break-word;"><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">&nbsp;&nbsp;</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">UNION</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">在有限取值范围内的一个值</span></div></td><td style="box-sizing: border-box; outline: 0px; overflow-wrap: break-word; font-size: 14px; text-align: left; border: 1px solid rgb(221, 221, 221); width: 241px; padding: 8px;"><div style="font-size: 16px;"><span style="font-size: 16px; font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: normal; line-height: 22px;">create_union(1,’a’,63)</span></div></td></tr></tbody></table><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><a href="https://blog.csdn.net/hellozhxy/article/details/81905898" style="font-size: 12pt;">https://blog.csdn.net/hellozhxy/article/details/81905898</a></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2. 文件存储</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">分割文本 ：TextFile</span></div></li><li><div><span style="font-size: 12pt;">序列化存储：1.sequencefile 2.RCfile 3.RegexSerDe</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.1 分割文本（外部表）</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">TextFile&nbsp;&nbsp;为默认格式，建表时默认为这个格式，导入数据时会直接把数据文件拷贝到hdfs上不进行处理。</span></div><div><span style="font-size: 12pt;">SequenceFile、RCFile、ORC格式的表不能直接从本地文件导入数据，数据要先导入到TextFile格式的表中，然后再从TextFile表中用insert导入到SequenceFile、RCFile表中。</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">TextFile：</span></div></li></ul><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;存储方式：行存储。可以使用Gzip压缩算法，但压缩后的文件不支持split。查询过程必须逐个字符判断是不是分隔符和行结束符，因此开销大。但是</span><span style="font-size: 12pt; font-weight: bold;">加载速度最快</span></div><div><img width="619"/></div><div><span style="font-size: 12pt; font-weight: bold;">2.2 序列化存储（内部表）</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.2.1 行存储</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。</span></div><div><img src="/Resources/hive%20%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F.resources/47B695ED-EC2C-4976-B6C4-EC54D80DD80F.png" height="357" width="866"/></div><div><br/></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">基于Hadoop系统行存储结构的优点在于快速数据加载和动态负载的高适应能力，这是因为行存储保证了相同记录的所有域都在同一个集群节点，即同一个 HDFS块。不过，行存储的缺点也是显而易见的，例如它不能支持快速查询处理，因为当查询仅仅针对多列表中的少数几列时，它不能跳过不必要的列读取；此外，由于混合着不同数据值的列，行存储不易获得一个极高的压缩比，即空间利用率不易大幅提高。</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">Sequence File</span></div></li></ul><div><br/></div><div><img src="/Resources/hive%20%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F.resources/F451024B-1E7D-4464-868C-6EB8217CED29.png" height="473" width="848"/></div><div><span style="font-size: 12pt;">Hadoop API提供的一种二进制文件，以key-value的形式序列化到文件中。存储方式：行存储。</span></div><div><span style="font-size: 12pt;">sequencefile支持三种压缩选择：NONE，RECORD，BLOCK。Record压缩率低，RECORD是默认选项，通常BLOCK会带来较RECORD更好的压缩性能。</span><span style="font-size: 12pt; font-weight: bold;">SequenceFile压缩率最低，查询速度一般</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.2.2列存储</span><span style="font-size: 12pt;">：</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法。</span></div><div><img src="/Resources/hive%20%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F.resources/BC88FE80-C8D9-4FBF-994B-C39A7E7E482A.png" height="694" width="774"/></div><div><br/></div><div><span style="font-size: 12pt;">在HDFS上按照 列组 存储表格的例子。在这个例子中，列A和列B存储在同一列组，而列C和列D分别存储在单独的列组。</span></div><div><span style="font-size: 12pt;">查询时列存储能够避免读不必要的列， 并且压缩一个列中的相似数据能够达到较高的压缩比。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">然而，由于 元组 重构的较高开销，它并不能提供 基于Hadoop系统的快速查询处理。列存储不能保证同一记录的所有域都存储在同一集群节点，行存储的例子中，记录的4个域存储在位于不同节点的3个HDFS块中。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">因此，记录的重构将导致通过集群节点网络的大 量数据传输。尽管预先分组后，多个列在一起能够减少开销，但是对于高度动态的负载模式，它并不具备很好的适应性。</span></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.2.3行列混合存储</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><img src="/Resources/hive%20%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F.resources/3B351811-00DD-47A2-9741-616D7E0A1760.png" height="544" width="889"/></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">RCFile ：RCFile结合 行存储的快速查询 和 列存储的节省空间的特点。行列混合的存储方式：</span><span style="font-size: 12pt; font-weight: bold;">数据按行分块，每块按列存储</span><span style="font-size: 12pt;">。</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">首先，RCFile保证同一行的数据位于同一节点，因此元组重构的开销很低；其次，像列存储一样，RCFile能够利用列维度的数据压缩，并且能跳过不必要的列读取。 （RCFile 的升级版为&nbsp;&nbsp;ORCFile）</span></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.3&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">分割文本&nbsp;&nbsp;和&nbsp;&nbsp;序列化存储&nbsp;&nbsp;大对比</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt; font-weight: bold;">RCfile压缩率最高，查询速度最快，数据加载最慢</span><span style="font-size: 12pt;">。</span></div></li><li><div><span style="font-size: 12pt;">相比 TEXTFILE 和 SEQUENCEFILE，RCFILE由于列式存储方式，数据加载时性能消耗较大，但是具有较好的压缩比和查询 响应。数据仓库的特点是一次写入、多次读取，因此，整体来看，RCFILE相比其余两种格式具有较明显的优势。</span></div></li><li><div><span style="font-size: 12pt;">在hive中使用压缩需要灵活的方式，如果是数据源的话，采用RCFile+bz或RCFile+gz的方式，这样可以很大程度上节省磁盘空间；而在计算的过程中，为了不影响执行的速度，可以浪费一点磁盘空间，建议采用RCFile+snappy的方式，这样可以整体提升hive的执行速度。至于lzo的方式，也可以在计算过程中使用，只不过综合考虑（速度和压缩比）还是考虑snappy适宜。</span></div></li></ul><div><br/></div><ul><li><div><span style="font-size: 12pt;">Parquet</span></div></li></ul><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;如果嵌套较多，就用 Parquet。如果数据结构是比较扁平的，那么用 ORC 比较合适。</span></div><div><br/></div><div><img src="/Resources/hive%20%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F.resources/4432E9A6-FA83-4C42-A02A-2938D02DDBD7.png" height="533" width="1323"/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">2.4 文件压缩</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">在Hive中对中间数据或最终数据做压缩，是提高数据吞吐量和性能的一种手段。对数据做压缩，可以大量减少磁盘的存储空间，同时压缩后的文件在磁盘间传输和I/O也会大大减少；当然压缩和解压缩也会带来额外的CPU开销，但是却可以节省更多的I/O和使用更少的内存开销。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><img src="/Resources/hive%20%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F.resources/CDD72A1F-FE82-4F26-B165-AD5058D815F9.png" height="296" width="1202"/></div><div><br/></div><div><span style="font-size: 12pt;">*Hadoop的会将大文件分割成HDFS block(默认64MB)大小的splits分片，每个分片对应一个Mapper程序。不可分割意味着无法在mapreduce中并行处理。MapReduce不分割gzip格式的文件（gzip文件大小为1GB，HDFS的块大小为64MB），因此一个map任务将串行处理16个HDFS块，且大都不是map的本地数据。与此同时，因为map任务少，所以作业分割的粒度不够细，从而导致运行时间变长。</span></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><br/></div><div><a href="http://icejoywoo.github.io/2016/03/29/hive-ocr-and-parquet.html#" style="font-size: 12pt;">http://icejoywoo.github.io/2016/03/29/hive-ocr-and-parquet.html#</a></div><div><br/></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="hive 系列" scheme="https://xinrihui.github.io/categories/hive-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="分布式计算框架" scheme="https://xinrihui.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    
    <category term="hive" scheme="https://xinrihui.github.io/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>Bert的前世今生-3.self-supervised（Bert）</title>
    <link href="https://xinrihui.github.io/2022/12/28/4.self-supervised%EF%BC%88Bert%20%EF%BC%89/"/>
    <id>https://xinrihui.github.io/2022/12/28/4.self-supervised%EF%BC%88Bert%20%EF%BC%89/</id>
    <published>2022-12-28T06:53:53.000Z</published>
    <updated>2023-03-10T15:00:27.366Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2021-12-03 16:28:34 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 16:36:27 +0000"/><title>4.self-supervised（Bert ）</title></head><body><div><div><br/></div><div>1.整整齐齐的一家人</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/26EC555F-B8B5-4281-9CF9-BB1ACA96AD58.png" height="50%" width="80%"/></div><div><br/></div><div>2.陷入了军备竞赛</div><div><br/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/F00EF66B-D8E5-40F2-80B9-6801F1811D36.png" height="50%" width="80%"/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/6ACB4222-6A92-4FBE-A21B-424CFC92CD43.png" height="50%" width="80%"/></div><div><br/></div><div>3.自监督学习 和&nbsp;&nbsp;传统的监督学习的区别是&nbsp;&nbsp;它的&nbsp;&nbsp;Label&nbsp;&nbsp;是&nbsp;&nbsp;语料 x&nbsp;&nbsp;自己产生的，而不是人工标注的&nbsp;&nbsp;</div><div><br/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/E26F4C16-6337-4C5E-B80F-EF6B3FB60358.png" height="50%" width="80%"/></div><div><br/></div><div><br/></div><div>3.自监督&nbsp;&nbsp;的 pre-train</div><div><br/></div><ul><li><div><span style="font-size: unset; color: unset; font-family: unset;">masked token prediction（做填空题）</span></div></li></ul><div>利用网络上已有的句子，随机地把某个位置的单词盖住，然后让模型去预测被盖住的位置&nbsp;&nbsp;</div><div><br/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/F1715A0E-7D5D-45DE-8D61-806FB49AE58B.png" height="50%" width="80%"/></div><div><br/></div><ul><li><div>seq2seq</div></li></ul><div><br/></div><div>显然我们可以得到一个 pre-train&nbsp;&nbsp;的 encoder，&nbsp;&nbsp; 那么如何&nbsp;&nbsp;得到 pre-train&nbsp;&nbsp;的 decoder：</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/0FBDC350-865C-4808-97EF-2B04450FA930.png" height="50%" width="80%"/></div><div>输入的 <span style="font-size: unset; color: unset; font-family: unset;">sequence</span>为 w1,w2,w3,w4，训练时的 标签（ground truth） 也为&nbsp;&nbsp;w1,w2,w3,w4，</div><div>若直接训练，模型是学不到东西的，它会把 w1&nbsp;&nbsp;原封不动的作为第一个输出，并以此类推，</div><div><br/></div><div><span style="font-size: unset; color: unset; font-family: unset;">所以我们要把输入的 source sequence 弄坏，让&nbsp;&nbsp;模型去输出一个&nbsp;&nbsp;正确的 target&nbsp;&nbsp;sequence</span></div><div><span style="font-size: unset;"><br/></span></div><div>把&nbsp;&nbsp;<span style="font-size: unset; color: unset; font-family: unset;">source sequence 弄坏&nbsp;&nbsp;的方法有很多，比如&nbsp;&nbsp;遮盖，删除，重新排序，旋转....</span></div><div><br/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/B9EB49F3-D7B4-44DF-8A1A-A47AADF6634C.png" height="50%" width="80%"/></div><div>上面这些方法的好坏的研究 google&nbsp;&nbsp;也做了 （google YYDS ==）</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/78A03460-90CC-4441-9FFA-2D4237AA6147.png" height="50%" width="80%"/></div><div>&nbsp;&nbsp;</div><div><br/></div><div><br/></div><div>4.训练好的模型 ， fine-tune&nbsp;&nbsp;后可以用于下游任务</div><div><br/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/9CF52889-2FD7-479F-BC25-87304097BF75.png" height="50%" width="80%"/></div><div>5.判断&nbsp;&nbsp;预训练模型的能力 可以将&nbsp;&nbsp;预训练模型&nbsp;&nbsp;针对以下 9个任务（bench mark） 进行 fine-tune&nbsp;&nbsp;然后评分</div><div><br/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/B4B5F0A9-59EC-436E-9A73-25ECEC646877.png" height="50%" width="80%"/></div><div><br/></div><div>目前各个模型的&nbsp;&nbsp;在不同任务的分数如下，中间的黑线为人类的分数作为基准，可以看出&nbsp;&nbsp;最右侧的 XLNet 模型已经有很多&nbsp;&nbsp;任务超过了人类</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/43B1E81F-A4D8-4CA4-8D9E-4A3040231E79.png" height="50%" width="80%"/></div><div><br/></div><div>6.针对不同类型任务的 fine-tune&nbsp;&nbsp;</div><div><br/></div><ul><li><div>文本分类</div></li></ul><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/98F339AE-1FE4-422F-913C-899F125CBC74.png" height="50%" width="80%"/></div><div>利用少量的&nbsp;&nbsp;与&nbsp;&nbsp;该任务相关的标注数据进行训练，并且只训练自己加的那部分模型（图中 Liner）</div><div><br/></div><ul><li><div>序列标注</div></li></ul><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/D141A0C1-3833-491F-9111-85AB8169C111.png" height="50%" width="80%"/></div><div><br/></div><ul><li><div>自然语言推理</div></li></ul><div><br/></div><div>输入两个句子，判断它们的关系</div><div><br/></div><div>eg.&nbsp;&nbsp;公众号文章&nbsp;&nbsp;和&nbsp;&nbsp; 评论，这个评论是支持文章还是反对文章</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/3A6B0ACF-F890-4A20-BE7F-15FAB5D625A7.png" height="50%" width="80%"/></div><div><br/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/BF58F0A7-52A2-4F23-AF52-5CBCA4D8FF0C.png" height="50%" width="80%"/></div><div><br/></div><ul><li><div>阅读理解</div></li></ul><div>看文章回答问题，问题的答案一定在文章中</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/59ECCE0C-8186-4E02-9792-97BA7D557713.png" height="50%" width="80%"/></div><div>将文章和问题输入模型，模型输出答案的&nbsp;&nbsp;开始位置 s 和&nbsp;&nbsp;结束位置 e（这都行 == ）</div><div><br/></div><div>首先确定&nbsp;&nbsp;开始位置 s，&nbsp;&nbsp;需要训练&nbsp;&nbsp;下图中的&nbsp;&nbsp;橙色的向量，它和 document&nbsp;&nbsp;对应位置的bert的输出向量点乘后&nbsp;&nbsp;经过 softmax，</div><div>找一个概率最大的位置&nbsp;&nbsp;作为开始位置</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/B567ABC7-FDAB-4849-AD58-798490BE933B.png" height="50%" width="80%"/></div><div><span style="font-size: unset; color: unset; font-family: unset;">然后 确定&nbsp;&nbsp;结束的位置 e，&nbsp;&nbsp;</span>需要训练&nbsp;&nbsp;下图中的&nbsp;&nbsp;蓝色的向量，它和 document&nbsp;&nbsp;对应位置的bert的输出向量点乘后&nbsp;&nbsp;经过 softmax，</div><div>找一个概率最大的位置&nbsp;&nbsp;作为&nbsp;&nbsp;结束位置</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/D7514D1F-C494-4351-985A-531873F64498.png" height="50%" width="80%"/></div><div><br/></div><div><br/></div><div>7.如果不用预训练好的参数&nbsp;&nbsp;而是全部从头开始学 （scratch）</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/C6EA18C1-AE7D-4AFD-918A-C29B45B2A0AF.png" height="50%" width="80%"/></div><div>上图中，实线是 fine-tune ，虚线是&nbsp;&nbsp;scratch ，</div><div>可以看出，使用&nbsp;&nbsp;预训练的参数不但&nbsp;&nbsp;损失下降的快，而且最后的损失也比较小</div><div><br/></div></div><div>但是 loss&nbsp;&nbsp;低不一定代表在测试集上的效果好（已经&nbsp;&nbsp; overfitting），换句话说&nbsp;&nbsp;我们要如何&nbsp;&nbsp;通过 loss 衡量模型的&nbsp;&nbsp;泛化能力（generalize）</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/F9FDCDF5-E4C5-42D3-A40F-D03AB5FD6F75.png" height="50%" width="80%"/></div><div>等高线&nbsp;&nbsp;代表了模型在训练集上的loss，训练开始时在某个 start point 上，训练结束时走到一个 local minimum&nbsp;&nbsp;的点</div><div>我们可以通过观察&nbsp;&nbsp;这个&nbsp;&nbsp;local minimum&nbsp;&nbsp; 所在的是一个&nbsp;&nbsp;陡峭的山谷&nbsp;&nbsp;还是&nbsp;&nbsp;一个平缓的盆地，后者的泛化能力好&nbsp;&nbsp;</div><div><br/></div><div>8. pre-trian&nbsp;&nbsp;的过程很痛苦</div><div><br/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/68467BA0-63A3-4674-9189-85B7CADB9D21.png" height="50%" width="80%"/></div><div>只有自己训练&nbsp;&nbsp;Bert&nbsp;&nbsp;才可以 去思考</div><div>（1）如何加速&nbsp;&nbsp;它的训练过程</div><div>（2）Bert&nbsp;&nbsp; 是怎么学会做填空题的，它怎么学到这里应该填动词&nbsp;&nbsp;还是&nbsp;&nbsp;名词</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/3E0DB95B-FE6B-4D73-8AA2-65346CB7364F.png" height="50%" width="80%"/></div><div>9.它为啥会 work</div><div><br/></div><div>学的是输入句子对应的字的 embedding，并且能解决 一词(子)多义 的问题</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/6E8736C5-4B7C-45EE-8878-A8978B02ACF5.png" height="50%" width="80%"/></div><div><br/></div><div>根据上下文，'<span style="color: rgb(255, 0, 0);">果</span>'&nbsp;&nbsp;这个字的 embedding&nbsp;&nbsp;可能不一样，比如 出现在 ‘苹<span style="color: rgb(255, 0, 0);">果</span>手机’中 ，和出现在 ‘吃苹<span style="color: rgb(255, 0, 0);">果</span>’中在向量空间中是不同的向量</div><div><br/></div><div>我们计算不同的 ‘果’embedding&nbsp;&nbsp;出的向量的&nbsp;&nbsp;距离</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/A74CA601-0716-4468-9024-7BEFF7872F89.png" height="50%" width="80%"/></div><div>如下图所示，上面 5&nbsp;&nbsp;个句子的&nbsp;&nbsp;<span style="color: rgb(255, 0, 0);">果</span>&nbsp;&nbsp;和下面5个句子的&nbsp;&nbsp;<span style="color: rgb(255, 0, 0);">果</span>，在&nbsp;&nbsp;Bert&nbsp;&nbsp;看来是&nbsp;&nbsp;不一样的</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/05B70B0C-3482-46C0-9EF3-AE8231E0ABDA.png" height="50%" width="80%"/></div><div><br/></div><div>根据语言学的假设：一个词的意思取决于它的上下文， bert&nbsp;&nbsp;可以看做一个 deep 的 CBOW，</div><div>它是&nbsp;&nbsp;<span style="color: rgb(255, 0, 0);">带上下文信息的 word embedding&nbsp;&nbsp;</span></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/563CB4CD-4014-49D5-9A08-70A30EF7B9FB.png" height="50%" width="80%"/></div><div><br/></div><div>10.多语言的&nbsp;&nbsp;Bert&nbsp;&nbsp;</div><div><br/></div><div>把各种语言的&nbsp;&nbsp;语料都交给 bert&nbsp;&nbsp;去做填空题（pre-train）</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/A2395343-F5F9-48D4-B84E-19B3125E768A.png" height="50%" width="80%"/></div><div><br/></div><div>在英文的 QA&nbsp;&nbsp;数据集上 fine-tune&nbsp;&nbsp;的 bert&nbsp;&nbsp;可以直接拿来做&nbsp;&nbsp;中文的 QA&nbsp;&nbsp;的推理（没有中文语料的训练过程，所以是 zero-shot）</div><div><br/></div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/F3FA97A8-E5AA-4778-83EE-B840E57FB9CD.png" height="50%" width="80%"/></div><div>效果如下：</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/07DC7AA8-726C-4898-93FA-47AB4D391259.png" height="50%" width="80%"/></div><div>在 104&nbsp;&nbsp;种语言的 pre-trian&nbsp;&nbsp;的时候，模型学会了做中文的填空，在使用英文问答数据集 fine-tune&nbsp;&nbsp;后，模型自动会做中文的问答</div><div><br/></div><div>之所以能这么做的原因是&nbsp;&nbsp;它在&nbsp;&nbsp;pre-trian&nbsp;&nbsp;学到了&nbsp;&nbsp;中文&nbsp;&nbsp;和&nbsp;&nbsp;英文的各个单词的 embedding ，它会把&nbsp;&nbsp;意思相近的单词的距离拉得很近</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/421C620D-A470-4864-8C14-5946CE409464.png" height="50%" width="80%"/></div><div>实验显示，不同语言通过 bert&nbsp;&nbsp;是可以被 align&nbsp;&nbsp;到一起的，但是&nbsp;&nbsp;能work&nbsp;&nbsp;的关键是&nbsp;&nbsp;语料库要足够大 （每种语言 1000k&nbsp;&nbsp;的句子）</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/E16643B4-E1F2-4A02-B9FB-C0446E95D587.png" height="50%" width="80%"/></div><div><br/></div><div>还有一个问题，在 pre-train 的时候&nbsp;&nbsp;输入的是&nbsp;&nbsp;英文句子&nbsp;&nbsp;或者是 中文句子，那它为啥在不在做填空的时候&nbsp;&nbsp;中英文混着来填写呢</div><div><img src="/Resources/4.self-supervised%EF%BC%88Bert%20%EF%BC%89.resources/6E676F72-6C56-46C1-BD68-8389579DACC0.png" height="50%" width="80%"/></div><div>这说明&nbsp;&nbsp;Bert&nbsp;&nbsp;可以分出来&nbsp;&nbsp;哪些是&nbsp;&nbsp;中文的词，哪些是英文的词，虽然&nbsp;&nbsp;<span style="color: rgb(255, 0, 0);">鱼</span>&nbsp;&nbsp;和 <span style="color: rgb(255, 0, 0);">fish&nbsp;&nbsp;</span>在向量空间中很近，但是它们两个还是有距离的</div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://www.bilibili.com/video/BV1az4y1f7Au?p=2&amp;vd_source=b3c5acfc1adec64d81835fde68fe58d1">李宏毅《自然语言处理》</a></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="Bert的前世今生" scheme="https://xinrihui.github.io/categories/Bert%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"/>
    
    
    <category term="transformer" scheme="https://xinrihui.github.io/tags/transformer/"/>
    
    <category term="nlp" scheme="https://xinrihui.github.io/tags/nlp/"/>
    
    <category term="深度学习" scheme="https://xinrihui.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="自监督学习" scheme="https://xinrihui.github.io/tags/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="bert" scheme="https://xinrihui.github.io/tags/bert/"/>
    
  </entry>
  
  <entry>
    <title>Bert的前世今生-2.transformer</title>
    <link href="https://xinrihui.github.io/2022/12/28/3.transformer/"/>
    <id>https://xinrihui.github.io/2022/12/28/3.transformer/</id>
    <published>2022-12-28T06:53:53.000Z</published>
    <updated>2023-03-10T15:00:27.440Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2021-12-03 09:00:05 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 16:36:14 +0000"/><title>3.transformer</title></head><body><div><div><br/></div><div><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">1. encoder</span></div><div><br/></div><div><span style="font-size: 12pt;">1.encoder 使用了 self-attention</span></div><div><img src="/Resources/3.transformer.resources/3809145B-77CD-45BB-BFE8-B7C64F6D5CE8.png" height="50%" width="80%"/></div><div><br/></div><div><span style="font-size: 12pt;">2.一层一层 block&nbsp;&nbsp;的堆叠，单独抽出一个 block&nbsp;&nbsp;来看，简单来说就是 self-attention&nbsp;&nbsp;的输出再加上一个FC&nbsp;&nbsp;就作为这一层 block&nbsp;&nbsp;的输出</span></div><div><img src="/Resources/3.transformer.resources/BE0FF797-3AED-4253-BB47-F91D1C4E7CC7.png" height="50%" width="80%"/></div><div>其实要复杂一些， self-attention&nbsp;&nbsp;的输出&nbsp;&nbsp;在加上&nbsp;&nbsp;残差（residual）连接后&nbsp;&nbsp;输入到 layer normalization&nbsp;&nbsp;再输入到 FC&nbsp;&nbsp;层中</div><div><img src="/Resources/3.transformer.resources/CE2D95CD-3509-42D4-A197-ECBD4D95E10C.png" height="50%" width="80%"/>&nbsp;&nbsp;</div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">3.bert&nbsp;&nbsp;就是 transformer&nbsp;&nbsp;的 encoder&nbsp;&nbsp;的堆叠</span></div><div><br/></div><div><img src="/Resources/3.transformer.resources/45A1CB82-4D9B-41FD-91E4-766356EDB5F3.png" height="50%" width="80%"/></div><div><br/></div><div>4.其他的改进</div><div><br/></div><div>（1）residual&nbsp;&nbsp;和 layer normal&nbsp;&nbsp;可以放在别的位置</div><div>（2）layer normal&nbsp;&nbsp; 比 batch&nbsp;&nbsp;normal&nbsp;&nbsp;好在哪里</div><div><img src="/Resources/3.transformer.resources/C3A60F4C-2159-4777-B97B-38982D5953A1.png" height="50%" width="80%"/></div><div><span style="font-size: 12pt; font-weight: bold;">2. decoder</span></div><div><br/></div><ul><li><div><span style="font-weight: bold;">autoregressive decoder</span></div></li></ul><div><br/></div><div>1.中文的粒度一般为字，英文为 subword&nbsp;&nbsp;</div><div><img src="/Resources/3.transformer.resources/7E98B750-97D4-4C2E-B17D-8DEC02A578B6.png" height="50%" width="80%"/></div><div><br/></div><div>每一步的输入&nbsp;&nbsp;是模型上一步输出的结果，这样中间的某一步出错会导致后面的句子全部坏掉</div><div><br/></div><div>2.decoder 架构图</div><div><img src="/Resources/3.transformer.resources/4E2B3113-620C-4D7B-9143-A59970C95F0A.png" height="50%" width="80%"/></div><div><br/></div><div>3.mask self-attention</div><div><br/></div><div><img src="/Resources/3.transformer.resources/16AA2A4B-EE97-4268-B5D2-082727A3051B.png" height="50%" width="80%"/></div><div>在解码的时候，我们是一步一步来的，即在&nbsp;&nbsp;输出 b1&nbsp;&nbsp;时&nbsp;&nbsp;只能看到 a1，在输出&nbsp;&nbsp; b2&nbsp;&nbsp;时，只能看到 a1&nbsp;&nbsp;和 a2 ；</div><div>而在编码的时候，我可以看到整个序列</div><div><br/></div><div><img src="/Resources/3.transformer.resources/004F7412-5ACF-4A5E-B4C8-87DAF655C1CB.png" height="50%" width="80%"/></div><div><span style="font-size: unset; color: unset; font-family: unset;">产生结束符号的时候，解码结束</span></div><div><img src="/Resources/3.transformer.resources/460FCBD7-EDE3-4912-BE0F-9AD22CEFC43E.png" height="50%" width="80%"/></div><div><br/></div><ul><li><div><span style="font-weight: bold;">non-autoregressive decoder</span></div></li></ul><div><br/></div><div>1.在&nbsp;&nbsp;autoregressive&nbsp;&nbsp; 中是一个步步进行解码，即每一步的输出是下一步的输入，</div><div>而 NAT&nbsp;&nbsp;是并行解码，输入的所有时间步都是 <start>，&nbsp;&nbsp;输出为&nbsp;&nbsp;所有时间步的解码结果</div><div><img src="/Resources/3.transformer.resources/2610191A-8225-48E6-9B48-E09054FEC120.png" height="50%" width="80%"/></div><div>如何决定解码序列的长度</div><ul><li><div>另外训练一个回归模型，输入为源句子，输出为目标句子的长度</div></li><li><div>使用固定的解码序列长度，丢弃在 <end>&nbsp;&nbsp;后的解码序列</div></li></ul><div><br/></div><div>2.NAT&nbsp;&nbsp;的优势：可以利用 self-attention&nbsp;&nbsp;的并行解码，并且可以控制输出的长度</div><div>（eg.&nbsp;&nbsp;在语音合成系统中，语音输出的时候我想要语速快一点，就可以把解码序列的长度减半）</div><div><br/></div><div>3.解码序列的准确性（performance） 比 AT&nbsp;&nbsp;差，原因是 <span style="font-weight: bold;">multi-modality</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">3.&nbsp;&nbsp;</span><span style="font-weight: bold;">encoder&nbsp;&nbsp;和 decoder&nbsp;&nbsp;中间连接部分（</span><span style="font-weight: bold;">cross attention</span><span style="font-weight: bold;">）</span></div><div><br/></div><div>1.在 cross attention&nbsp;&nbsp;中，两个蓝色的输入来自 encoder ，一个绿色的来自 decoder&nbsp;&nbsp;</div><div><br/></div><div><img src="/Resources/3.transformer.resources/8C7AE296-1A6F-48E4-BA82-9F1FBEB0EAEF.png" height="50%" width="80%"/></div><div><br/></div><div>k,v&nbsp;&nbsp;来自 encoder ，而 q&nbsp;&nbsp;来自 decoder</div><div><img src="/Resources/3.transformer.resources/6DE9F2B5-9E5D-4088-BD0F-DFDBBF319C18.png" height="50%" width="80%"/></div><div><br/></div><div>2.cross attention&nbsp;&nbsp;的改进</div><div><br/></div><div>可以有各式各样的连接方式，例如 在 encoder&nbsp;&nbsp;的中间层就输出给&nbsp;&nbsp;cross attention，</div><div><img src="/Resources/3.transformer.resources/DF38D578-34DE-44A8-A8EB-FABD5CC68755.png" height="50%" width="80%"/></div><div><br/></div><div><span style="font-size: 12pt; font-weight: bold;">4. 训练</span></div><div><br/></div><div>1.给 decoder&nbsp;&nbsp;的输入为正确答案&nbsp;&nbsp;而不是上一步它自己的输出，这是 teacher forcing</div><div><img src="/Resources/3.transformer.resources/C0AF8502-55DE-4005-9E4F-FACEB814DB1F.png" height="50%" width="80%"/></div><div>&nbsp;&nbsp;</div><div>训练的时候永远看到的都是正确的序列，但是在推理的时候有可能会产生错误的输出，这里存在的mismatch 被称为 exposure bias&nbsp;&nbsp;</div><div><img src="/Resources/3.transformer.resources/2B7A9250-C34D-433B-B9AF-39438CDDA0E3.png" height="50%" width="80%"/></div><div><br/></div><div>解决方法是在训练的时候&nbsp;&nbsp;给输入的序列随机加入噪声，</div><div><br/></div><div><img src="/Resources/3.transformer.resources/666E0005-ABD2-45EE-90CE-4D8806C2B076.png" height="50%" width="80%"/></div><div><br/></div><div>2.生僻的内容训练语料中没有，我们可以从输入（source）中直接 copy&nbsp;&nbsp;给模型</div><div><br/></div><div><img src="/Resources/3.transformer.resources/E7FED90F-935E-41C1-A651-A3D0F19AD5B8.png" height="50%" width="80%"/></div><div><br/></div><div>想让一个 seq2seq model&nbsp;&nbsp;输出人类的语句，起码需要&nbsp;&nbsp;百万条句子的训练语料</div><div><br/></div><div>3.在一些应用中，我们需要规定 attention&nbsp;&nbsp;的作用规则：</div><div><br/></div><div>（1）强迫 attention&nbsp;&nbsp;看到每一个时间步，eg.&nbsp;&nbsp;机器翻译有一段话没有被翻译出来，这令人无法接受</div><div>（2）规定&nbsp;&nbsp;attention&nbsp;&nbsp; 按照从左到右的顺序看所有的输入</div><div><br/></div><div><img src="/Resources/3.transformer.resources/4D5CD2E6-DA54-4986-88BA-7CD55C99A096.png" height="50%" width="80%"/></div><div><br/></div><div>4.beam search&nbsp;&nbsp;不一定有用</div><div><br/></div><div><img src="/Resources/3.transformer.resources/0B12CF70-DCCE-4A9D-AE97-56714A11BE60.png" height="50%" width="80%"/></div><div>decoder&nbsp;&nbsp;部分加一些随机性，有时会得到更好的结果</div><div><br/></div><div>5.<span style="font-size: unset; color: unset; font-family: unset;">训练的时候我们是&nbsp;&nbsp; minimize&nbsp;&nbsp;所有时间步的&nbsp;&nbsp;Cross entropy，但是在评价的时候&nbsp;&nbsp;我们是想要 maximize bleu score&nbsp;&nbsp;</span></div><div><img src="/Resources/3.transformer.resources/AC6C3B58-BED4-4DF1-AE95-8FC533CE35C5.png" height="50%" width="80%"/></div><div>可以直接把 bleu score&nbsp;&nbsp;作为&nbsp;&nbsp;损失函数？</div><ul><li><div>这个问题比较复杂，因为&nbsp;&nbsp;bleu score&nbsp;&nbsp;无法微分，也就做不了梯度下降，可以考虑强化学习</div></li></ul><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://www.bilibili.com/video/BV1az4y1f7Au?p=2&amp;vd_source=b3c5acfc1adec64d81835fde68fe58d1">李宏毅《自然语言处理》</a></div><div><br/></div><div><br/></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="Bert的前世今生" scheme="https://xinrihui.github.io/categories/Bert%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"/>
    
    
    <category term="transformer" scheme="https://xinrihui.github.io/tags/transformer/"/>
    
    <category term="nlp" scheme="https://xinrihui.github.io/tags/nlp/"/>
    
    <category term="深度学习" scheme="https://xinrihui.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Bert的前世今生-1. self-attention</title>
    <link href="https://xinrihui.github.io/2022/12/28/2.%20self-attention/"/>
    <id>https://xinrihui.github.io/2022/12/28/2.%20self-attention/</id>
    <published>2022-12-28T06:53:53.000Z</published>
    <updated>2023-03-10T14:56:14.679Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2021-11-17 13:17:27 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="https://www.tensorflow.org/text/tutorials/nmt_with_attention#download_and_prepare_the_dataset"/><meta name="updated" content="2022-12-28 06:32:13 +0000"/><title>2. self-attention</title></head><body><div><div><br/></div><div>1.简单地使用 FC 层来做序列标注，显然没有考虑上下文信息，因此可以在FC层的基础上 增加一个窗口，但是序列的长度会发生变化，窗口的大小不容易设置</div><div><br/></div><div><img src="/Resources/2.%20self-attention.resources/E27567C1-3EC2-4981-9FE0-4E875662A4FF.png" height="50%" width="80%"/><br/></div><div><br/></div><div><br/></div><div>2.self-attention 中每一个时间步的输出都考虑了所有时间步的输入</div><div><img src="/Resources/2.%20self-attention.resources/ECB62272-F212-4A16-9474-1637A261BC53.png" height="50%" width="80%"/><br/></div><div><br/></div><div>3.与以前的 soft attention 一样，关键是 计算 注意力的权重 alpha，</div><ul><li><div>在 soft attention 中，注意力的权重 alpha 代表的是 解码器的 隐状态 h_t-1 和 编码器的输出向量 a_j 之间的相关程度，</div></li><li><div>在 self-attention 中，注意力的权重 alpha 代表的是 输入向量 a_i 和 输入向量 a_j 的相关程度</div></li></ul><div><img src="/Resources/2.%20self-attention.resources/31C0ABAE-9B02-4F26-8986-2C376401CA70.png" height="50%" width="80%"/><br/></div><div><br/></div><div>4.注意力权重 alpha 的计算方法（对齐模型）</div><div><img src="/Resources/2.%20self-attention.resources/039B1782-7449-46B8-93A0-AECAC50BE537.png" height="50%" width="80%"/><br/></div><ul><li><div>additive attention</div></li></ul><div><br/></div><div>利用输出层维度为1 的前馈神经网络 ，得到注意力的权重</div><div><br/></div><ul><li><div>dot-product attention</div></li></ul><div><br/></div><div>二者的理论复杂度相同，但是在实践中，dot-product更快，而且节省空间，因为它可以利用很多 优化后的矩阵相乘算子。</div><div><br/></div><div>对于较小的dk而言，这两种机制的性能相似。但是当 dot product 对于较大的dk则不进行缩放的时候 ，additive attention的效果要优于dot product attention，。</div><div><br/></div><div>我们怀疑对于较大的dk值，点积的幅度会增大，从而将softmax函数推入梯度极小的区域。为了减少这样的 影响，我们给dot products乘上了 一个缩放因子</div><div><br/></div><div><br/></div><div>5.某时间步的 q_1 向量 和 其余所有时间步的 k_j 向量 计算dot-product  得到注意力权重 alpha</div><div><br/></div><div><img src="/Resources/2.%20self-attention.resources/AD7C7160-6196-4EC6-A6D5-BC56907BEF83.png" height="50%" width="80%"/><br/></div><div><br/></div><div>然后对所有 时间步的 v 向量加权求和得到 第一个时间步的输出向量 b_1</div><div><img src="/Resources/2.%20self-attention.resources/E99A5657-CACF-4466-9716-1ABAA8276D34.png" height="50%" width="80%"/><br/></div><div><br/></div><div>6.将上述过程 采用向量化的方式进行计算</div><div><br/></div><div><img src="/Resources/2.%20self-attention.resources/2448EF10-B950-44BF-8D54-7859161203E3.png" height="50%" width="80%"/><br/></div><div><img src="/Resources/2.%20self-attention.resources/D0AA72C4-5741-45DC-A9FC-8CAEC0993FEE.png" height="50%" width="80%"/><br/></div><div>上图中 是对每一列做 softmax，一个列是针对 某个时间步 t 的一套权重</div><div><br/></div><div><img src="/Resources/2.%20self-attention.resources/B781FF61-0004-4D96-BEED-9AA6CB6451B4.png" height="50%" width="80%"/><br/></div><div><br/></div><div>总结向量化计算的过程可以发现，看似虽然复杂，但是只有 W 为需要学习的参数矩阵；</div><div>这种大的矩阵乘法 GPU 是最喜欢的（全部可以并行），而 RNN 只能一个一个时间步地计算</div><div><img src="/Resources/2.%20self-attention.resources/07693885-DAB6-4495-95FC-972CB7E775F8.png" height="50%" width="80%"/><br/></div><div><br/></div><div>7.上述例子都是 one-head 的 self-attention ， multi-head attention 就是 有两套的 Q, K, V 向量</div><div><br/></div><div><img src="/Resources/2.%20self-attention.resources/AF2B1835-4624-4039-9186-D41033A44056.png" height="50%" width="80%"/><br/></div><div><br/></div><div>每个时间步都输出 2个 b向量， 我们将 2个 b 向量合并然后映射为 1个 b 向量</div><div><img src="/Resources/2.%20self-attention.resources/60521F3D-9448-47E1-85C6-61962C799E67.png" height="50%" width="80%"/><br/></div><div><br/></div><div>8.位置编码</div><div><br/></div><div>transformer 既没有 RNN的 recurrence 也没有 CNN 的convolution，从上面的计算可以看出 self-attention 对每一个时间步都是同等对待，因此没有考虑时序的信息，但是序列建模的场景下显然时序的信息至关重要，比如"你欠我100万明天要还" 和 "我欠你100万明天要还" 的含义截然不同。</div><div><img src="/Resources/2.%20self-attention.resources/925A41FB-D29A-4AEA-9CAA-3073168781B7.png" height="50%" width="80%"/><br/></div><div>每一个位置用一个独立的位置向量 e 表示，然后和 token 的 embedding 相加，</div><div>向量e 的生成方式可以是 手工去设计（hand-crafted），也可以是从数据中学来的（learned from data）</div><div><br/></div><ul><li><div>transformer 计算token的位置信息 使用的是正弦波</div></li></ul><div>　　　　　　<img src="/Resources/2.%20self-attention.resources/33BDE66A-C0D6-451A-AE4D-57B99E6A78AD.png" height="50%" width="80%"/><br/></div><div>考虑 使用 长度为 512 的 one-hot 向量来表示位置，</div><div>eg. 位置为0 表示为 [1,0,0,...,0]，位置为1表示为 [0,1,0,...,0]</div><div><br/></div><div>由于正弦/余弦 是周期函数，有 Mod （取模）的效果，这样即使 位置 超过 512 也能被表示</div><div><br/></div><ul><li><div>BERT 直接训练一个position embedding来保留位置信息，每个位置随机初始化一个向量，加入模型训练，最后就得到一个包含位置信息的embedding，然后直接将 position embedding 和 word embedding 相加</div></li></ul><div><br/></div><div>位置编码有多种方法，这是一个探索的热点</div><div><img src="/Resources/2.%20self-attention.resources/FF475E9D-1BDC-4139-AB76-0AC9AD7FA1BE.png" height="50%" width="80%"/><br/></div><div><br/></div><div><br/></div><div>要表示位置信息，首先出现在脑海里的一个点子可能是，给句子中的每个词赋予一个相位，也就是[0, 1]中间的一个值，第一个词是0，最后一个词是1，中间的词在0到1之间取值。</div><div>这是个符合直觉的想法，但是其中一个问题在于，你并不知道每个句子中词语的个数是多少，这会导致每个词语之间的间隔变化是不一致的。而对于一个句子来说，每个词语之间的间隔都应该是具有相同含义的。</div><div>那为了保证每个词语的间隔含义一致，我们是不是可以给每个词语添加一个线性增长的时间戳呢？比如说第一个词是0，第二词是1，以此类推，第N个词的位置编码是N。</div><div>这样其实也会有问题。同样，我们并不知道一个句子的长度，如果训练的句子很长的话，这样的编码是不合适的。</div><div><br/></div><div>因此，理想状态下，编码方式应该要满足以下几个条件：</div><ul><li><div>对于每个位置的词语，它都能提供一个独一无二的编码</div></li><li><div>词语之间的间隔对于不同长度的句子来说，含义应该是一致的</div></li><li><div>能够随意延伸到任意长度的句子</div></li></ul><div><br/></div><div>文章提出了一种简单且有效的编码能够满足以上所有条件:</div><div><img src="/Resources/2.%20self-attention.resources/16994309-21A8-4EB9-A6FB-B462E8E7437B.png" height="50%" width="80%"/></div><div>其中：</div><div><img src="/Resources/2.%20self-attention.resources/2AA7C04D-C867-4828-9BD5-243DC154E45D.png" height="50%" width="80%"/></div><div><br/></div><div>t 表示当前时间步，即 token 在句子中的位置， 向量 p_t 表示的是该词语对应的位置编码，  d表示的是编码的维度。</div><div><img src="/Resources/2.%20self-attention.resources/33DA41A8-174B-49D1-B42C-291474E64D6C.png" height="50%" width="80%"/></div><div>d=512</div><div><div><br/></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div>i</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>k=(i//2)</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>w_k</div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div>0</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>0</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>1</div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div>1</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>0</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>1</div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div>2</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>1</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>0.96466162</div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div>3</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>1</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>0.96466162</div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div>....</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><br/></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div>511</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>255</div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div>0.00010366</div></td></tr></tbody></table><div><br/></div></div><div><br/></div><div>从公式可以看出，其实一个词语的位置编码是由不同频率的余弦函数函数组成的，从低位到高位，余弦函数对应的频率由 1.03 (约等于1) 降低到了 1/10000  ，按照论文中的说法，也就是，波长从  2*pai 增加到了 1000*2*pai。</div><div><br/></div><div>为什么这样简单的sines和cosines的组合可以表达位置信息呢？一开始的确有点难理解。别着急，这边举个二进制的例子就明白了。可以观察一下下面这个表，我们将数字用二进制表示出来。可以发现，每个比特位的变化率是不一样的，越低位的变化越快，红色位置0和1每个数字会变化一次，而黄色位，每8个数字才会变化一次。对应上面的 p_t，向量中低位（k小）频率高，变化的快，而高位（k大）频率低，变化的慢</div><div><img src="/Resources/2.%20self-attention.resources/9BAAAD5B-66D9-4C77-AD2F-3C66845A68E3.jpg" height="50%" width="80%"/><br/></div><div><br/></div><div>不同频率的sines和cosines组合其实也是同样的道理，通过调整三角函数的频率，我们可以实现这种低位到高位的变化，这样的话，位置信息就表示出来了。</div><div><img src="/Resources/2.%20self-attention.resources/8188AA05-AE44-4ED0-ACEF-A048EB7055CD.png" height="50%" width="80%"/><br/></div><div><br/></div><div><br/></div><div>9.与 CNN 的关系</div><div><br/></div><div>图像的通道数量 可以 作为序列的时间维度，这样 图像也能当做序列数据 来处理</div><div><img src="/Resources/2.%20self-attention.resources/DC54BE41-E686-49CA-868F-F2AF29F824D0.png" height="50%" width="80%"/><br/></div><div><br/></div><div>self-attention 可以看做是 一个 flexible的 CNN；</div><div>CNN可以看做是一个 窗口（视野） 受到限制的 self-attention</div><div><img src="/Resources/2.%20self-attention.resources/F2510500-9041-4F87-BDD2-C506CD343A4A.png" height="50%" width="80%"/><br/></div><div><img src="/Resources/2.%20self-attention.resources/501D7398-9CAC-498C-BDA6-9E93230344AB.png" height="50%" width="80%"/><br/></div><div><br/></div><div>self-attention 是比 CNN 更大的模型，因此在大数据量下才能发挥它的威力</div><div><br/></div><div><img src="/Resources/2.%20self-attention.resources/4E7E22F3-1D29-4BDA-A20E-BBE97A12A5D2.png" height="50%" width="80%"/><br/></div><div><br/></div><div>10.与 RNN 的关系</div><div><br/></div><ul><li><div>循环模型（ Recurrent models）最大的问题在于  其顺序的性质 导致 无法并行化的训练，而且容易超过内存的限制（比如50tokens长度的句子就会占据很大的内存）</div></li></ul><div><br/></div><ul><li><div>self-attention 可以更好的对长距离的依赖进行 建模</div></li></ul><div><br/></div><div><img src="/Resources/2.%20self-attention.resources/C9B8292C-8E56-4D55-9763-00D308748289.png" height="50%" width="80%"/><br/></div><div><br/></div><div><br/></div><div>11.与 GNN 的关系</div><div><br/></div><div>将图上的所有节点都看做 输入向量， self-attention 的初始假设是 某个向量 和 其余所有向量都有联系，而有了图中的拓扑信息后，我们可以只计算图中有链接的两个向量</div><div><br/></div><div><img src="/Resources/2.%20self-attention.resources/A15E879F-E471-44C7-957D-D5639E14BD86.png" height="50%" width="80%"/><br/></div><div>这也是 GNN 的一种</div><div><br/></div><div><br/></div><div>12.各种 self-attention 的变形</div><div><br/></div><div>原始的  self-attention  的问题在于计算量过大，后面的很多变形都是为了加快计算，但是相对应的在 benchmark 上的得分就差了</div><div><br/></div><div><img src="/Resources/2.%20self-attention.resources/4AE9CECB-B0EC-46D4-957E-1F88ED8A0F8C.png" height="50%" width="80%"/><br/></div><div><br/></div><div><br/></div></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://www.bilibili.com/video/BV1az4y1f7Au?p=2&amp;vd_source=b3c5acfc1adec64d81835fde68fe58d1">李宏毅《自然语言处理》</a></div><div><a href="https://www.zhihu.com/people/xeon-4-47/posts">https://www.zhihu.com/people/xeon-4-47/posts</a></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="Bert的前世今生" scheme="https://xinrihui.github.io/categories/Bert%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"/>
    
    
    <category term="transformer" scheme="https://xinrihui.github.io/tags/transformer/"/>
    
    <category term="nlp" scheme="https://xinrihui.github.io/tags/nlp/"/>
    
    <category term="深度学习" scheme="https://xinrihui.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Bert的前世今生-4.self-supervised（Bert 和它的朋友们）</title>
    <link href="https://xinrihui.github.io/2022/12/28/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89/"/>
    <id>https://xinrihui.github.io/2022/12/28/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89/</id>
    <published>2022-12-28T06:53:53.000Z</published>
    <updated>2023-03-10T15:00:27.443Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2021-12-07 13:24:46 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 16:36:35 +0000"/><title>5.self-supervised（Bert 和它的朋友们）</title></head><body><div><div><span style="font-weight: bold;">Part1. how to pre-train</span></div><div><br/></div><div>1.在 bert&nbsp;&nbsp;之前&nbsp;&nbsp;我们早就有 pre-train model 了，&nbsp;&nbsp;比如&nbsp;&nbsp;词向量</div><div><br/></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/2E731020-C47D-4903-AA07-02CE13FA33E2.png" height="50%" width="80%"/></div><div>有一个table（矩阵） 去存每一个词（word）的词向量，需要的时候&nbsp;&nbsp;就去里面找</div><div><br/></div><div>对于英文来说，把 token&nbsp;&nbsp;的粒度设置到&nbsp;&nbsp;单词，会有一个问题，就是英文的单词太多了，</div><div>肯定会有&nbsp;&nbsp;训练语料中没有见过的单词，它肯定不在&nbsp;&nbsp;table&nbsp;&nbsp;里。</div><div><br/></div><div>我们可以把&nbsp;&nbsp;token&nbsp;&nbsp;的粒度设置到&nbsp;&nbsp; 字符（character），把&nbsp;&nbsp;所有的字符输入到模型中，输出该单词的 embedding，这就是 fast-text</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/965A66E6-617D-49EF-94A8-250AE6F2CE84.png" height="50%" width="80%"/></div><div><br/></div><div>对于中文，可以把&nbsp;&nbsp;文字图片丢给 CNN，让模型去学&nbsp;&nbsp;中文的形态&nbsp;&nbsp;和&nbsp;&nbsp;文字意思的&nbsp;&nbsp;关系</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/4FD17156-12F3-4487-9F32-E6328E82563E.png" height="50%" width="80%"/></div><div><br/></div><div>上述模型的问题是，对于&nbsp;&nbsp;同一个 token ，它对应的 embedding&nbsp;&nbsp;是一样的，并没有考虑上下文的信息</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/9A157133-5BAF-478D-82AD-8444B1C33624.png" height="50%" width="80%"/></div><div>eg. '养只<span style="color: rgb(255, 0, 0);">狗'</span>&nbsp;&nbsp;和 '单身<span style="color: rgb(255, 0, 0);">狗'</span>&nbsp;&nbsp;中对&nbsp;&nbsp;<span style="color: rgb(255, 0, 0);">狗</span>&nbsp;&nbsp;的 embedding&nbsp;&nbsp;是相同的</div><div><br/></div><div>2.contextualized word embedding&nbsp;&nbsp;</div><div><br/></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/2FB5FE3C-B391-4998-8B98-00EF5251CDB0.png" height="50%" width="80%"/></div><div>Bert， ElMo 也是一个&nbsp;&nbsp;token&nbsp;&nbsp;对应一个 embedding，但是它是把整个句子看过之后，再给句子中的每一个 token&nbsp;&nbsp;一个 embedding，</div><div>显然，这个 token&nbsp;&nbsp; 的&nbsp;&nbsp;embedding&nbsp;&nbsp;是考虑了上下文信息的</div><div><br/></div><div>这种&nbsp;&nbsp;考虑上下文信息的 word embedding&nbsp;&nbsp; 最早起源于 CoVe</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/729BEF6D-9B4E-4748-86F6-3FF6D21252FD.png" height="50%" width="80%"/></div><div>它通过训练一个 seq2seq 翻译模型来拿到 word&nbsp;&nbsp;的&nbsp;&nbsp;embedding （图中 encoder&nbsp;&nbsp;输出的彩色向量），</div><div>使用翻译任务来做 pre-train 是比较合适的，因为模型会关注到每一个词，<span style="font-size: unset; color: unset; font-family: unset;">若使用 摘要任务，模型会 忽视那些不重要词，因此无法拿到每一个词的&nbsp;&nbsp;embedding，</span></div><div>但是&nbsp;&nbsp;它有一个问题，就是&nbsp;&nbsp;平行语料的数目太少了。</div><div>那么能不能用&nbsp;&nbsp;现成的&nbsp;&nbsp;没有标注的文本去训练呢</div><div><br/></div><div>3.最朴素的想法是&nbsp;&nbsp;来自于&nbsp;&nbsp;语言模型的 predict next token&nbsp;&nbsp;</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/15B308CD-6C44-4E8C-B65C-B11983F4D728.png" height="50%" width="80%"/></div><div><br/></div><div>一开始大家都用 LSTM，后来改为使用 self-attention</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/746A729E-9A7B-4FFC-A5EF-AB3694721231.png" height="50%" width="80%"/></div><div>因为是模型要预测下一个词，我们不能让模型偷看到&nbsp;&nbsp;未来的序列，所以在模型做 attention&nbsp;&nbsp;的时候要限制它的视野（ mask self-attention ），</div><div>如上图，在第 1&nbsp;&nbsp;个时间步 要&nbsp;&nbsp;限制&nbsp;&nbsp;它的 attention&nbsp;&nbsp;只能看到 w1，</div><div>在第 2个时间步要&nbsp;&nbsp;限制&nbsp;&nbsp;它的attention&nbsp;&nbsp;只能看到 w1, w2</div><div><br/></div><div>在&nbsp;&nbsp;predict next token&nbsp;&nbsp;中，会把所有&nbsp;&nbsp;上文（左侧） 的信息都编码到隐状态向量中，然后来预测下一个单词</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/6870F8D8-55C8-41BA-8684-EAD2FDD54221.png" height="50%" width="80%"/></div><div>很显然，我们可以把下文（右边）的信息也编码进来</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/6FD5AEA3-2009-4CF6-B678-25173F34E307.png" height="50%" width="80%"/></div><div>ELMO&nbsp;&nbsp;有两个 LSTM （双向 LSTM）：</div><div>&nbsp;&nbsp; 一个正向的 LSTM，从左往右编码，一个反向的 LSTM&nbsp;&nbsp;从右往左编码，然后将两个 LSTM&nbsp;&nbsp;的编码向量拼接起来；</div><div>但是，它还是有不足之处，这两个LSTM&nbsp;&nbsp;是独立编码的，我们能不能在编码的时候就考虑&nbsp;&nbsp;所有的上下文</div><div><br/></div><div>4.比 predict next token&nbsp;&nbsp; 更好的思路：做填空（masking input）</div><div><br/></div><div>随机盖住&nbsp;&nbsp;某个位置的 token，让模型去预测被盖住的位置</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/3A649836-797A-4617-BB5D-03E87F2F6CD0.png" height="50%" width="80%"/></div><div>bert&nbsp;&nbsp;采用的是&nbsp;&nbsp;没有限制的 self-attention，就是&nbsp;&nbsp;每一个时间步都可以 attend&nbsp;&nbsp;所有的时间步</div><div><br/></div><div>做填空的思路早就有了：上古神兽 CBOW</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/AEBF5DEB-7568-4B95-9BCB-F2AFC915C355.png" height="50%" width="80%"/></div><div>CBOW&nbsp;&nbsp;与 bert&nbsp;&nbsp;的区别在于：</div><div>（1）CBOW&nbsp;&nbsp; 的窗口大小有限，至多&nbsp;&nbsp;上下20个单词，而 bert&nbsp;&nbsp;是整个句子</div><div>（2）CBOW&nbsp;&nbsp; 的 embedding 模型很简单，连激活函数都没有，就是线性的，而&nbsp;&nbsp;Bert&nbsp;&nbsp;是用了很多层的 self-attention&nbsp;&nbsp;</div><div><br/></div><div>随机盖住&nbsp;&nbsp;某个位置的 token&nbsp;&nbsp;不一定是一个好的方法，因为&nbsp;&nbsp;如果是中文，一般 token&nbsp;&nbsp;的粒度是字，我们盖住&nbsp;&nbsp;某个字，</div><div>模型很容易从&nbsp;&nbsp;旁边的子来预测出这个字是什么， eg.&nbsp;&nbsp;黑X江，模型很容易学到 X=龙，这样模型就不会去学 long-term&nbsp;&nbsp;的 dependence</div><div><br/></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/4DFB62E1-19EF-4BB6-9417-47BB96CDD5A4.png" height="50%" width="80%"/></div><div>因此我们可以&nbsp;&nbsp;盖住&nbsp;&nbsp;整个词（whole word masking），甚至是一个&nbsp;&nbsp;短语（phrase） 和&nbsp;&nbsp;命名实体（entity），让模型去做难一点的事情</div><div><br/></div><div>还可以&nbsp;&nbsp;每次盖住&nbsp;&nbsp;随机长度的 token ，下表格&nbsp;&nbsp;是各种 mask&nbsp;&nbsp;方法 在benchmark&nbsp;&nbsp;上的成绩</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/AA05CC6E-69E2-40CF-ABBA-005798FD0FC2.png" height="50%" width="80%"/></div><div><br/></div><div>上面的方法是&nbsp;&nbsp;从&nbsp;&nbsp;<span style="color: rgb(255, 0, 0);">mask&nbsp;&nbsp;的粒度</span> 出发来考虑；</div><div><br/></div><div>还有从 <span style="color: rgb(255, 0, 0);">上下文（context）的选取方法</span> 出发来改进 masking input&nbsp;&nbsp;方法，XLNet：</div><div><br/></div><div><br/></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/945FAB9C-6DF1-4019-975F-8EC49DB6E48E.png" height="50%" width="80%"/></div><div><br/></div><ul><li><div><span style="font-size: unset; color: unset; font-family: unset;">从语言模型的角度看，把&nbsp;&nbsp;句子中的&nbsp;&nbsp;token&nbsp;&nbsp;打乱顺序，然后让模型去预测下一个是什么</span></div></li></ul><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/F04B7DE6-25D7-4FCD-9D4A-48D01E9F4E76.png" height="50%" width="80%"/></div><ul><li><div>从 self-attenion&nbsp;&nbsp;的角度，<span style="font-size: unset; color: unset; font-family: unset;">之前我们是用&nbsp;&nbsp;所有上下文的 token&nbsp;&nbsp;来预测这个被 mask&nbsp;&nbsp;的位置，</span><span style="font-size: unset; color: unset; font-family: unset;">在&nbsp;&nbsp;XLNet&nbsp;&nbsp;中，是用&nbsp;&nbsp;随机选取的上下文信息来预测</span></div></li></ul><div><br/></div><div>5.bert&nbsp;&nbsp;不适合做&nbsp;&nbsp;语言生成（generation）的任务</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/73E77676-6994-4722-9EAF-98D859BFACDC.png" height="50%" width="80%"/></div><div>语言生成任务是&nbsp;&nbsp;给前面的序列（上文），让模型去生成下一个 token，语言模型在训练的时候就符合这一过程；</div><div>而 bert&nbsp;&nbsp;在训练的时候&nbsp;&nbsp;是把中间的某个位置 mask&nbsp;&nbsp;掉，去用上下文来预测这个位置的单词，</div><div>在推理时，我们可以每次把&nbsp;&nbsp;最后一个 token mask&nbsp;&nbsp;掉，然后让&nbsp;&nbsp;Bert&nbsp;&nbsp;来预测最后一个位置填啥，但是这么做和训练的状况不符合，即模型很少遇到这种情况，导致效果一般；</div><div>上述讨论前提是采用 autoregressive model，即我们是从左到右按顺序来生成 token ，若采用 non-autoregressive，bert&nbsp;&nbsp;在做语言生成的效果会更好</div><div><br/></div><div>5.即然 bert&nbsp;&nbsp;不适用与&nbsp;&nbsp;语言生成，那么如何用它做 seq2seq</div><div><br/></div><div>显然我们可以得到一个 pre-train&nbsp;&nbsp;的 encoder，&nbsp;&nbsp; 那么如何&nbsp;&nbsp;得到 pre-train&nbsp;&nbsp;的 decoder</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/0440D228-AD8F-44D6-AEF5-DC9F0554A170.png" height="50%" width="80%"/></div><div><span style="font-size: unset; color: unset; font-family: unset;">输入的</span> <span style="font-size: unset; color: unset; font-family: unset;">sequence</span><span style="font-size: unset; color: unset; font-family: unset;">为 w1,w2,w3,w4，训练时的 标签（ground truth） 也为&nbsp;&nbsp;w1,w2,w3,w4，</span></div><div>若直接训练，模型是学不到东西的，它会把 w1&nbsp;&nbsp;原封不动的作为第一个输出，并以此类推，</div><div><span style="font-size: unset;"><br/></span></div><div><span style="font-size: unset; color: unset; font-family: unset;">所以我们要把输入的 source sequence 弄坏，让&nbsp;&nbsp;模型去输出一个&nbsp;&nbsp;正确的 target&nbsp;&nbsp;sequence，</span></div><div>把&nbsp;&nbsp;<span style="font-size: unset; color: unset; font-family: unset;">source sequence 弄坏&nbsp;&nbsp;的方法有很多，比如&nbsp;&nbsp;遮盖，删除，重新排序，旋转....</span></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/D85BA5FE-EE99-4B44-948E-9F85BA7B649B.png" height="50%" width="80%"/></div><div>论文 MASS&nbsp;&nbsp; 使用了上图中的第一种方法，</div><div>论文 BART&nbsp;&nbsp; <span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">使</span>用了上图的后面四种方法，发现&nbsp;&nbsp;<span style="color: rgb(255, 70, 53);">打乱 token&nbsp;&nbsp;的排序</span> 和 <span style="color: rgb(255, 0, 0);">句子旋转</span> 的效果不好，</div><div>最好的方法是 text infilling （mask&nbsp;&nbsp;的位置包括 0-N&nbsp;&nbsp;个 token）</div><div><br/></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/681F34F6-E4CA-458E-8311-D171C136AB78.png" height="50%" width="80%"/></div><div><br/></div><div>6.&nbsp;&nbsp;大一统模型 UniLM，一个模型&nbsp;&nbsp;即是 encoder&nbsp;&nbsp;又是 decoder&nbsp;&nbsp;还是 seq2seq（encoder +decoder&nbsp;&nbsp;） ，包打天下</div><div><br/></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/B1F274CE-7CCD-4E17-BFAF-C682922C8C74.png" height="50%" width="80%"/></div><div>（&nbsp;&nbsp;上图白色方框为&nbsp;&nbsp;<span style="color: rgb(255, 0, 0);">能看到</span> ）</div><div>一个模型有 3&nbsp;&nbsp;种训练的方法：</div><ul><li><div>Bert&nbsp;&nbsp;的&nbsp;&nbsp;训练方法（encoder），每个&nbsp;&nbsp;时间步能看到全部的上下文（attend to all tokens）</div></li><li><div>GPT&nbsp;&nbsp;的 训练方法 （decoder），每个&nbsp;&nbsp;时间步&nbsp;&nbsp;只能看到上文（attend to left tokens）</div></li><li><div>BART / MASS （seq2seq），左半部分是 encoder ，每个&nbsp;&nbsp;时间步能看到 segment1&nbsp;&nbsp;的全部上下文，<span style="font-size: unset; color: unset; font-family: unset;">右半部分的 decoder ，</span>每个&nbsp;&nbsp;时间步&nbsp;&nbsp;只能看到上文</div></li></ul><div><br/></div><div>7.让模型在很大的词表中找一个最佳的 token（ K分类问题，K&nbsp;&nbsp;很大），所产生的计算量很大，有没有降低计算量的方法</div><div><br/></div><div>我们可以&nbsp;&nbsp;把 句子中某个位置的词置换掉（replace）然后让模型来判断这里是否发生了置换</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/AEE3D8F2-64E6-4C9F-90D7-55CDB5E875CC.png" height="50%" width="80%"/></div><div><br/></div><div>原句子是 the chef cook the meal ，我们把&nbsp;&nbsp;cook&nbsp;&nbsp;替换为 ate ，希望模型能发现这个位置的 token 被替换了。</div><div>对比 传统的&nbsp;&nbsp;做填空（masking input）方法，它有两个好处：</div><ul><li><div>二分类 计算量低</div></li><li><div>sequence 的每一个位置都用上了（每个位置 模型&nbsp;&nbsp;都可以用来学习&nbsp;&nbsp;二分类），而&nbsp;&nbsp; <span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">masking input&nbsp;&nbsp;模型只会去学</span>&nbsp;&nbsp;被 mask&nbsp;&nbsp;的位置&nbsp;&nbsp;</div></li></ul><div><br/></div><div>问题是怎么去做 token&nbsp;&nbsp;的替换，我们期待替换后的句子语法上没有问题，但是语义和原来的不同</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/C69DB1EF-9843-406D-A451-5298CD4BA472.png" height="50%" width="80%"/></div><div>用一个&nbsp;&nbsp;很小的 pre-train bert&nbsp;&nbsp;来&nbsp;&nbsp;输出要被替换的单词，如上图所示，先 mask small bert&nbsp;&nbsp;的某个位置，然后用预测的 token&nbsp;&nbsp;作为原来句子中要替换的单词&nbsp;&nbsp;</div><div><br/></div><div>ELECTRA 效果很惊喜</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/FB15B6A3-52EE-4286-B721-EAE330D3C9B1.png" height="50%" width="80%"/></div><div>上图横轴是计算量，纵轴是 GLUE&nbsp;&nbsp;评分，可以看出 ，ELECTRA&nbsp;&nbsp;在同等的计算量下效果比其他模型好，甚至只要 1/4&nbsp;&nbsp;的计算量就接近了 XLNet&nbsp;&nbsp;的效果 （右图）</div><div><br/></div><div>8.可不可以用&nbsp;&nbsp; self-attention&nbsp;&nbsp;的方法去&nbsp;&nbsp;生成一个 sentence&nbsp;&nbsp;的 embedding&nbsp;&nbsp;</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/BA50C438-99C1-4496-B2E7-1753C1602A23.png" height="50%" width="80%"/></div><div>和 word&nbsp;&nbsp;的 embedding&nbsp;&nbsp;思路相同，通过某个句子的上下文信息，我们可以知道这个句子的意思</div><div><br/></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/BB0B96DB-4D2C-4DB5-908D-D96F54FDC383.png" height="50%" width="80%"/></div><ul><li><div>skip thought：将当前句子输入 encoder ，得到编码向量，然后将编码向量输入 decoder 生成&nbsp;&nbsp;下一个句子，这种 generation&nbsp;&nbsp;的任务计算量大，不好训练</div></li><li><div>quick thought：将两个句子分别输入 encoder 生成两个&nbsp;&nbsp;编码向量&nbsp;&nbsp;并计算两个向量的相似度，若它们是相邻句子，则最小化两个向量的距离（思路&nbsp;&nbsp;类似 DSSM）</div></li></ul><div><br/></div><div>在最早的 Bert&nbsp;&nbsp;中提出了一种&nbsp;&nbsp;通过 判断两个句子是不是首尾连接 来得到 sentence embedding&nbsp;&nbsp;的方法（NSP），但是效果不好</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/72C3ADE0-2D0B-4E7C-A461-61192F92F04E.png" height="50%" width="80%"/></div><div>NSP&nbsp;&nbsp;的任务&nbsp;&nbsp;对模型来说太简单了，因为你找两个完全无关的句子，模型很容易就能看出来</div><div><br/></div><div>因此，在 RoBerta ， ALBERT，&nbsp;&nbsp;和 structBert&nbsp;&nbsp;中提出了&nbsp;&nbsp;让模型判断两个句子是否前后相接（如果我把两个句子前后倒置，模型要判断为&nbsp;&nbsp;No），</div><div>显然这是一个比较难的任务</div><div><br/></div><div>9.上面介绍了这么多的 pre-train&nbsp;&nbsp;的方法，那到底哪个效果好呢</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/F7495429-AE44-4A60-A57D-8A1E7B36231D.png" height="50%" width="80%"/></div><div>在 T5&nbsp;&nbsp;的论文中，google&nbsp;&nbsp;展示了&nbsp;&nbsp;强悍的算力，因为他们把所有的&nbsp;&nbsp;pre-train&nbsp;&nbsp;方法都试了一遍 ==</div><div><br/></div><div><br/></div><div>10.pre-train model 架构如下图，中间的 layer&nbsp;&nbsp;的选择可以是 LSTM ， self-attention，和&nbsp;&nbsp; tree-based model&nbsp;&nbsp;</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/9725F56F-2DE8-4980-96F1-1F2A8903A227.png" height="50%" width="80%"/></div><div>选择&nbsp;&nbsp;tree-based（语法树） 是因为它可以表征&nbsp;&nbsp;文法信息，但是现在大家用的很少，</div><div>因为 LSTM&nbsp;&nbsp;和&nbsp;&nbsp;self-attention&nbsp;&nbsp;在&nbsp;&nbsp;训练过程中也学到了文法的信息&nbsp;&nbsp;</div><div><br/></div><div><span style="font-size: unset; color: unset; font-family: unset;">11.一方面&nbsp;&nbsp;大公司&nbsp;&nbsp;在把模型变得越来越大，但是也有&nbsp;&nbsp;一些&nbsp;&nbsp;炼丹乞丐在致力于把模型变得更小</span></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/32C32DBB-C2DA-4570-B7E0-887CC0EC20C1.png" height="50%" width="80%"/></div><div>最有意思的是 albert ，它让 bert&nbsp;&nbsp;所有层&nbsp;&nbsp;都共享一套参数，大大降低了要学习的参数数量，并且效果还更好了</div><div><br/></div><div>12.神经网络的压缩方法</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/EEBF477C-4F24-4694-B095-03D7BF49635F.png" height="50%" width="80%"/></div><div><br/></div><div>13.神经网络架构 的新进展</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/7442C3E1-E10F-4CBF-AB7C-3653BD5F4192.png" height="50%" width="80%"/></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">transformer-XL</span>&nbsp;&nbsp;是为了&nbsp;&nbsp;让&nbsp;&nbsp;模型一次吃进去更长的序列（transformer&nbsp;&nbsp;在训练的时候 seq length&nbsp;&nbsp;为定长512），</div><div>从原来的一句话变成一段话，乃至一整篇文章</div><div><br/></div><div>re<span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">former&nbsp;&nbsp;和 long</span><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">former&nbsp;&nbsp;是为了降低 self-attention&nbsp;&nbsp;的时间复杂度，</span></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">因为 self-attention&nbsp;&nbsp; 的时间复杂度为 O(n^2)&nbsp;&nbsp;其中 n&nbsp;&nbsp;为序列的长度，我们如果&nbsp;&nbsp;把 n&nbsp;&nbsp;变得很大，训练效率太低了</span></div><div><br/></div><div><br/></div><hr/><div><br/></div><div><span style="font-weight: bold;">Part2. how to fine-tune</span></div><div><br/></div><div>1.在 pre-train model&nbsp;&nbsp;的基础上加上一个&nbsp;&nbsp;特定的任务的网络层</div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/FAFA2005-6AE1-40BD-ACD2-CE420CBAF750.png" height="50%" width="80%"/></div><div><span style="font-size: unset;"><br/></span></div><div><span style="font-size: unset; color: unset; font-family: unset;">2.NLP&nbsp;&nbsp;的任务可以&nbsp;&nbsp;按照 输入输出 进行分类</span></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/B52E8FDD-5DD7-49D0-B02F-7E5D81CD5940.png" height="50%" width="80%"/></div><ul><li><div>对于输入有多个句子的情况，我们要在&nbsp;&nbsp;两个句子&nbsp;&nbsp;中间用标记字符（SEP）标识</div></li></ul><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/0F9BE78D-4B03-46F3-974E-E2C6846DC00F.png" height="50%" width="80%"/></div><div><br/></div><ul><li><div>输出是 one class&nbsp;&nbsp;时，可以有两种做法</div></li></ul><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/BF80DC83-A76C-48A4-BD36-D1029858DD61.png" height="50%" width="80%"/></div><div>（1）在fine-tune 时&nbsp;&nbsp;在输入标记&nbsp;&nbsp;一个特殊的&nbsp;&nbsp;标记位（CLS），把这个&nbsp;&nbsp;时间步输出的 embedding&nbsp;&nbsp;给&nbsp;&nbsp;分类模型（task specific model）</div><div><span style="font-size: unset; color: unset; font-family: unset;">（2）把所有时间步输出的 embedding&nbsp;&nbsp;给 分类模型</span></div><div><br/></div><ul><li><div>对每一个 token&nbsp;&nbsp;输出一个分类</div></li></ul><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/8944845B-E592-4B3F-92F2-305193C78131.png" height="50%" width="80%"/></div><div><br/></div><ul><li><div>输出是输入的&nbsp;&nbsp;一部分</div></li></ul><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/6B0B0EE3-6F17-4A0B-A622-FFCF32318774.png" height="50%" width="80%"/></div><div><br/></div><ul><li><div>输出是&nbsp;&nbsp;一整个 sequence</div></li></ul><div><br/></div><div><span style="font-weight: bold;">方法v1&nbsp;&nbsp;</span></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/90D95898-AFC2-4142-9574-CC1252F036CA.png" height="50%" width="80%"/></div><div>把 pre-train model&nbsp;&nbsp;作为 encoder，然后&nbsp;&nbsp;加上一个&nbsp;&nbsp;由 LSTM + attention&nbsp;&nbsp;组成的 decoder ，这种方法的问题在于</div><div>decoder&nbsp;&nbsp;没有使用&nbsp;&nbsp;pre-train&nbsp;&nbsp;的参数，</div><div><br/></div><div><span style="font-weight: bold;">方法v2</span></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/EB1C1147-A990-4942-A394-BE51C436BC79.png" height="50%" width="80%"/></div><div>左半部分&nbsp;&nbsp;作为 encoder&nbsp;&nbsp;接收输入 input sequence ，&nbsp;&nbsp;在特殊标记位之后，右半部分作为 decoder ，</div><div>pre-train model 所有时间步的输出都接入分类模型</div><div><br/></div><div><span style="font-weight: bold;">方法v3</span></div><div><span style="font-size: unset; color: unset; font-family: unset;">pre-train&nbsp;&nbsp;一体化的 seq2seq，包括 encoder&nbsp;&nbsp;和 decoder</span></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/96FAE2CE-82F9-4A34-8C6B-7FB2F8B97949.png" height="50%" width="80%"/></div><div><br/></div><div><br/></div><div>3.可以选择 fine-tune&nbsp;&nbsp;整个 model（包括 pre-train&nbsp;&nbsp;和 task specific&nbsp;&nbsp;部分） 还是&nbsp;&nbsp;只是 fine-tune task specific model ，前者一般比后者效果好，</div><div>如果&nbsp;&nbsp;不使用&nbsp;&nbsp;pre-train model&nbsp;&nbsp;直接 train&nbsp;&nbsp;一个这么大的模型肯定会出现 overfitting</div><div><br/></div><div>4.除了 用&nbsp;&nbsp;pre-train mode 的最后一层的输出&nbsp;&nbsp;作为&nbsp;&nbsp;&nbsp;&nbsp;task specific model&nbsp;&nbsp;的输入外，还可以用中间层的输出进行融合</div><div><br/></div><div><img src="/Resources/5.self-supervised%EF%BC%88Bert%20%E5%92%8C%E5%AE%83%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC%EF%BC%89.resources/63A838D1-2A0E-4F9F-9EEA-B7785B70213E.png" height="50%" width="80%"/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://www.bilibili.com/video/BV1az4y1f7Au?p=2&amp;vd_source=b3c5acfc1adec64d81835fde68fe58d1">李宏毅《自然语言处理》</a></div><div><br/></div></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="Bert的前世今生" scheme="https://xinrihui.github.io/categories/Bert%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"/>
    
    
    <category term="transformer" scheme="https://xinrihui.github.io/tags/transformer/"/>
    
    <category term="nlp" scheme="https://xinrihui.github.io/tags/nlp/"/>
    
    <category term="深度学习" scheme="https://xinrihui.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="自监督学习" scheme="https://xinrihui.github.io/tags/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="bert" scheme="https://xinrihui.github.io/tags/bert/"/>
    
  </entry>
  
  <entry>
    <title>Transformer 论文和源码分析</title>
    <link href="https://xinrihui.github.io/2022/12/28/Transformer%20%E8%AE%BA%E6%96%87%E5%92%8C%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    <id>https://xinrihui.github.io/2022/12/28/Transformer%20%E8%AE%BA%E6%96%87%E5%92%8C%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</id>
    <published>2022-12-28T06:47:10.000Z</published>
    <updated>2022-12-28T06:47:10.838Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2021-12-03 08:58:45 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="https://notebooks.githubusercontent.com/view/ipynb?azure_maps_enabled=true&amp;browser=chrome&amp;color_mode=auto&amp;commit=53a1be68727b5d5c3a0d0bf18721013843a49041&amp;device=unknown_device&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f74656e736f72666c6f772f74656e736f723274656e736f722f353361316265363837323762356435633361306430626631383732313031333834336134393034312f74656e736f723274656e736f722f6e6f7465626f6f6b732f5472616e73666f726d65725f7472616e736c6174652e6970796e62&amp;logged_in=false&amp;nwo=tensorflow%2Ftensor2tensor&amp;path=tensor2tensor%2Fnotebooks%2FTransformer_translate.ipynb&amp;platform=windows&amp;repository_id=94460704&amp;repository_type=Repository&amp;version=104#14a7c3ce-1400-4b7e-b191-3383004e9937"/><meta name="updated" content="2022-12-28 06:45:47 +0000"/><title>Transformer 论文和源码分析</title></head><body><div><div><div><span style="font-weight: bold;">Part1. 论文</span></div><div><br/></div><div>1.Transformer 完全依赖于注意力机制来 表达 输入和输出之间的 全局依赖关系，而没有采用 循环结构 </div><div><br/></div><div>2.Transformer  采用了 编码器-解码器 结构，</div><div>  （1）编码器将符号表示形式（x1; :::; xn）的输入序列映射到 连续表示形式 z =（z1; :::; zn）的序列。</div><div>  （2）上一步拿到z后，解码器一次生成一个符号的符号的输出序列（y1; :::; ym）。 模型的每一步都是自回归的，在生成下一步的输出时，会将 上一步 生成的符号用作附加输入。</div><div><br/></div><div>3.Multi-Head Attention</div><div><img src="/Resources/Transformer%20%E8%AE%BA%E6%96%87%E5%92%8C%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.resources/A3B67D7C-4ED8-4DA2-9072-B6D05E5E71CB.png" height="546" width="447"/><br/></div><div>multi-head attention 是由 h 个 scaled dot-product attention 组成的</div><div><br/></div><div><br/></div><div><span style="font-size: unset; color: unset; font-family: unset;">与 d_model个 维度 一起输入 注意力函数 （ single-head attention ）相比，我们发现 把 总维度 线性投影 h次 有更好的效果。对每一个子空间，我们可以并行的 计算他们的注意力函数，最后得到 dv 维度的 输出value。我们最后会把这些 子空间 连接起来 ，并再次做 线性投影</span></div><div><img src="/Resources/Transformer%20%E8%AE%BA%E6%96%87%E5%92%8C%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.resources/4AED5A46-8353-4947-8012-14D393A41632.png" height="266" width="1212"/><br/></div><div>其中 Attention 函数：</div><div><img src="/Resources/Transformer%20%E8%AE%BA%E6%96%87%E5%92%8C%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.resources/69411E8B-17AE-4BB0-85B6-C4AE8F7EAEA2.png" height="135" width="1126"/><br/></div><div>总的计算代价，Multi-Head Attention 和 使用全维度的  single-head attention  是一样的</div><div><br/></div><div><br/></div><div>4.我们从三个方面来对比  循环层 、卷积层 和 self-attention层 的处理序列编码-解码的效率：</div><div><br/></div><div>（1）每一层的计算复杂度</div><div><br/></div><div>（2）可以并行化的计算量，以 所需的最少顺序操作数衡量。 对于某个序列 ，self-attention可以直接计算  的点乘结果，而rnn就必须按照顺序从  计算到</div><div><br/></div><div>（3）<span style="font-weight: bold;">网络中远程依赖关系之间的路径长度</span></div><div><br/></div><div>影响学习这种远程依赖关系的一个关键因素是网络中前向和后向信号必须经过的路径长度。</div><div>输入和输出序列中位置的任意组合之间的路径越短，学习远程依赖关系就越容易。</div><div>因此，我们 比较了由不同层类型组成的网络中任意两个输入和输出位置之间的最大路径长度。</div><div><br/></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(26, 26, 26); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-variant-caps: normal; font-variant-ligatures: normal;">这里Path length指的是要计算一个序列长度为n的信息要经过的路径长度。cnn需要增加卷积层数来扩大视野，rnn需要从1到n逐个进行计算，而self-attention只需要一步矩阵计算就可以。所以也可以看出，self-attention可以比rnn更好地解决长时依赖问题。当然如果计算量太大，比如序列长度n&gt;序列维度d这种情况，也可以用窗口限制self-attention的计算数量</span></div><div><br/></div><ul><li><div><span style="font-weight: bold;">RNN &amp; self-attention</span></div></li></ul><div>self-attention 层使用常数的操作单元（无论句子的长度, t=512）连接所有位置，而 recurrent层则需要 O（n）个 操作单元（取决于 输入序列的长度n） 。</div><div>在计算复杂度方面，当 序列长度n小于表示 维数d时（一般都是 n&lt;d），self-attention层比 recurrent层要快，</div><div>为了提高  长序列任务的计算性能，可以将self-attention 限制为仅考虑输入序列中以各个输出位置为中心的大小为r的邻域，这会将最大路径长度增加到O（n / r）。</div><div><img src="/Resources/Transformer%20%E8%AE%BA%E6%96%87%E5%92%8C%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.resources/FAF14F0E-E7B9-4F81-83DC-41C156DE4066.png" height="249" width="1172"/><br/></div><div><br/></div><div>n- 序列的长度  </div><div>d- 中间层的维度</div><div>k- CNN 中卷积核(1D 卷积) 的维度</div><div><br/></div><ul><li><div><span style="font-weight: bold;">CNN &amp;self-attention</span></div></li></ul><div>内核宽度k &lt;n的单个卷积层 无法连接所有成对的输入和输出位置。</div><div>因此，需要 在连续内核的情况下 堆叠 O（n / k）个卷积层，而在膨胀卷积的情况下则需要O（logk（n）），从而增加了任意两个位置之间最长路径的长度 。</div><div>卷积层通常的计算复杂度比循环层 高出k倍。  但是，可分离卷积将复杂度大大降低到O（k·n·d + n·d2）。</div><div>但是，即使k = n，可分离卷积的复杂度也等于self-attention层和 逐点前馈层的组合，而后者是我们所用的结构。</div><div><br/></div><div>5.作为附带的好处，自我关注可以产生更多可解释的模型。各个 attention heads 不仅学会执行不同的任务，而且许多attention heads似乎表现出与句子的句法和语义结构有关的行为。</div><div>即 self-attention模型更可解释，attention结果的分布表明了该模型学习到了一些语法和语义信息</div><div><br/></div><div><span style="font-weight: bold;">6.意义</span></div><div><br/></div><div>transformer 几乎可以用在所有的 NLP 的任务上，后续的工作，像 Bert, GPT 这种很大的预训练模型可以大幅提升所有 NLP 任务的性能，这有点像 CNN 对于计算机视觉的改变：一方面 可以用大量的数据训练一个很大的CNN模型，让其他任务也能从中受益，另一方面为研究者提供了统一的框架， 研究者可以告别之前繁琐的特征提取和建模的工作。原来做NLP 要做文本的预处理，并且根据任务设计模型的架构，我们现在只需要 使用 transformer  就能在所有的任务上取得好的成绩。</div><div><br/></div><div>transformer 不仅仅在NLP 中，在CV 中也取得了很大的进展，同样一个模型在机器学习的所有的领域都能用，一个领域的研究者取得的突破很快可以启发到其他的研究者，另外，人对于自然世界的感知是多模态的，transformer  能把不同的数据融合起来，即把多模态的数据映射到同一个语义空间，使得我们可以做出更大更好的模型。</div><div><br/></div><div><span style="font-size: unset; color: unset; font-family: unset;">Attention 在 模型中的作用是把序列的信息聚合起来，模型中的 MLP 层和 残差连接是不可缺少的。</span><span style="font-size: unset; color: unset; font-family: unset;">Attention 虽然不会对 顺序建模，但是它其实做了一个更广泛的偏纳规制，这么做的代价是 由于假设变得更加一般，模型抓取信息的能力变差了，因此要使用更大的模型和更多的数据才会有好的效果。</span></div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><br/></div><div><span style="font-size: unset; color: unset; font-family: unset;">《Attention Is All You Need》</span></div><div><a href="https://www.jianshu.com/p/b1030350aadb">https://www.jianshu.com/p/b1030350aadb</a></div><div><a href="https://zhuanlan.zhihu.com/p/44121378">https://zhuanlan.zhihu.com/p/44121378</a></div></div><div><br/></div><hr/><div><br/></div><div><span style="font-weight: bold;">Part2.</span> <span style="font-weight: bold;">源码分析</span><span style="font-weight: bold;">（tensor2tensor）</span></div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">1.初始化超参数</span></div><div><br/></div><div>PROBLEM = "translate_enfr_wmt32k" # 英语到法语的机器翻译任务  词表大小为32K </div><div>MODEL = "transformer” </div><div><br/></div><div><span style="font-size: unset;"><span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">HPARAMS</span></span> <span style="font-size: unset; color: unset; font-family: unset;">= "</span><span style="font-size: unset;"><span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">transformer_big</span></span>”<font face="unset"><span style="color: unset; font-size: unset;"> </span></font></div><div><span style="font-size: unset; color: unset; font-family: unset;"># 模型名字，对应论文中的 大</span><span style="font-size: unset; color: unset; font-family: unset;">transformer， 若只有1个GPU 使用 </span><span style="color: rgb(255, 0, 0);">transformer_big_single_gpu</span></div><div># 还可以选择 <span style="color: rgb(255, 0, 0);">transformer_base</span>  对应<span style="font-size: unset; color: unset; font-family: unset;">论文中 标准的 </span><span style="font-size: unset; color: unset; font-family: unset;">transformer</span></div><div>       </div><div>train_steps : 论文提到了在 大的 transformer上使用 8 gpu 时，迭代次数为 300k。因此，如果你有1个gpu，你需要将 迭代次数 x8 或者更多。</div><div>若为 基础的 transformer， train_steps 设置为 100K，100K x 8=800K</div><div><br/></div><div>train_steps <span style="font-weight: bold;">=</span> 300000 # Total number of train steps for all Epochs</div><div>eval_steps <span style="font-weight: bold;">=</span> 100 # Number of steps to perform for each evaluation</div><div>batch_size <span style="font-weight: bold;">=</span> 4096 # 使用动态 batch，表示一个批次的 token 的总数</div><div>save_checkpoints_steps <span style="font-weight: bold;">=</span> 1000</div><div>ALPHA <span style="font-weight: bold;">=</span> 0.1</div><div>schedule <span style="font-weight: bold;">=</span> "continuous_train_and_eval"</div><div><br/></div><div><span style="color: rgb(255, 0, 0);"># 建立模型超参数对象 ，位于 tensor2tensor\utils\hparams_lib.py</span></div><div>hparams = create_hparams(<span style="color: rgb(255, 0, 0);">HPARAMS</span>) </div><div><br/></div><div><span style="color: rgb(255, 0, 0);"># 配置 hparams </span></div><div>hparams.batch_size = batch_size</div><div>hparams.learning_rate<span style="font-size: unset; color: unset; font-family: unset;">= ALPHA</span></div><div><br/></div><div>#hparams.max_length = 256</div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">2.模型对象</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);"># 位于  tensor2tensor\utils\trainer_lib.py</span></div><div>tensorflow_exp_fn = <span style="color: rgb(255, 0, 0);">create_experiment</span>(</div><div>        run_config=RUN_CONFIG,</div><div>        hparams=hparams,</div><div>        model_name=MODEL,</div><div>        problem_name=PROBLEM,</div><div>        data_dir=DATA_DIR,</div><div>        train_steps=train_steps,</div><div>        eval_steps=eval_steps,</div><div>        #use_xla=True # For acceleration</div><div>    )</div><div><br/></div><div>tensorflow_exp_fn.<span style="color: rgb(255, 0, 0);">train_and_evaluate</span>()</div><div><br/></div><div><span style="font-weight: bold;">2.1 动态 batch </span></div><div><br/></div><div><br/></div><hr/><div><font style="color: rgb(255, 38, 0);">#位于</font><span style="color: rgb(255, 0, 0);"> tensor2tensor\utils\trainer_lib.py</span><br/></div><div><br/></div><div>def <span style="color: rgb(255, 0, 0);">create_experiment</span>(</div><div>    run_config,</div><div>    hparams,</div><div>    model_name,</div><div>    problem_name,</div><div>    data_dir,</div><div>    train_steps,</div><div>    eval_steps,</div><div>    .....</div><div><span style="font-size: unset; color: unset; font-family: unset;">):</span></div><div>  </div><div style="margin-left: 40px;"># Input fns from Problem</div><div style="margin-left: 40px;">problem = hparams.problem</div><div style="margin-left: 40px;">train_input_fn = problem.<span style="color: rgb(255, 0, 0);">make_estimator_input_fn</span>(tf_estimator.ModeKeys.TRAIN,</div><div style="margin-left: 40px;">                                                 hparams)</div><div style="margin-left: 40px;"><span style="font-size: unset;"><br/></span></div><div style="margin-left: 40px;"><span style="font-size: unset; color: unset; font-family: unset;">return</span> <span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">T2TExperiment</span><span style="font-size: unset; color: unset; font-family: unset;">(estimator, hparams, train_spec, eval_spec,</span></div><div style="margin-left: 40px;">                     use_validation_monitor, decode_hparams)</div><div><br/></div><div><br/></div><div>class <span style="color: rgb(255, 0, 0);">T2TExperiment</span>(object):</div><div>  """Custom Experiment class for running distributed experiments."""</div><div><br/></div><div style="margin-left: 40px;">def <span style="color: rgb(255, 0, 0);">train_and_evaluate</span>(self):</div><div style="margin-left: 40px;">  if self._use_validation_monitor:</div><div style="margin-left: 40px;">    tf.logging.warning("EvalSpec not provided. Estimator will not manage "</div><div style="margin-left: 40px;">                       "model evaluation. Assuming ValidationMonitor present "</div><div style="margin-left: 40px;">                       "in train_hooks.")</div><div style="margin-left: 40px;">    self.<span style="color: rgb(255, 0, 0);">train</span>()</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">def <span style="color: rgb(255, 0, 0);">train</span>(self, max_steps=None):</div><div style="margin-left: 40px;">  mlperf_log.transformer_print(key=mlperf_log.TRAIN_LOOP)</div><div style="margin-left: 40px;">  mlperf_log.transformer_print(key=mlperf_log.TRAIN_EPOCH, value=0)</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  self._estimator.train(</div><div style="margin-left: 40px;">      self._train_spec.<span style="color: rgb(255, 0, 0);">input_fn</span>,</div><div style="margin-left: 40px;">      hooks=self._train_spec.hooks,</div><div style="margin-left: 40px;">      max_steps=max_steps or self._train_spec.max_steps)</div><div><br/></div><div><br/></div><hr/><div><span style="color: rgb(255, 38, 0);">#位于 </span><span style="font-size: unset;"><span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">tensor2tensor\data_generators\problem.py</span></span><br/></div><div><br/></div><div>def <span style="color: rgb(255, 0, 0);">make_estimator_input_fn</span>(self,</div><div>                            mode,</div><div>                            hparams,</div><div>                            data_dir=None,</div><div>                            force_repeat=False,</div><div>                            prevent_repeat=False,</div><div>                            dataset_kwargs=None):</div><div>  """Return input_fn wrapped for Estimator."""</div><div><br/></div><div style="margin-left: 40px;">  def estimator_input_fn(params, config):</div><div style="margin-left: 40px;">    return self.<span style="color: rgb(255, 0, 0);">input_fn</span>(</div><div style="margin-left: 40px;">        mode,</div><div style="margin-left: 40px;">        hparams,</div><div style="margin-left: 40px;">        data_dir=data_dir,</div><div style="margin-left: 40px;">        params=params,</div><div style="margin-left: 40px;">        config=config,</div><div style="margin-left: 40px;">        force_repeat=force_repeat,</div><div style="margin-left: 40px;">        prevent_repeat=prevent_repeat,</div><div style="margin-left: 40px;">        dataset_kwargs=dataset_kwargs)</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  return estimator_input_fn</div><div><br/></div><div><br/></div><hr/><div><span style="color: rgb(255, 38, 0);">#位于 </span><span style="color: rgb(255, 0, 0);">tensor2tensor\utils\data_reader.py</span><br/></div><div><span style="color: rgb(255, 0, 0);"><br/></span></div><div>def <span style="color: rgb(255, 0, 0);">input_fn</span>(dataset,</div><div>             filepattern,</div><div>             skip_random_fraction_when_training,</div><div>            </div><div><span>    <span>    <span>    </span></span></span> <span style="color: rgb(255, 0, 0);">batch_size_means_tokens_param</span>,  </div><div><span style="color: rgb(255, 0, 0);"><span>    <span>    <span>    </span></span></span># batch size 是否代表 一个批次中 token 的总个数</span></div><div>            </div><div><span>    <span>    <span>    </span></span></span> batch_size_multiplier,</div><div>             max_length,</div><div>             mode,</div><div>             hparams,</div><div>             data_dir=None,</div><div>             params=None,</div><div>             config=None,</div><div>             force_repeat=False,</div><div>             prevent_repeat=False):</div><div><br/></div><div><br/></div><div style="margin-left: 40px;"># Batching</div><div style="margin-left: 40px;">if not <span style="color: rgb(255, 0, 0);">batch_size_means_tokens</span>:</div><div style="margin-left: 40px;">  # Batch size means examples per datashard.</div><div style="margin-left: 40px;">    .....</div><div style="margin-left: 40px;"/><div style="margin-left: 40px;">else:</div><div style="margin-left: 40px;">  # batch_size means tokens per datashard</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 80px;"><span style="color: rgb(255, 0, 0);">cur_batching_scheme</span> = <span style="color: rgb(255, 0, 0);">hparams_to_batching_scheme</span>(</div><div style="margin-left: 80px;">    hparams,</div><div style="margin-left: 80px;">    shard_multiplier=num_shards,</div><div style="margin-left: 80px;">    length_multiplier=batch_size_multiplier)</div><div style="margin-left: 80px;"><br/></div><div style="margin-left: 80px;">dataset = dataset.apply(</div><div style="margin-left: 80px;">    <span style="color: rgb(255, 0, 0);">tf.data.experimental.</span><span style="color: rgb(255, 0, 0);">bucket_by_sequence_length</span>(</div><div style="margin-left: 80px;">        example_length, </div><div style="margin-left: 80px;">        <span style="overflow-x: auto; position: relative; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; border: var(--devsite-inline-nested-code-border,0); border-radius: var(--devsite-inline-code-border-radius,0); word-break: normal; direction: ltr !important; color: var(--devsite-code-color); font-variant-caps: normal; font-variant-ligatures: normal; background-position: 0px center;">bucket_boundaries</span><span style="overflow-x: auto; position: relative; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; border: var(--devsite-inline-nested-code-border,0); border-radius: var(--devsite-inline-code-border-radius,0); word-break: normal; direction: ltr !important; color: var(--devsite-code-color); font-variant-caps: normal; font-variant-ligatures: normal; background-position: 0px center;">=</span><span style="color: rgb(255, 0, 0);">cur_batching_scheme</span>["boundaries"],</div><div style="margin-left: 80px;">        <span style="overflow-x: auto; position: relative; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 14px; border: var(--devsite-inline-nested-code-border,0); border-radius: var(--devsite-inline-code-border-radius,0); word-break: normal; direction: ltr !important; color: var(--devsite-code-color); font-variant-caps: normal; font-variant-ligatures: normal; background-position: 0px center;">bucket_batch_sizes=</span><span style="color: rgb(255, 0, 0);">cur_batching_scheme</span>["batch_sizes"])</div><div style="margin-left: 80px;">)</div><div style="margin-left: 80px;"><span style="color: rgb(255, 0, 0);"># 通过固定 一个批次中 token 的总个数 来动态调整 batch  </span></div><div style="margin-left: 80px;"><span style="color: rgb(255, 0, 0);">#</span><span style="color: rgb(255, 0, 0);"> </span><a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#bucket_by_sequence_length" style="color: rgb(255, 0, 0);">https://www.tensorflow.org/api_docs/python/tf/data/Dataset#bucket_by_sequence_length</a></div><div style="margin-left: 40px;"><br/></div><div><br/></div><div>def <span style="color: rgb(255, 0, 0);">hparams_to_batching_scheme</span>(hparams,</div><div>                               drop_long_sequences=False,</div><div>                               shard_multiplier=1,</div><div>                               length_multiplier=1):</div><div>  """Wrapper around _batching_scheme with hparams."""</div><div>  </div><div style="margin-left: 40px;">return <span style="color: rgb(255, 0, 0);">batching_scheme</span>(</div><div style="margin-left: 40px;">     <span style="color: rgb(255, 0, 0);"> batch_size=hparams.batch_size, # hparams 中配置的 </span><span style="color: rgb(255, 0, 0);">batch_size</span></div><div style="margin-left: 40px;">      min_length=hparams.min_length,</div><div style="margin-left: 40px;">      max_length=hparams.max_length,</div><div style="margin-left: 40px;">      min_length_bucket=hparams.min_length_bucket,</div><div style="margin-left: 40px;">      length_bucket_step=hparams.length_bucket_step,</div><div style="margin-left: 40px;">      drop_long_sequences=drop_long_sequences,</div><div style="margin-left: 40px;"><span style="font-size: unset; color: unset; font-family: unset;">    )</span></div><div><br/></div><div><br/></div><div>def <span style="color: rgb(255, 0, 0);">batching_scheme</span>(batch_size,</div><div>                    max_length,</div><div>                    min_length_bucket,</div><div>                    length_bucket_step,</div><div>                    drop_long_sequences=False,</div><div>                    shard_multiplier=1,</div><div>                    length_multiplier=1,</div><div>                    min_length=0):</div><div>  """A batching scheme based on model hyperparameters.</div><div><br/></div><div>  Args:</div><div><span style="color: rgb(255, 0, 0);">    batch_size: int, total number of tokens in a batch.</span></div><div><br/></div><div>Returns:</div><div>   A dictionary with parameters that can be passed to input_pipeline:</div><div>     * boundaries: list of bucket boundaries <span style="color: rgb(255, 0, 0);"># 不同的 batch 的长度的边界</span></div><div>     * batch_sizes: list of batch sizes for each length bucket <span style="color: rgb(255, 0, 0);"># 每个 batch 的样本的个数</span></div><div><br/></div><div>  """</div><div><br/></div><div><span style="font-weight: bold;">2.2 通过模型名字 注册模型</span></div><div><br/></div><div><br/></div><hr/><div><span style="color: #ff2600;">#位于 </span><span style="color: rgb(255, 0, 0);">tensor2tensor\utils\trainer_lib.py</span></div><div>def <span style="color: rgb(255, 0, 0);">create_experiment</span>(</div><div>    run_config,</div><div>    hparams,</div><div>    model_name,</div><div>    problem_name,</div><div>    data_dir,</div><div>    train_steps,</div><div>    eval_steps,</div><div>    .....</div><div><span style="font-size: unset; color: unset; font-family: unset;">):</span></div><div><br/></div><div style="margin-left: 40px;">estimator = <span style="color: rgb(255, 0, 0);">create_estimator</span>(</div><div style="margin-left: 40px;">    model_name,</div><div style="margin-left: 40px;">    hparams,</div><div style="margin-left: 40px;">    run_config,</div><div style="margin-left: 40px;">    schedule=schedule,</div><div style="margin-left: 40px;">    decode_hparams=decode_hparams,</div><div style="margin-left: 40px;">    use_tpu=use_tpu,</div><div style="margin-left: 40px;">    use_tpu_estimator=use_tpu_estimator,</div><div style="margin-left: 40px;">    use_xla=use_xla,</div><div style="margin-left: 40px;">    export_saved_model_api_version=export_saved_model_api_version,</div><div style="margin-left: 40px;">    use_guarantee_const_getter=use_guarantee_const_getter)</div><div><br/></div><div>def <span style="color: rgb(255, 0, 0);">create_estimator</span>(model_name,</div><div>                     hparams,</div><div>                     run_config,</div><div>                     schedule="train_and_evaluate",</div><div><span style="font-size: unset; color: unset; font-family: unset;">):</span></div><div><br/></div><div>  """Create a T2T Estimator."""</div><div style="margin-left: 40px;">  model_fn = t2t_model.T2TModel.<span style="color: rgb(255, 0, 0);">make_estimator_model_fn</span>(<span style="font-size: unset; color: unset; font-family: unset;">model_name, hparams,                                                 decode_hparams=decode_hparams, use_tpu=use_tpu)</span></div><div><br/></div><div><br/></div><hr/><div><br/></div><div><span style="color: #ff2600;">#位于 </span><span style="color: rgb(255, 0, 0);">tensor2tensor\utils\t2t_model.py</span></div><div><br/></div><div>def <span style="color: rgb(255, 0, 0);">make_estimator_model_fn</span>(model_name,</div><div>                            hparams,</div><div>                            decode_hparams=None,</div><div>                            use_tpu=False):</div><div><br/></div><div>  model_cls = registry.model(<span style="color: rgb(255, 0, 0);">model_name</span>) <span style="color: rgb(255, 0, 0);"># 使用模型的名字注册模型</span></div><div><br/></div><div><br/></div><div>其中模型的名字定义在 <span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">tensor2tensor\tensor2tensor\models\transformer.py</span></div><div><br/></div><div><br/></div><hr/><div><span style="color: #ff2600;">#位于 </span><span style="color: rgb(255, 0, 0);">t</span><span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">ensor2tensor\tensor2tensor\models\transformer.py</span></div><div><br/></div><div>@registry.register_hparams</div><div>def <span style="color: rgb(255, 0, 0);">transformer_base_single_gpu</span>():  <span style="color: rgb(255, 0, 0);"># 模型的名字</span></div><div><br/></div><div>  """HParams for transformer base model for single GPU."""</div><div style="margin-left: 40px;">  hparams = <span style="color: rgb(255, 0, 0);">transformer_base</span>()</div><div style="margin-left: 40px;">  hparams.batch_size = 1024</div><div style="margin-left: 40px;">  hparams<span style="color: rgb(255, 0, 0);">.learning_rate_schedule</span> = " <span style="color: rgb(255, 0, 0);">constant </span>* <span style="color: rgb(255, 0, 0);">linear_warmup </span>* <span style="color: rgb(255, 0, 0);">rsqrt_decay </span>" <span style="color: rgb(255, 0, 0);"># 不同学习率策略进行组合</span></div><div style="margin-left: 40px;">  hparams.<span style="color: rgb(255, 0, 0);">learning_rate_constant</span> = 0.1</div><div style="margin-left: 40px;">  hparams.<span style="color: rgb(255, 0, 0);">learning_rate_warmup_steps</span> = 16000</div><div style="margin-left: 40px;">  return hparams</div><div><br/></div><div>@registry.register_hparams</div><div>def <span style="color: rgb(255, 0, 0);">transformer_big_single_gpu</span>():</div><div>  """HParams for transformer big model for single GPU."""</div><div style="margin-left: 40px;">  hparams = <span style="color: rgb(255, 0, 0);">transformer_big</span>()</div><div style="margin-left: 40px;">  hparams.layer_prepostprocess_dropout = 0.1</div><div style="margin-left: 40px;">  hparams.learning_rate_warmup_steps = 16000</div><div style="margin-left: 40px;">  return hparams</div><div><br/></div><div><br/></div><div>@registry.register_hparams</div><div>def <span style="color: rgb(255, 0, 0);">transformer_base_v1</span>():</div><div>  """Set of hyperparameters."""</div><div style="margin-left: 40px;">  hparams = common_hparams.basic_params1()</div><div style="margin-left: 40px;">  hparams.norm_type = "layer"</div><div style="margin-left: 40px;">  hparams.hidden_size = 512</div><div style="margin-left: 40px;">  hparams.batch_size = 4096</div><div style="margin-left: 40px;">  hparams.max_length = 256</div><div style="margin-left: 40px;">  hparams.clip_grad_norm = 0.  # i.e. no gradient clipping</div><div style="margin-left: 40px;">  hparams.optimizer_adam_epsilon = 1e-9</div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">  hparams.learning_rate_schedule = "legacy" #</span><span style="color: rgb(255, 0, 0);">学习率策略</span></div><div style="margin-left: 40px;"> <span style="color: rgb(255, 0, 0);"> hparams.learning_rate_decay_scheme = "noam"</span></div><div style="margin-left: 40px;">  <span style="color: rgb(255, 0, 0);">hparams.learning_rate = 0.1</span></div><div style="margin-left: 40px;">  hparams.learning_rate_warmup_steps = 4000</div><div style="margin-left: 40px;">  hparams.initializer_gain = 1.0</div><div style="margin-left: 40px;">  hparams.num_hidden_layers = 6</div><div style="margin-left: 40px;">  hparams.initializer = "uniform_unit_scaling"</div><div style="margin-left: 40px;">  hparams.weight_decay = 0.0</div><div style="margin-left: 40px;">  hparams.optimizer_adam_beta1 = 0.9</div><div style="margin-left: 40px;">  hparams.optimizer_adam_beta2 = 0.98</div><div style="margin-left: 40px;">  hparams.num_sampled_classes = 0</div><div style="margin-left: 40px;">  hparams.label_smoothing = 0.1</div><div style="margin-left: 40px;">  hparams.shared_embedding_and_softmax_weights = True</div><div style="margin-left: 40px;">  hparams.symbol_modality_num_shards = 16</div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">2.3 多种学习率策略</span></div><div><br/></div><div><br/></div><hr/><div><br/></div><div><span style="color: rgb(255, 0, 0);"># 位于 tensor2tensor\tensor2tensor\utils\learning_rate.py</span></div><div><br/></div><div>def learning_rate_schedule(hparams):</div><div>  """Learning rate schedule based on hparams."""</div><div><br/></div><div style="margin-left: 40px;">  schedule_string = <span style="color: rgb(255, 0, 0);">hparams.learning_rate_schedule</span></div><div style="margin-left: 40px;">  </div><div style="margin-left: 40px;">  names = schedule_string.split("*") <span style="color: rgb(255, 0, 0);"># 切分出不同的学习率策略</span></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  names = [name.strip() for name in names if name.strip()]</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  ret = tf.constant(1.0)</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  for name in names:</div><div style="margin-left: 40px;">    ret *= <span style="color: rgb(255, 0, 0);">learning_rate_factor</span>(name, step_num, hparams) <span style="color: rgb(255, 0, 0);"># 不同策略乘起来</span></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  return ret</div><div><br/></div><div><br/></div><div>def <span style="color: rgb(255, 0, 0);">learning_rate_factor</span>(name, step_num, hparams):</div><div>  """Compute the designated learning rate factor from hparams."""</div><div><br/></div><div style="margin-left: 40px;">  if name == "constant":</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">    return hparams.learning_rate_constant</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  elif name == "linear_warmup":</div><div style="margin-left: 40px;">    return <span style="color: rgb(255, 0, 0);">tf.minimum(1.0, step_num / hparams.learning_rate_warmup_steps)</span></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">elif name == "legacy":</div><div style="margin-left: 40px;">  return <span style="color: rgb(255, 0, 0);">legacy_learning_rate_schedule</span>(hparams)</div><div><br/></div><div><br/></div><div>def <span style="color: rgb(255, 0, 0);">legacy_learning_rate_schedule</span>(hparams):</div><div>  """Backwards-compatible learning-rate schedule."""</div><div><br/></div><div style="margin-left: 40px;">  step_num = _global_step(hparams)</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  warmup_steps = tf.to_float(hparams.learning_rate_warmup_steps)</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  if hparams.learning_rate_decay_scheme == "<span style="color: rgb(255, 0, 0);">noam</span>":</div><div style="margin-left: 40px;">    ret = <span style="color: rgb(255, 0, 0);">5000.0</span> * hparams.hidden_size**-0.5 * tf.minimum(</div><div style="margin-left: 40px;">        (step_num + 1) * warmup_steps**-1.5, (step_num + 1)**-0.5) <span style="color: rgb(255, 0, 0);"># 论文中公式（3）</span></div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  optimizer_correction = <span style="color: rgb(255, 0, 0);">0.002</span> if "adam" in hparams.optimizer else 1.0</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">  return ret * optimizer_correction * hparams.<span style="color: rgb(255, 0, 0);">learning_rate </span><span style="color: rgb(255, 0, 0);"># 5000 * 0.002 * 0.1 = 1</span></div><div style="margin-left: 40px;"> </div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a></div><div><a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/Transformer_translate.ipynb">https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/Transformer_translate.ipynb</a></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></div><hr/><hr/><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="transformer 系列" scheme="https://xinrihui.github.io/categories/transformer-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="transformer" scheme="https://xinrihui.github.io/tags/transformer/"/>
    
    <category term="nlp" scheme="https://xinrihui.github.io/tags/nlp/"/>
    
    <category term="深度学习" scheme="https://xinrihui.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Spark shuffle 机制</title>
    <link href="https://xinrihui.github.io/2022/12/25/1.shuffle%20%E7%A0%94%E7%A9%B6/"/>
    <id>https://xinrihui.github.io/2022/12/25/1.shuffle%20%E7%A0%94%E7%A9%B6/</id>
    <published>2022-12-25T01:54:24.000Z</published>
    <updated>2022-12-29T02:04:23.575Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-12-07 09:55:36 +0000"/><meta name="source" content="yinxiang.superNote"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="https://tech.meituan.com/2016/05/12/spark-tuning-pro.html"/><meta name="updated" content="2022-12-24 15:29:44 +0000"/><title>1.shuffle 研究</title></head><body><h1>总结</h1><div><br/></div><div><span style="font-size: 12pt;">1.管道执行 pipeline</span></div><div><span style="font-size: 12pt;">操作都在内存中执行，不需要为了把计算结果给其他任务而将数据落盘</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">2.Shuffle是 map reduce 的中间过程。map 和 reduce 过程经常被提及 而shuffle不配有姓名，但它恰恰是 开销最大 也最值得优化的步骤</span></div><div><br/></div><div><span style="font-size: 12pt;">3.排序</span></div><div><br/></div><div><span style="font-size: 12pt;">mapreduce 是所有的 shuffle 都排序，排序的目的是： 在O(1) 的空间复杂度下在 reduce 端实现 key  的聚合；</span></div><div><br/></div><div><span style="font-size: 12pt;">spark 在一开始的版本中，为了节约排序的时间代价（快排 O(nlogn)），在 reduce 端 采用 内存中的 hashmap  来做 key  的聚合，当内存写满后再 溢写到磁盘中</span></div><div><br/></div><div><span style="font-size: 12pt;">4.Pipline &amp; writing disk</span></div><div><span style="font-size: 12pt;">mapreduce 是全部落盘，spark 是遇到shuffle 才落盘， MPP是全部pipeline；</span></div><div><span style="font-size: 12pt;">Pipeline越多 延迟越低 容错越差（没有检查点 错了就回到原点 重头再来） 任务调度更加精确 带来了系统复杂度上升（我这边计算好了要交给你 你注意接收）那么系统的吞吐量和可扩展性必然下降</span></div><div><br/></div><div><span style="font-size: 12pt;">5.宽依赖 和 窄依赖</span></div><div><br/></div><div><span style="font-size: 12pt;">窄依赖：一个子分区只依赖于一个 父分区，或者依赖于多个完整的父分区 （因为完整所以不需要把分区打散了传送）。</span></div><div><br/></div><div><span style="font-size: 12pt;">宽依赖：一个子分区 依赖多个父分区的其中一部分（因为不完整，需要将分区打散了再发送）。</span></div><div><br/></div><hr/><div><br/></div><h1>尽量避免使用shuffle类算子</h1><div><br/></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle是一个涉及到CPU(序列化反序列化)、网络IO(跨节点数据传输)以及磁盘IO(shuffle中间结果落地)的操作，所以它是最消耗性能的操作</span>。</span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle过程就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作</span>。比如reduceByKey、join等算子，都会触发shuffle操作。</span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle过程中，各个节点上的相同key都会先写入本地磁盘文件中，然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同key。而且相同key都拉取到同一个节点（优先放入内存中）进行聚合操作时，还有可能会因为一个节点上处理的key过多，导致内存不够存放，进而溢写到磁盘文件中</span>。</span></div><div><br/></div><div><span style="font-size: 12pt;">因此在shuffle过程中，可能会发生大量的磁盘文件读写的IO操作，以及数据的网络传输操作。磁盘IO和网络数据传输也是shuffle性能较差的主要原因。因此在我们的开发过程中，能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</span></div><div><br/></div><h2>方案1.map 端预聚合</h2><div><span style="font-size: 12pt;">在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。通常来说，在可能的情况下，<span style="font-weight: bold;">建议使用reduceByKey或者aggregateByKey算子</span>来<span style="font-weight: bold;">替代掉groupByKey算子</span>。<span style="font-weight: bold;">因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合</span>。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。</span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;"> groupByKey                                                                                                     </span></span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/8307D049-2768-4F48-B093-A2D2B865F7AB.png"/><div><span style="font-size: 12pt;"><span style="font-weight: bold;"> reduceByKey</span></span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/28927950-4E28-4D39-911C-27EFFFF657B1.png"/><div><br/></div><div><br/></div><h2>方案２.广播</h2><div><br/></div><div><span style="font-size: 12pt;">使用广播，把较小的表广播出去，相当于每个节点都复制了一份</span></div><div><span style="font-size: 12pt;">// 传统的join操作会导致shuffle操作。</span></div><div><span style="font-size: 12pt;">// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。</span></div><div><span style="font-size: 12pt;">val rdd3 = rdd1.join(rdd2)</span></div><div><br/></div><div><span style="font-size: 12pt;">// Broadcast+map的join操作，不会导致shuffle操作。</span></div><div><span style="font-size: 12pt;">// 使用Broadcast将一个数据量较小的RDD作为广播变量。</span></div><div><span style="font-size: 12pt;">val rdd2Data = rdd2.collect()</span></div><div><span style="font-size: 12pt;">val rdd2DataBroadcast = sc.broadcast(rdd2Data)</span></div><div><br/></div><div><span style="font-size: 12pt;">// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。</span></div><div><span style="font-size: 12pt;">// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。</span></div><div><span style="font-size: 12pt;">// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。</span></div><div><span style="font-size: 12pt;">val rdd3 = rdd1.map(rdd2DataBroadcast...)</span></div><div><br/></div><div><span style="font-size: 12pt;">// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。</span></div><div><span style="font-size: 12pt;">// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。</span></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用：</span></span></div><div><a href="https://tech.meituan.com/spark_tuning_basic.html" rev="en_rl_none"><span style="font-size: 12pt;"><u>https://tech.meituan.com/spark_tuning_basic.html</u></span></a></div><div><br/></div><div><br/></div><h1>数据倾斜问题</h1><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">现象：</span></span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">1.绝大多数task执行得都非常快，但个别task执行极慢。比如，总共有1000个task，997个task都在1分钟之内执行完了，但是剩余两三个task却要一两个小时</span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">2.原本能够正常执行的Spark作业，某天突然报出OOM（内存溢出）异常，观察异常栈，是我们写的业务代码造成的。</span></p><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">原理：</span></span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">1.在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。比如大部分key对应10条数据，但是个别key却对应了100万条数据，那么大部分task可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别task可能分配到了100万数据，要运行一两个小时。因此，整个Spark作业的运行进度是由运行时间最长的那个task决定的。因此出现数据倾斜的时候，Spark作业看起来会运行得非常缓慢，甚至可能因为某个task处理的数据量过大导致内存溢出。举个例子：</span></p><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/D5F2C86A-0C55-4805-9390-0450E87ECE84.png"/><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">2.可能会触发shuffle操作的RDD算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。</span></p><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">解决方案</span></span></p><p style="--en-paragraph:true;"><br/></p><h2>1.聚合（groupByKey）</h2><p style="--en-paragraph:true;"><br/></p><div><span style="font-size: 12pt;">对于聚合类的shuffle ，可以采用两阶段聚合（局部聚合+全局聚合）</span></div><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;">第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)</span></p><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/3010811A-0551-46B8-A2E8-9B78C7610D2C.png"/><h2>２.连接(join)</h2><p style="--en-paragraph:true;"><br/></p><h3>1.reduce join 转换为 map join</h3><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（1）reduce join：走shuffle过程，一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join。</span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（2）map join：将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后<span style="font-weight: bold;">对其创建一个Broadcast变量</span>；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。</span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（3）缺点：我们需要将小表进行广播，此时会比较消耗内存资源，<span style="font-weight: bold;">driver和每个Executor内存中都会驻留一份小RDD的全量数据</span>。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。</span></p><p style="--en-paragraph:true;"><br/></p><h3>2.采样倾斜的key并分拆join</h3><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><b><span style="font-weight: 700;">方案实现思路：</span></b> </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（1）对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（2）然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;"> （3）接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（4）再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（5）而另外两个普通的RDD就照常join即可。 </span></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">（6）最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。</span></p><p style="--en-paragraph:true;"><br/></p><p style="text-align:start;"><span style="font-size: 12pt;"><b><span style="font-weight: 700;">方案实现原理：</span></b>对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了</span></p><p style="text-align:start;"><br/></p><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/4D110DDA-A219-4A32-9A6C-09F8B67C6702.png"/><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><br/></p><div><br/></div><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">总结：</span>针对原始RDD进行join操作时候遇到的种种问题，spark提供了高层抽象spark SQL，它将完成上述的SQL优化</span></p><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;"><span style="font-weight: bold;">引用：</span></span></p><p style="--en-paragraph:true;"><a href="https://tech.meituan.com/spark_tuning_pro.html" rev="en_rl_none"><span style="font-size: 12pt;">https://tech.meituan.com/spark_tuning_pro.html</span></a></p><p style="--en-paragraph:true;"><br/></p><h1>spark SQL 实现 join 的物理计划</h1><div><br/></div><h2>1.Broadcast (hash) Join</h2><div><span style="font-size: 12pt;">在SparkSQL中，对两个表做Join最直接的方式是先根据key分区，再在每个分区中把key值相同的记录拿出来做连接操作。但这样就不可避免地涉及到shuffle，而shuffle在Spark中是比较耗时的操作，我们应该尽可能的设计Spark应用使其避免大量的shuffle。步骤如下：</span></div><div><span style="font-size: 12pt;">1. broadcast阶段：将小表广播分发到大表所在的所有主机。广播算法可以有很多，最简单的是先发给driver，driver再统一分发给所有executor；要不就是基于bittorrete的p2p思路；</span></div><div><span style="font-size: 12pt;">2. hash join阶段：在每个executor上执行单机版hash join，小表映射，大表试探</span></div><div><span style="font-size: 12pt;">executor存储小表的全部数据，一定程度上牺牲了空间，换取shuffle操作大量的耗时（类似于 hive 的mapjoin ）</span></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/695F22E9-6704-42E1-9873-07EDAE923B5D.png" height="456" width="831"/><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">缺点：</span>这个方案只能用于广播较小的表，否则数据的冗余传输就远大于shuffle的开销；另外，广播时需要将被广播的表现collect到driver端，当频繁有广播出现时，对driver的内存也是一个考验。</span></div><div><span style="font-size: 12pt;">只有当表的大小在 spark.sql.autoBroadcastJoinThreshold 的设置值（默认为 10MB）之内，才会启用 broadcast join，否则采用sort merge join。此方法适合 一张大表和一张非常小的小表 join。</span></div><div><br/></div><h2>2.shuffle Hash Join （ 重分区 hash join ）</h2><div><br/></div><div><span style="font-size: 12pt;">如果一张表很小，执行join操作最优的选择无疑是broadcast hash join，效率最高。但是一旦小表数据量增大，广播所需内存、带宽等资源必然就会太大，broadcast hash join就不再是最优方案。此时可以按照join key进行分区，根据key相同必然分区相同的原理，就可以将大表join分而治之，划分为很多小表的join，充分利用集群资源并行化。</span></div><div><span style="font-size: 12pt;">分为两步：</span></div><div><span style="font-size: 12pt;">1. 对两张表分别按照 join keys进行重分区，即shuffle，目的是为了让 有相同join keys值的记录分到对应的分区中</span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/9D78FE48-5048-47F8-A919-45E85E0A7A19.png" height="293" width="876"/><div><span style="font-size: 12pt;">2. 对 各个 分区中的数据 进行join：先将 <span style="font-weight: bold;">小表的分区构造为一张hash表</span>，然后根据大表分区中记录的join keys值拿出来进行匹配；</span></div><div><br/></div><div><span style="font-size: 12pt;">优点：两张表 对应的 两个分区 自己做 join ，不用 和 其他的分区 做关联，降低开销</span></div><div><br/></div><div><span style="font-size: 12pt;">Shuffle Hash Join的条件有以下几个：</span></div><div><br/></div><div><span style="font-size: 12pt;">1）分区的平均大小不超过spark.sql.autoBroadcastJoinThreshold所配置的值，默认是10M</span></div><div><span style="font-size: 12pt;">2） 开启 尝试使用hash join的开关，spark.sql.join.preferSortMergeJoin=false</span></div><div><span style="font-size: 12pt;">3）一侧的表要明显小于另外一侧，小的一侧将被hash（明显小于的定义为3倍小，此处为经验值）</span></div><div><br/></div><div><span style="font-size: 12pt;">我们可以看到，在一定大小的表中，SparkSQL从时空结合的角度来看，将两个表进行重新分区，并且对小表中的分区进行hash化，从而完成join。在保持一定复杂度的基础上，尽量减少driver和executor的内存压力，提升了计算时的稳定性。</span></div><div><br/></div><div><br/></div><h2>3.shuffle Sort Merge Join （ 重分区 排序 join ）</h2><div><br/></div><div><span style="font-size: 12pt;">首先将两张表按照join keys进行了重新shuffle，保证join keys值相同的记录会被分在相应的分区。</span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/7675B305-2BE3-4D1D-9C37-2CE5B9423E5F.png" height="443" width="859"/><div><br/></div><div><span style="font-size: 12pt;">分区后对每个分区内的数据进行排序（<span style="font-weight: bold;">spark shuffle 阶段 自动排序</span>），排序后再对相应的分区内的记录进行连接。因为两个序列都是有序的，从头遍历，碰到key相同的就输出；如果不同，左边小就继续取左边，反之取右边。可以看出，无论分区有多大，Sort Merge Join都不用把某一侧的数据全部加载到内存中，而是 即用 即取 即丢，从而大大提升了大数据量下sql join的稳定性。</span></div><div><br/></div><div><span style="font-size: 12pt;">这是spark SQL 默认的join 方法，适合两张表都是大表的情况。</span></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/2AD3BD2D-330D-4E33-B6F6-B346A2392C93.png" height="615" width="1079"/><div><br/></div><div><span style="font-size: 12pt;">其实 <span style="font-weight: bold;">hash join</span> 的思路来源于传统的数据库</span></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">Hash Join</span></span></div><div><span style="font-size: 12pt;">先来看看这样一条SQL语句：select * from order,item where item.id = order.i_id，很简单一个Join节点，参与join的两张表是item和order，join key分别是item.id以及order.i_id。现在假设这个Join采用的是hash join算法，整个过程会经历三步：</span></div><div><span style="font-size: 12pt;">1） 确定Build Table以及Probe Table：这个概念比较重要，Build Table使用join key构建Hash Table，而Probe Table使用join key进行探测，探测成功就可以join在一起。通常情况下，小表会作为Build Table，大表作为Probe Table。此事例中item为Build Table，order为Probe Table。</span></div><div><span style="font-size: 12pt;">2） 构建Hash Table：依次读取Build Table（item）的数据，对于每一行数据根据join key（item.id）进行hash，hash到对应的Bucket，生成hash table中的一条记录。数据缓存在内存中，如果内存放不下需要dump到外存。</span></div><div><span style="font-size: 12pt;">3） 探测：再依次扫描Probe Table（order）的数据，使用相同的hash函数映射Hash Table中的记录，映射成功之后再检查join条件（item.id = order.i_id），如果匹配成功就可以将两者join在一起。</span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/54886F94-64CA-45E3-B3A6-F85E54FE56F3.png" height="493" width="805"/><div><span style="font-size: 12pt;">很显然，hash join基本都只扫描两表一次，可以认为o(a+b)，较之最极端的笛卡尔集运算a*b，时间复杂度低。</span></div><p style="--en-paragraph:true;"><br/></p><p style="--en-paragraph:true;"><span style="font-size: 12pt;">Join操作是传统数据库中的一个高级特性，尤其对于当前MySQL数据库更是如此，原因很简单，MySQL对Join的支持目前还比较有限，只支持Nested-Loop Join算法，因此在OLAP场景下MySQL是很难吃的消的，不要去用MySQL去跑任何OLAP业务，结果真的很难看。和MySQL相比，PostgreSQL、SQLServer、Oracle等这些数据库对Join支持更加全面一些，都支持Hash Join算法。总体而言，传统数据库单机模式做Join的场景毕竟有限，也建议尽量减少使用Join。然而大数据领域就完全不同，Join是标配，OLAP业务根本无法离开表与表之间的关联，对Join的支持成熟度一定程度上决定了系统的性能，夸张点说，’得Join者得天下’。</span></p><p style="--en-paragraph:true;"><br/></p><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用：</span></span></div><div><a href="http://hbasefly.com/2017/03/19/sparksql-basic-join/" rev="en_rl_none"><span style="font-size: 12pt;">http://hbasefly.com/2017/03/19/sparksql-basic-join/</span></a></div><div><a href="http://sharkdtu.com/posts/spark-sql-join.html" rev="en_rl_none"><span style="font-size: 12pt;">http://sharkdtu.com/posts/spark-sql-join.html</span></a></div><div><br/></div><h1><span style="color: #000000;">有的 join 其实属于 窄依赖 </span></h1><div><br/></div><ul><li><div><span style="font-size: 12pt;"><span style="font-weight: bold;">窄依赖（不发生 shuffle）</span>：父Rdd的分区最多只能被一个子Rdd的分区所引用，即一个父Rdd的分区对应一个子Rdd的分区，或者多个父Rdd的分区对应一个子Rdd的分区。即<span style="font-weight: bold;">一对一 或 多对一（儿子有多个父亲）</span>，如下图左边所示。</span></div></li></ul><div><br/></div><ul><li><div><span style="font-size: 12pt;"><span style="font-weight: bold;">宽依赖（发生shuffle）</span>：RDD的分区依赖于父RDD的多个分区或所有分区，即存在一个父RDD的一个分区对应一个子RDD的多个分区。1个父RDD分区对应多个子RDD分区，这其中又分两种情况：1个父RDD对应所有子RDD分区（未经协同划分的Join）或者1个父RDD对应非全部的多个RDD分区（如groupByKey），即<span style="font-weight: bold;">一对多（父亲有多个儿子）。</span></span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">（1）图中左半部分join：如果两个RDD在进行join操作时，一个RDD的partition仅仅和另一个RDD中已知个数的Partition进行join，那么这种类型的join操作就是窄依赖，例如图1中左半部分的join操作(join with inputs co-partitioned)；</span></div><div><br/></div><div><span style="font-size: 12pt;">（2）图中右半部分join：其它情况的join操作就是宽依赖,例如图1中右半部分的join操作(join with inputs not co-partitioned)，由于是需要父RDD的所有partition进行join的转换，这就涉及到了shuffle，因此这种类型的join操作也是宽依赖。</span></div><div><br/></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/Image.png" height="410" width="565"/><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">join with inputs co-partitions</span>：</span></div><div><span style="font-size: 12pt;">如果 两张表的 分区 是一一对应的， 相当于 <span style="font-weight: bold;">分区hash join</span> 的 第一步已经 天然做好了，因此 只要 两张表的 对应两个分区（相当于 两个子表 ）自己 做Join 即可，</span></div><div><span style="font-size: 12pt;">具体可以采用 hash Join ，若分区 内已经有序，还可以使用 sort merge Join 。</span></div><div><span style="font-size: 12pt;">在这种情况下，子RDD 的一个分区的 数据 不会 “可能来自于 所有的 父RDD” ，所以是窄依赖。</span></div><div><br/></div><h1>shuffle管理器</h1><div><br/></div><div><span style="font-size: 12pt;">在Spark 1.2以前，默认的 shuffle计算引擎 是HashShuffleManager。它有着一个非常严重的弊端，就是会产生大量的中间磁盘文件，进而由大量的磁盘IO操作影响了性能。因此在Spark 1.2以后的版本中，默认的 ShuffleManager 改成了 SortShuffleManager</span></div><div><br/></div><h2>HashShuffleManager</h2><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle write</span>：主要就是在一个stage结束计算之后，为了下一个stage可以执行shuffle类的算子（比如reduceByKey），而将每个task处理的数据按key进行“分类”。所谓“分类”，就是<span style="font-weight: bold;">对相同的key执行hash算法，从而将相同key都写入同一个磁盘文件中，而每一个磁盘文件都只属于下游stage的一个task</span>。在将数据写入磁盘之前，会先将数据写入内存缓冲中，当内存缓冲填满之后，才会溢写到磁盘文件中去。下一个stage的task有多少个，当前stage的每个task就要创建多少份磁盘文件。如图所示，下一个stage 一共有3个task ，当前的每一个task都要创建3个文件。可见，未经优化的<span style="font-weight: bold;">shuffle write操作所产生的磁盘文件的数量是极其惊人的。（MapReduce 也存在此问题）</span></span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">shuffle read</span>：此时该stage的每一个task就需要将上一个stage的计算结果中的所有相同key，从各个节点上通过网络都拉取到自己所在的节点上，然后进行key的聚合或连接等操作。由于shuffle write的过程中，task给下游stage的每个task都创建了一个磁盘文件，因此shuffle read的过程中，每个task只要从上游stage的所有task所在节点上，拉取属于自己的那一个磁盘文件即可。shuffle read的拉取过程是一边拉取一边进行聚合的。每个shuffle read task都会有一个自己的buffer缓冲，每次都只能拉取与buffer缓冲相同大小的数据，然后通过内存中的一个Map进行聚合等操作。聚合完一批数据后，再拉取下一批数据，并放到buffer缓冲中进行聚合操作。以此类推，直到最后将所有数据到拉取完，并得到最终的结果。</span></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/a8d32434d35045b4b05ef6bcc7ce4fba.jpeg" height="564" width="957"/><div><br/></div><div><span style="font-size: 12pt;">优化后的Hash Shuffle</span></div><div><span style="font-size: 12pt;">普通机制Hash Shuffle会产生大量的小文件(M * R），对文件系统的压力也很大，也不利于IO的吞吐量，后来做了优化（设置spark.shuffle.consolidateFiles=true开启，默认false），把在同一个core上的多个Mapper输出到同一个文件，这样文件数就变成core * R 个了。如下图所示：2个core 4个map task 3 个reduce task，会产生2*3=6个小文件。</span></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/24e46dede4474c3d8d9349bb93579a4b.jpeg" height="736" width="957"/><div><br/></div><div><span style="font-size: 12pt;">Hash shuffle合并机制的问题：如果 Reducer 端的并行任务或者是数据分片过多的话则 Core * Reducer Task 依旧过大，也会产生很多小文件。进而引出了更优化的sort shuffle。</span></div><div><br/></div><h2>SortShuffleManager</h2><div><br/></div><h3>普通运行机制</h3><div><br/></div><div><span style="font-size: 12pt;">在该模式下，数据会先写入一个内存数据结构中，此时根据不同的shuffle算子，可能选用不同的数据结构。</span></div><ul><li><div><span style="font-size: 12pt;">如果是 reduceByKey 这种 <span style="font-weight: bold;">聚合类的shuffle算子，那么会选用Map数据结构，一边通过Map进行聚合，一边写入内存</span>；</span></div></li><li><div><span style="font-size: 12pt;">如果是join这种普通的shuffle算子，那么会选用Array数据结构，直接写入内存。</span></div></li></ul><div><span style="font-size: 12pt;">接着，每写一条数据进入内存数据结构之后，就会判断一下，是否达到了某个临界阈值。如果达到临界阈值的话，那么就会尝试将内存数据结构中的数据溢写到磁盘，然后清空内存数据结构。<span style="font-weight: bold;">在溢写到磁盘文件之前，会先根据key对内存数据结构中已有的数据进行排序</span>。排序过后，会分批将数据写入磁盘文件。默认的batch数量是10000条，也就是说，排序好的数据，会以每批1万条数据的形式分批写入磁盘文件。一个task将所有数据写入内存数据结构的过程中，会发生多次磁盘溢写操作，也就会产生多个临时文件。</span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">最后会将之前所有的临时磁盘文件都进行合并</span>，这就是merge过程，此时会将之前所有临时磁盘文件中的数据读取出来，然后依次写入最终的磁盘文件之中。此外，<span style="font-weight: bold;">由于一个当前task就只对应一个磁盘文件</span>，也就意味着该task为下游stage的task准备的数据都在这一个文件中，因此还会单独写一份<span style="font-weight: bold;">索引文件，其中标识了下游各个task的数据 在文件中的start offset与end offset</span>。</span></div><div><br/></div><div><span style="font-size: 12pt;">下游的 task 的数量 取决于 分区函数( eg. partitionBy , repartition ) 所设定的分区数目 ，这里的下游 相当于 MapReduce 中的 reduce 阶段 ，在reduce 阶段 ：一个分区对应一个 reduce task ，它自己去拉取 各个Map task 生成的属于自己的分区文件 ； </span></div><div><span style="font-size: 12pt;">这里的优化策略可以概括为，对于 一个 Map task，它本来要生成 多个分区文件，我们将它合并到一个文件中，并搭配一个索引文件，这样大大减少了文件数量。</span></div><div><br/></div><div><br/></div><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/C7C9849D-7F60-4F02-8F46-806CBB693D89.png"/><div><br/></div><h3>bypass 运行机制</h3><div><br/></div><img src="/Resources/1.shuffle%20%E7%A0%94%E7%A9%B6.resources/e46b3cd956dd4f1493fa6218d842be2d.jpeg" height="694" width="1080"/><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">触发条件：</span></div><ul><li><div><span style="font-size: 12pt;">shuffle map task 数量小于 spark.shuffle.sort.bypassMergeThreshold 参数设定值。</span></div></li></ul><div><span style="font-size: 12pt;">AND</span></div><ul><li><div><span style="font-size: 12pt;">join 类算子（由于在普通的运行机制下，对于聚合类算子，会预先进行聚合再写入文件，性能更优）</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;">此时task会为每个reduce端的task都创建一个临时磁盘文件，并将数据按key进行hash然后根据key的hash值，将key写入对应的磁盘文件之中。当然，写入磁盘文件时也是先写入内存缓冲，缓冲写满之后再溢写到磁盘文件的。最后，同样会将所有临时磁盘文件都合并成一个磁盘文件，并创建一个单独的索引文件。</span></div><div><br/></div><div><span style="font-size: 12pt;">该过程的磁盘写机制其实跟未经优化的HashShuffleManager是一模一样的，因为都要创建数量惊人的磁盘文件，只是在最后会做一个磁盘文件的合并而已。因此少量的最终磁盘文件，也让该机制相对未经优化的HashShuffleManager来说，shuffle read的性能会更好。</span></div><div><br/></div><div><br/></div><h1>为什么 shuffle 的中间结果落磁盘 而不落在内存</h1><div><br/></div><p>在目前的 Spark 实现中，shuffle block 一定是落地到磁盘的，无法像普通 RDD 那样 cache 到本地内存或 Tachyon 中。想将 shuffle block cache 到内存中，应该主要是为了提速，但事实上并没有什么必要。</p><p><br/></p><p>首先，内存 cache 发挥作用的前提是被 cache 的数据会被反复使用。使用越频繁，相对来说收益越高。而 shuffle block 只有在下游 task 失败，进行容错恢复时才有重用机会，频次很低。值得注意的是，在不 cache 的情况下，针对同一个含 shuffle 的 RDD 执行多个 action，并不会重用 shuffle 结果。Shuffle block 是按 job ID + task ID + attempt ID 标识的，每个 action 都对应于一个独立的 job，因此无法重用。这里或许是 Spark 的一个可改进点。</p><p><br/></p><p>其次，从数据量上说，如果执行的是需要 shuffle 大数据量的 Spark job，内存容量不够，无论如何都需要落盘；如果执行的是小数据量的 Spark job，虽然 shuffle block 会落盘，但仍然还在 OS cache 内，而 shuffle block 一般都是在生成之后短时间内即被下游 task 取走，所以大部分情况下仍然还是内存访问。</p><p><br/></p><p>最后，将 shuffle block cache 在内存中的确有一个潜在好处，就是有机会直接在内存中保存原始的 Java 对象而避免序列化开销。但这个问题在新近的 Spark 版本中也有了比较好的解决方案。Tungsten project 中引入的 UnsafeRow 格式统一了内存和磁盘表示，已经最小化了序列化成本。</p><p><br/></p><h1>分区函数：HashPartitioner 和 RangePartitioner </h1><div><br/></div><div><span style="font-size: 12pt;">HashPartitioner的原理很简单，只是计算key的hashcode，然后对新分区的数目取余。所以HashPartitioner最重要的属性是新分区的数量。注意HashPartition不能支持key为数组类型。</span></div><div><br/></div><div><span style="font-size: 12pt;">HashPartitioner分区可能导致每个分区中数据量的不均匀。</span></div><div><br/></div><div><span style="font-size: 12pt;">RangePartitioner的原理会稍微复杂一些，会遍历rdd的所有分区数据，从每个分区都会采样，然后根据样本，生成新分区的边界值，这样就可以根据key把数据分布到对应的新分区。</span></div><div><br/></div><div><span style="font-size: 12pt;">Range分区尽量保证每个分区中数据量的均匀，将一定范围内的数映射到某一个分区内。分区与分区之间数据是有序的，但分区内的元素是不能保证顺序的。</span></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="https://zhmin.github.io/2019/01/06/spark-partitioner/" rev="en_rl_none"><span style="font-size: 12pt;">https://zhmin.github.io/2019/01/06/spark-partitioner/</span></a></div><div><a href="https://www.jianshu.com/p/d9fd44781a32" rev="en_rl_none"><span style="font-size: 12pt;">https://www.jianshu.com/p/d9fd44781a32</span></a></div><div><br/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="spark 系列" scheme="https://xinrihui.github.io/categories/spark-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="spark" scheme="https://xinrihui.github.io/tags/spark/"/>
    
    <category term="分布式计算框架" scheme="https://xinrihui.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>Spark RDD 算子</title>
    <link href="https://xinrihui.github.io/2022/12/25/2.RDD%20%E7%AE%97%E5%AD%90/"/>
    <id>https://xinrihui.github.io/2022/12/25/2.RDD%20%E7%AE%97%E5%AD%90/</id>
    <published>2022-12-25T01:54:24.000Z</published>
    <updated>2022-12-29T02:04:23.571Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="羊村的好朋友小灰灰"/><meta name="created" content="2022-12-07 04:27:35 +0000"/><meta name="source" content="yinxiang.superNote"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="https://blog.csdn.net/CYJ2014go/article/details/83014075"/><meta name="updated" content="2022-12-24 15:29:03 +0000"/><meta name="content-class" content="yinxiang.superNote"/><title>2.RDD 算子</title></head><body><h1><span style="font-family: unset;"><span style="color: unset;">读写文件</span></span></h1><div><br/></div><div><span style="font-size: 12pt;">spark默认读取 HDFS中的文件（<span style="font-weight: bold;">hdfs://Master:9000</span>/tmp/hive1）</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">sc.textFile("hdfs://Master:9000/tmp/people") // idea IDE默认在file:///里找。最好指明文件路径 是在 HDFS 还是在本地 </div><div><br/></div><div><span style="font-size: 12pt;">读取本地文件:</span></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">val rdd=sc.textFile("file:////app/hadoop/spark110/NOTICE")   //必须在所有datanode中都有，而且都为此路径</div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">windows 下的 本地文件 路径必须使用 '\\' 隔开</span></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">data_dir = 'data\\' #   当前文件夹下有 data目录tmp_index_file_dir = data_dir + 'tmp_index_spark.bin'  lines = sc.textFile(tmp_index_file_dir,8)</div><div><br/></div><div><span style="font-size: 12pt;"><span style="color: rgb(255, 0, 0);">问题： 如何控制 输出的文件 只有一个切片</span></span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">lines = sc.textFile(tmp_index_file_dir,8) # 对大文件 进行切片 sliceNum=8，否则报错# 20/05/30 11:54:28 ERROR PythonRunner: This may have been caused by a prior exception:java.net.SocketException: Connection reset by peer: socket write errorlines=lines.map(lambda line:line.split("\t"))lines=lines.sortBy(lambda x: x[0])lines=lines.map(lambda line: line[0]+"\t"+line[1])# lines.saveAsTextFile(sorted_tmp_index_file_dir) # 在文件夹下 保存 sliceNum 个切片文件lines.coalesce(1, shuffle=True).saveAsTextFile(sorted_tmp_index_file_dir) # 在文件夹下 只有一个 切片</div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="https://stackoverflow.com/questions/24371259/how-to-make-saveastextfile-not-split-output-into-multiple-file" rev="en_rl_none"><span style="font-size: 12pt;">https://stackoverflow.com/questions/24371259/how-to-make-saveastextfile-not-split-output-into-multiple-file</span></a></div><div><br/></div><div><br/></div><h1>遍历 </h1><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">lines = sc.textFile(tmp_index_file_dir,8)  # 对大文件 要进行切片 sliceNum=8，否则报错print(lines.first())  # 显示 第1条print(lines.take(10)) # 可以看 指定数目的记录for line in lines: #TypeError: 'RDD' object is not iterable     print(line)for line in lines.collect() : # lazy 原则， 遇到 action 才真正 执行DAG 计算图；collect() 将数据从各个计算节点 拉回到主节点     print(line)</div><div><br/></div><div><br/></div><h1>重分区 </h1><div><br/></div><h2>coalesce() 和 repartition()</h2><div><br/></div><div><span style="font-size: 12pt;"><span style="color: rgb(255, 0, 0);">问题：分区太多了怎么办</span></span></div><div><br/></div><div><span style="font-size: 12pt;">在用户使用Spark的过程中，常常会使用filter算子进行数据过滤。 而频繁的过滤或者过<span style="font-family: unset;"><span style="color: unset;">滤掉的数据量过大就会产生问题，造成大量小分区的产生（每个分区数据量小）。</span></span></span></div><div><span style="font-size: 12pt;"><span style="font-family: unset;"><span style="color: unset;">例如：</span></span></span></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">val rdd2 = rdd1.filter(line=&gt;lines.contains("error")).filter(line=&gt;line.contains("info")).collect()</div><div><br/></div><div><span style="font-size: 12pt;">Spark会对每一个分区分配一个task 来执行 RDD 的计算，如果task过多，那么每个task处理的数据量很小，就会造成线程频繁的在task之间切换，使得资源开销较大，且很多任务等待执行，并行度不高，这会造成集群工作效益低下。</span></div><div><br/></div><div><span style="font-size: 12pt;">采用 重分区的函数 来进行数据紧缩，减少分区数量，将小分区合并为大分区，从而提高效率</span></div><div><br/></div><div><span style="font-size: 12pt;">coalesce() 方法的 参数 shuffle默认 为false，</span></div><div><span style="font-size: 12pt;">repartition() 等价于 coalesce(shuffle=True)</span></div><div><br/></div><div><span style="font-size: 12pt;">假设RDD有 N个分区，需要重新划分成M个分区：（N -&gt; M）</span></div><ul><li><div><span style="font-size: 12pt;">N &lt; M: 一般情况下N个分区有数据分布不均匀的状况，利用HashPartitioner函数将数据重新分区为M个，这时需要将shuffle设置为true。因为重分区前后相当于宽依赖，会发生shuffle过程，此时可以使用 coalesce(shuffle=true)，或者直接使用repartition()。</span></div></li></ul><div><br/></div><ul><li><div><span style="font-size: 12pt;">如果N &gt; M 并且 N和M相差不多(假如N是1000，M是100): 那么就可以将N个分区中的若干个分区合并成一个新的分区，最终合并为M个分区，这是前后是窄依赖关系，可以使用coalesce(shuffle=false)。</span></div></li></ul><div><br/></div><ul><li><div><span style="font-size: 12pt;">如果 N &gt;&gt; M并且两者相差悬殊: 这时如果将shuffle设置为false，父子 RDD 是窄依赖关系，他们同处在一个stage中，就可能造成spark程序的并行度不够，从而影响性能。即当前的每个分区数据量过大，需要将分区数量增加，以利用并行计算能力，这就需要把Shuffle设置为true</span></div></li></ul><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="https://blog.csdn.net/lzq20115395/article/details/80602071" rev="en_rl_none"><span style="font-size: 12pt;">https://blog.csdn.net/lzq20115395/article/details/80602071</span></a></div><div><a href="http://lxw1234.com/archives/2015/07/341.htm" rev="en_rl_none"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/07/341.htm</span></a></div><div><br/></div><h2>分组 partitionBy</h2><div><br/></div><div><span style="font-size: 12pt;">repartition和partitionBy都是重新分区的算子，其中partitionBy只能作用于PairRDD. 但是，当作用于PairRDD时，repartition和partitionBy的行为是不同的。</span></div><div><br/></div><div><span style="font-size: 12pt;">repartition是把 <span style="color: #FF0000;">数据随机打散均匀分布于各个Partition，即随机数分区（不是根据 key 算出 hashcode 的 hash 分区）</span>；</span></div><div><br/></div><div><span style="font-size: 12pt;">partitionBy则在参数中指定了Partitioner（默认HashPartitioner），将每个(K,V)对按照K根据Partitioner计算得到对应的Partition。</span></div><div><span style="font-size: 12pt;">在合适的时候使用partitionBy可以减少shuffle次数，提高效率。</span></div><p><br/></p><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:570px;" width="570px"><colgroup><col style="width: 190px;"/><col style="width: 190px;"/><col style="width: 190px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>优点</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>缺点</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">repartition</span></div><div><span style="font-size: 12pt;">（随机分区）</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>使每个分区里数据尽量均匀</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>相同key的记录可能重分区到不同的分区</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">partitionBy</span></div><div><span style="font-size: 12pt;">（默认哈希分区）</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>相同key的记录会重分区到同一个分区</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>有数据倾斜的情况会导致每个分区数据量不均匀</div></td></tr></tbody></table><p><br/></p><div><br/></div><div><span style="font-size: 12pt;">我们可以自己设计合理的分区方法( 比如数量比较大的key 加个随机数 随机分到更多的分区， 这样处理数据倾斜更彻底一些)</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">def partitionBy(partitioner: Partitioner)                abstract class Partitioner extends Serializable {  def numPartitions: Int  def getPartition(key: Any): Int}</div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//查看rdd1中每个分区的元素  val rdd1 =  rdd.partitionBy(new org.apache.spark.HashPartitioner(2))rdd1.mapPartitionsWithIndex{      (partIdx,iter) =&gt; {         val part_map = scala.collection.mutable.Map[String, List[(Int,Int)]]()              while(iter.hasNext){              val part_name = "part_" + partIdx             var elem = iter.next()              if(part_map.contains(part_name)) {  var elems = part_map(part_name) elems ::= elem part_map(part_name) = elems              } else {                 part_map(part_name) = List[(Int,Int)]{elem}             }         }         part_map.iterator        }     }.collect// Map[分区ID, 该分区的元素列表] </div><div><br/></div><div><span style="font-size: 12pt;">这里的分区方法可以选择， 默认的分区就是 HashPartition分区:</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">class HashPartitioner(partitions: Int) extends Partitioner {  require(partitions &gt;= 0, s"Number of partitions ($partitions) cannot be negative.")  def numPartitions: Int = partitions  def getPartition(key: Any): Int = key match {    case null =&gt; 0    case _ =&gt; Utils.nonNegativeMod(key.hashCode, numPartitions)  }  override def equals(other: Any): Boolean = other match {    case h: HashPartitioner =&gt;      h.numPartitions == numPartitions    case _ =&gt;      false  }  override def hashCode: Int = numPartitions}</div><div><br/></div><div><span style="font-size: 12pt;">还可以选择 范围分区 RangePartitioner ：先键值排序， 确定样本大小，采样后不放回 总体的随机采样方法， 分配键值的分区，通过样本采样避免数据倾斜。</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">val rdd2 = rdd.partitionBy(new org.apache.spark.RangePartitioner(3,rdd))rdd2.glom()</div><div><br/></div><div><span style="font-size: 12pt;">还可以 自定义分区函数， 自己根据业务数据减缓数据倾斜问题:</span></div><div><br/></div><div><span style="font-size: 12pt;">要实现自定义的分区器，你需要继承 org.apache.spark.Partitioner 类并实现下面三个方法</span></div><div><br/></div><div><span style="font-size: 12pt;">* numPartitions: Int：返回创建出来的分区数。</span></div><div><span style="font-size: 12pt;">* getPartition(key: Any): Int：返回给定键的分区编号（ 0 到 numPartitions-1）。</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//自定义分区类，需继承Partitioner类class UsridPartitioner(numParts:Int) extends Partitioner{  //覆盖分区数  override def numPartitions: Int = numParts    //覆盖分区号获取函数  override def getPartition(key: Any): Int = {     if(key.toString == "A")           key.toString.toInt%10     else:          key.toString.toInt%5        }}</div><div><br/></div><div><br/></div><h1>排序 sortBy()</h1><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">list_b=[['1', '1'], ['0', '1'], ['2', '1'], ['3', '1'], ['4', '1'], ['5', '1'], ['6', '1'], ['7', '1'], ['8', '1'],['9', '1']]lines = sc.parallelize(list_b)lines=lines.sortBy( lambda x: x[0] ) # 指定 排序的键print(lines.take(10))</div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="https://www.iteblog.com/archives/1240.html" rev="en_rl_none"><span style="font-size: 12pt;">https://www.iteblog.com/archives/1240.html</span></a></div><div><a href="http://lxw1234.com/archives/2015/07/363.htm" rev="en_rl_none"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/07/363.htm</span></a></div><div><br/></div><h1>分组聚合 groupByKey   reduceByKey()</h1><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1 = sc.makeRDD(Array(("A",0),("A",2),("B",1),("B",2),("C",1)))rdd1.groupByKey().collect// res81: Array[(String, Iterable[Int])] = Array((A,CompactBuffer(0, 2)), (B,CompactBuffer(2, 1)), (C,CompactBuffer(1)))</div><div><br/></div><div><span style="font-size: 12pt;">（2）reduceByKey</span></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">reduceByKey </span>用于将RDD[K,V]中 每个 Key 对应的 Value 值 根据映射函数来运算。</span></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">效果上 相当于 利用 groupbyKey 把 相同 key 对应的 value 值 放入一个 List 中，再对 这个 List 执行  reduce </span></span></div><div><br/></div><div><span style="font-size: 12pt;">def reduceByKey(func: (V, V) =&gt; V): RDD[(K, V)]</span></div><div><br/></div><div><span style="font-size: 12pt;">def reduceByKey(func: (V, V) =&gt; V, numPartitions: Int): RDD[(K, V)]</span></div><div><br/></div><div><span style="font-size: 12pt;">def reduceByKey(partitioner: Partitioner, func: (V, V) =&gt; V): RDD[(K, V)]</span></div><div><br/></div><div><span style="font-size: 12pt;">参数 numPartitions 用于指定分区数；</span></div><div><span style="font-size: 12pt;">参数 partitioner 用于指定分区函数；</span></div><div><br/></div><div><span style="font-size: 12pt;">eg1.</span></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1 = sc.makeRDD(Array(("A",0),("A",2),("B",1),("B",2),("C",1))) rdd1.partitions.size // res82: Int = 15var rdd2 = rdd1.reduceByKey((x,y) =&gt; x + y)rdd2.collect// res85: Array[(String, Int)] = Array((A,2), (B,3), (C,1))rdd2.partitions.size// res86:Int=15 var rdd2=rdd1.reduceByKey(new org.apache.spark.HashPartitioner(2),(x,y)=&gt;x+y)//rdd2:org.apache.spark.rdd.RDD[(String,Int)]=ShuffledRDD[95]at reduceByKey at:23 rdd2.collect// res87:Array[(String,Int)]=Array((B,3),(A,2),(C,1)) rdd2.partitions.size// res88:Int=2</div><div><span style="font-size: 12pt;"><span style="color: rgb(0, 0, 255);"> </span></span></div><div><span style="font-size: 12pt;">eg2.单词统计</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：val rdd1 = sc.textFile("/home/centos/test.txt")val rdd2 = rdd1.flatMap(line=&gt;line.split(" ")) // map( line=&gt;line.split(" "))   每一行 返回一个 数组( 包含 这一行的单词) ;    flatMap 把 这个数组 拍扁 成原子的 即 一个一个单词val rdd3 = rdd2.map(word = &gt; (word,1))// val rdd4 = rdd3.reduceByKey(_ + _)  val rdd4 = rdd3.reduceByKey( (x,y) =&gt; x + y )rdd4.collect</div><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">因为 groupByKey 会产生大量的 shuffle  开销，所以  可以使用 reduceByKey() ， 在map 端进行 预聚合  （详见  《大规模数据管理》-&gt;分布式计算框架 -&gt; spark 原理） </span></div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="http://lxw1234.com/archives/2015/07/363.htm" rev="en_rl_none"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/07/363.htm</span></a></div><div><br/></div><div><br/></div><div><br/></div><h1>操作分区 mapPartitions 和 mapPartitionsWithIndex</h1><div><br/></div><div><span style="font-size: 12pt;">（1）mapPartitions 函数 和 map 函数类似，只不过映射函数的参数 由RDD中的每一个元素 变成了 RDD中每一个分区的迭代器。mapPartitions  的作用类似于 MapReduce 中的 clean up 步骤。</span></div><div><br/></div><div><span style="font-size: 12pt;">如果在映射的过程中需要 频繁创建额外的对象，使用mapPartitions要比map高效。</span></div><div><span style="font-size: 12pt;">例如，将RDD中的所有数据通过JDBC连接写入数据库，如果使用map函数，可能要为每一个元素都创建一个connection，这样开销很大，如果使用mapPartitions，那么只需要针对每一个分区建立一个connection。</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1=sc.makeRDD(1to5,2) // 两个分片： (1,2) , (3,4,5)//rdd1有两个分区var rdd3=rdd1.mapPartitions{x=&gt;{|    var result=List[Int]()|    var i=0|    while(x.hasNext){|        i+=x.next()|    }|    result.::(i).iterator|   }|}// rdd3:org.apache.spark.rdd.RDD[Int]=MapPartitionsRDD[84]at mapPartitions at:23 //rdd3将rdd1中每个分区中的数值累加rdd3.collect// res65:Array[Int]=Array(3,12)rdd3.partitions.size//res66:Int=2</div><div><span style="font-size: 12pt;">（2）mapPartitionsWithIndex</span></div><div><br/></div><div><span style="font-size: 12pt;">函数作用同mapPartitions，不过提供了两个参数，第一个参数为分区的索引。</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1=sc.makeRDD(1to5,2)//rdd1有两个分区var rdd2=rdd1.mapPartitionsWithIndex{(x,iter)=&gt;{var result=List[String]()var i=0while(iter.hasNext){i+=iter.next()}result.::(x+"|"+i).iterator}}//rdd2将rdd1中每个分区的数字累加，并在每个分区的累加结果前面加了分区索引rdd2.collect//res13:Array[String]=Array(0|3,1|12)</div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="http://lxw1234.com/archives/2015/07/363.htm"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/07/363.htm</span></a></div><div><br/></div><h1>操作数据行 map 和 flatMap</h1><div><br/></div><div><span style="font-size: 12pt;">（1）map </span></div><div><span style="font-size: 12pt;">将一个RDD中的每个数据项，通过map中的函数映射变为一个新的元素。</span></div><img src="/Resources/2.RDD%20%E7%AE%97%E5%AD%90.resources/C736A18F-C9CC-4AB1-87FB-E5104A1ACA37.png" height="379" width="1087"/><div><br/></div><div><br/></div><div><span style="font-size: 12pt;">输出文件内容 </span></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">hadoop fs -cat /tmp/lxw1234/1.txt// hello world// hello spark// hello hive</div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：//读取HDFS文件到RDDvar data = sc.textFile("/tmp/lxw1234/1.txt")//使用map算子var mapresult = data.map(line =&gt; line.split("\\s+"))//运算map算子结果mapresult.collect// res0: Array[Array[String]] = Array(Array(hello, world), Array(hello, spark), Array(hello, hive))</div><div><br/></div><div><span style="font-size: 12pt;"><b>scala 正则表达式 ：</b></span></div><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:380px;" width="380px"><colgroup><col style="width: 190px;"/><col style="width: 190px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">\\d</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">表示 0-9 的数字,</span></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">\\s</span></div><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">表示 空格,回车,换行等空白符,</span></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;"> \\w</span></div><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">表示单词字符 ( 数字 字母 下划线 )</span></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">+号</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="font-size: 12pt;">表示一个或多个的意思</span></div></td></tr></tbody></table><div><br/></div><div><span style="font-size: 12pt;">（2）flatMap</span></div><div><span style="font-size: 12pt;">flatmap()是将函数应用于RDD中的每个元素，将返回的迭代器的所有内容构成新的RDD,这样就得到了一个由各列表中的元素组成的RDD,而不是一个列表组成的RDD。</span></div><img src="/Resources/2.RDD%20%E7%AE%97%E5%AD%90.resources/51EF3E9F-6C53-4686-8475-AE5C20C21344.png" height="369" width="993"/><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：//使用flatMap算子var flatmapresult = data.flatMap(line =&gt; line.split("\\s+"))//运算flagMap算子结果flatmapresult.collect//res1: Array[String] = Array(hello, world, hello, spark, hello, hive)</div><div><br/></div><div><span style="font-size: 12pt;"><span style="font-weight: bold;">引用</span></span></div><div><a href="http://lxw1234.com/archives/2015/06/325.htm" rev="en_rl_none"><span style="font-size: 12pt;">http://lxw1234.com/archives/2015/06/325.htm</span></a></div><div><br/></div><h1>reduce </h1><div><br/></div><div><span style="font-size: 12pt;">（1）reduce </span></div><div><br/></div><div><span style="font-size: 12pt;">根据映射函数f，对RDD中的元素进行二元计算，返回计算结果。</span></div><div><br/></div><div><span style="font-size: 12pt;">reduce把一个函数作用在一个序列 [x1, x2, x3, ...] 上，这个函数 必须接收两个参数（二元操作符： x  和 y  相当于 集合中的两个元素）</span></div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:python;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;"># python 中利用 reduce 求 sum from functools import reducedef add(x, y):   return x + yreduce(add, [1, 3, 5, 7, 9])</div><div><br/></div><div style="--en-codeblock:true;--en-codeblockLanguage:text/x-java;box-sizing: border-box; padding: 8px; font-family: Monaco, Menlo, Consolas, &quot;Courier New&quot;, monospace; font-size: 12px; color: rgb(51, 51, 51); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; background-color: rgb(251, 250, 248); border: 1px solid rgba(0, 0, 0, 0.14902); background-position: initial initial; background-repeat: initial initial; margin-top: 6px;">//在 spark-shell 模式下：var rdd1=sc.makeRDD(1to10,2) rdd1.reduce(_+_)// res18:Int=55 var rdd2=sc.makeRDD(Array(("A",0),("A",2),("B",1),("B",2),("C",1))) rdd2.reduce((x,y)=&gt;{    // x=("A",0)  y=("A",2)|(x._1+y._1,x._2+y._2)|})// res21:(String,Int)=(CBBAA,6)</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="spark 系列" scheme="https://xinrihui.github.io/categories/spark-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="spark" scheme="https://xinrihui.github.io/tags/spark/"/>
    
    <category term="分布式计算框架" scheme="https://xinrihui.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>计算机组成原理 -数据sense</title>
    <link href="https://xinrihui.github.io/2022/12/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%20-%E6%95%B0%E6%8D%AEsense/"/>
    <id>https://xinrihui.github.io/2022/12/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%20-%E6%95%B0%E6%8D%AEsense/</id>
    <published>2022-12-24T16:17:10.000Z</published>
    <updated>2022-12-24T16:17:10.782Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2022-12-24 16:12:25 +0000"/><meta name="source" content="yinxiang.superNote"/><meta name="updated" content="2022-12-24 16:16:12 +0000"/><title>计算机组成原理 -数据sense</title></head><body><div><br/></div><h1>1.不同硬件的性能指标</h1><div><br/></div><h2>Latency</h2><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:707px;" width="707px"><colgroup><col style="width: 285px;"/><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 162px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Latency</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Notes</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Notes2</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>L1 cache reference  （<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">读取CPU的一级缓存</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(255, 194, 0);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>0.5 ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Branch mispredict<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">(转移、分支预测)</span></span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>5   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>L2 cache reference（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);"> 读取CPU的二级缓存</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>7   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>14x L1 cache</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>L3 cache reference  </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>20   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Mutex lock/unlock（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">互斥锁\解锁</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>25   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Main memory reference（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">读取内存数据</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>100   ns  </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>200x L1 cache</div><div>20x L2 cache, </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Compress 1K bytes with Zippy</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Send 1 KB bytes over 1 Gbps network</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 4 KB randomly from SSD*</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>150,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>150 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from memory</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>250,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(255, 194, 0);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>250 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Round trip within same datacenter（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">从一个数据中心往返一次，ping一下</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>500,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>500 us</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(0, 168, 45);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><span style="color: rgb(255, 255, 255);">Disk seek（磁盘寻道）</span></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from 1 Gbps network（千兆网络）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>40X memory, </div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from 10Gbps network（万兆网络）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div> 4X memory</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from disk</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>30,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>30 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>120x memory, </div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Read 1 MB sequentially from SSD*</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div> 4X memory，</div><div>~1GB/sec </div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Send packet CA-&gt;Netherlands-&gt;CA（<span style="font-size: 12pt;"><span style="color: rgb(51, 51, 51);">一个包的一次远程访问</span></span>）</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>150,000,000   ns</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>150 ms</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr></tbody></table><div><br/></div><div><span style="font-family: unset;"><span style="color: unset;">#1. 千兆网  万兆网</span></span></div><div> 百兆网（100M）100mbit/s = 0.1 Gbps /s = 100M/8 B/s=12.5MB/s</div><div> 千兆网（1G） 1000mbit/s= 1Gbps /s = 125MB /s</div><div style="text-align:justify;"> 万兆网 （10G） 10000mbit/s=10Gbps /s=1.25GB /s</div><div style="text-align:justify;"><br/></div><div>#2.  内存 和 磁盘的访问速度，随机访问差 100 ,000 倍，顺序访问为 7倍 </div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://stackoverflow.com/questions/61065606/what-is-reference-when-it-says-l1-cache-reference-or-main-memory-reference" rev="en_rl_none">https://stackoverflow.com/questions/61065606/what-is-reference-when-it-says-l1-cache-reference-or-main-memory-reference</a></div><div><a href="https://stackoverflow.com/questions/4087280/approximate-cost-to-access-various-caches-and-main-memory" rev="en_rl_none">https://stackoverflow.com/questions/4087280/approximate-cost-to-access-various-caches-and-main-memory</a></div><div><br/></div><div><br/></div><h2><span style="font-family: unset;"><span style="color: unset;">IOPS </span></span></h2><div><br/></div><div>IOPS 和 数据吞吐量  MBPS(吞吐率) 适用于不同的场合：</div><div>读取10000个1KB文件，用时10秒  Throught(吞吐量)=1MB/s ，IOPS=1000（1s 读取 1000个文件）  追求 IOPS</div><div>读取1个10MB文件，用时0.2秒  Throught(吞吐量)=50MB/s, IOPS=5  追求 吞吐量</div><div><br/></div><div>（1）对4KB数据包进行 连续读 :</div><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:390px;" width="390px"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(255, 194, 0);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>MBPS(吞吐率)</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>IOPS</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>PCIE4.0-SSD</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>7000MB/s</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>PCIE-SSD</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>2000MB /S </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SSD </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>404MB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>103K/S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SAS</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>190MB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>41K/S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SATA</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>124MB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>31K/S</div></td></tr></tbody></table><div>顺序读，SAS总体表现是 SATA硬盘的1.3倍， 普通SSD 总体表现是sata硬盘的4倍：</div><div><br/></div><div>（2）对4KB数据包进行 随机读</div><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:390px;" width="390px"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>MBPS(吞吐率)</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};background-color:rgb(255, 194, 0);border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>IOPS</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>PCIE4.0-SSD</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1000K /S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>PCIE-SSD</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>500 K /S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SSD </div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>505MB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>129 K /S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SAS</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1784KB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>456/S</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>SATA</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>466KB/S</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>114/S</div></td></tr></tbody></table><div><br/></div><div><span style="color: rgb(255, 0, 0);">问题： 机械硬盘 （HDD）IOPS 理论值的计算</span></div><div><br/></div><div>IOPS = 1000 ms/ (寻道时间 + 旋转延迟)。可以忽略数据传输时间。</div><div><br/></div><div>7200 rpm的磁盘 IOPS = 1000 / (10.5 + 4.17) = 68 IOPS</div><div>10000 rpm的磁盘IOPS = 1000 / (7 + 3) = 100 IOPS</div><div>15000 rpm的磁盘IOPS = 1000 / (5 + 2) = 142 IOPS</div><div><br/></div><div><span style="color: rgb(255, 0, 0);">问题：为什么一定是 4KB</span></div><div>在NTFS格式的硬盘中，最小存储单元就是 4KB，测试软件会产生很多4KB小文件，</div><div><br/></div><div>随机：数据是随机分布的，以此来考验SSD对 内部数据的寻找速度，把这一堆 的 4KB小文件乱扔一气，让SSD自己找去吧。</div><div><br/></div><div>顺序：4KB 的小文件 是顺序存放的</div><div><br/></div><div><span style="font-weight: bold;">引用</span></div><div><a href="https://blog.csdn.net/luyegang1/article/details/74453879" rev="en_rl_none">https://blog.csdn.net/luyegang1/article/details/74453879</a></div><div><br/></div><h1>2.<span style="font-family: unset;"><span style="color: unset;">数据库的单节点性能</span></span></h1><div><br/></div><table style="--en-fitwindow:false;border-left:1px solid #d9d9d9;border-top:1px solid #d9d9d9;border-collapse:collapse;width:413px;" width="413px"><colgroup><col style="width: 283px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div><br/></div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>QPS</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>MySQL / PosgreSQL 等 SQL 数据库</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>1k </div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>MongoDB / Cassandra 等 硬盘型NoSQL 数据库</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>10k</div></td></tr><tr><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>Redis / Memcached</div></td><td style="--en-typeInfo:{&quot;type&quot;:&quot;text&quot;,&quot;data&quot;:{}};border-right:1px solid #d9d9d9;border-bottom:1px solid #d9d9d9;padding:10px;"><div>100k ~ 1m</div></td></tr></tbody></table><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="计算机组成原理" scheme="https://xinrihui.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
    
    <category term="内存性能" scheme="https://xinrihui.github.io/tags/%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD/"/>
    
    <category term="磁盘性能" scheme="https://xinrihui.github.io/tags/%E7%A3%81%E7%9B%98%E6%80%A7%E8%83%BD/"/>
    
    <category term="网络性能" scheme="https://xinrihui.github.io/tags/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD/"/>
    
    <category term="延迟" scheme="https://xinrihui.github.io/tags/%E5%BB%B6%E8%BF%9F/"/>
    
    <category term="IOPS" scheme="https://xinrihui.github.io/tags/IOPS/"/>
    
  </entry>
  
  <entry>
    <title>数据结构-查找</title>
    <link href="https://xinrihui.github.io/2022/12/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%9F%A5%E6%89%BE%E6%80%BB%E7%BB%93/"/>
    <id>https://xinrihui.github.io/2022/12/25/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%9F%A5%E6%89%BE%E6%80%BB%E7%BB%93/</id>
    <published>2022-12-24T16:04:51.000Z</published>
    <updated>2023-03-10T05:58:08.444Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2022-06-23 01:27:46 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2022-06-23 02:35:43 +0000"/><title>数据结构-查找总结</title></head><body><div><img src="/Resources/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%9F%A5%E6%89%BE%E6%80%BB%E7%BB%93.resources/%E6%9F%A5%E6%89%BE-1.jpg" height="500" width="1000"/></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="数据结构和算法" scheme="https://xinrihui.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="二分查找" scheme="https://xinrihui.github.io/tags/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
    
    <category term="跳表" scheme="https://xinrihui.github.io/tags/%E8%B7%B3%E8%A1%A8/"/>
    
    <category term="红黑树" scheme="https://xinrihui.github.io/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/"/>
    
    <category term="B+树" scheme="https://xinrihui.github.io/tags/B-%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>HBase - 事务</title>
    <link href="https://xinrihui.github.io/2022/12/24/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1/"/>
    <id>https://xinrihui.github.io/2022/12/24/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1/</id>
    <published>2022-12-24T15:40:19.000Z</published>
    <updated>2022-12-24T15:41:55.433Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2020-04-13 07:24:44 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="source-url" content="http://hbasefly.com/2017/07/26/transaction-2/"/><meta name="updated" content="2022-02-17 13:42:51 +0000"/><title>HBase 原理4：事务</title></head><body><div><div><br/></div><div><span style="font-size: 12pt;">HBase是BigTable的开源实现，事务模型也与BigTable一脉相承 –</span> <span style="font-size: 12pt; font-weight: bold;">仅支持行级别的事务</span><span style="font-size: 12pt;">。</span></div><div><span style="font-size: 12pt;">虽然Jeff Dean大神在接受采访时公开承认目前在技术领域最后悔的事情就是没有在BigTable中加入</span> <span style="font-size: 12pt; font-weight: bold;">跨行事务模型</span><span style="font-size: 12pt;">，以至于之后很多团队都在BigTable之上重复造各种各样的分布式事务轮子。</span></div><div><span style="font-size: 12pt;">之后Google又发布了一篇介绍分布式事务模型的的paper – Percolator，现在很多团队都参考该论文实现分布式事务，包括TiDB、Omid等</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">1.原子性</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase数据会首先写入WAL，再写入Memstore。写入Memstore异常很容易可以回滚，因此保证写入/更新原子性只需要保证 写入WAL的原子性即可。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase 0.98之前版本需要保证WAL写入的原子性并不容易，这由WAL的结构决定。</span></div><div><span style="font-size: 12pt;">假设一个行级事务更新R行中的3列（c1, c2, c3），来看看之前版本和当前版本的WAL结构：</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">之前版本WAL结构：</span></div></li></ul><div><span style="font-size: 12pt;">&lt;logseq1-for-edit1&gt;:&lt;KeyValue-for-edit-c1&gt;</span></div><div><span style="font-size: 12pt;">&lt;logseq2-for-edit2&gt;:&lt;KeyValue-for-edit-c2&gt;</span></div><div><span style="font-size: 12pt;">&lt;logseq3-for-edit3&gt;:&lt;KeyValue-for-edit-c3&gt;</span></div><div><span style="font-size: 12pt;">每个KV都会形成一个WAL单元，这样一行事务更新多少列就会产生多少个WAL单元。在将这些WAL单元append到日志文件的时候，一旦出现宕机或其他异常，就会出现部分写入成功的情况，原子性更新就无法保证。</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">当前版本WAL结构：</span></div></li></ul><div><span style="font-size: 12pt;">&lt;logseq#-for-entire-txn&gt;:&lt;WALEdit-for-entire-txn&gt;</span></div><div><span style="font-size: 12pt;">&lt;logseq#-for-entire-txn&gt;:&lt;-1, 3, &lt;Keyvalue-for-edit-c1&gt;, &lt;KeyValue-for-edit-c2&gt;, &lt;KeyValue-for-edit-c3&gt;&gt;</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">通过这种结构，每个事务 只会产生一个WAL单元。这样就可以保证WAL写入时候的原子性。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">2.</span><span style="font-size: 12pt; font-weight: bold;">事务隔离性&nbsp;&nbsp;保证&nbsp;&nbsp;一致性</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">2.1 写写并发控制</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">现在假设有 两个 并发写入 请求同时进来，都对</span> <span style="font-size: 12pt;"><span style="font-size: 12pt; color: rgb(255, 0, 0);">同一行数据</span></span><span style="font-size: 12pt; font-weight: bold;">&nbsp;&nbsp;</span><span style="font-size: 12pt;">进行写入。下图所示RowKey为Greg，现在分别更新 列族info 下的 Company列 和 Role列：</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">蓝色的写入请求：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/F3C23DF7-D3E7-4928-9550-8D0556ED3255.png" height="90" width="680"/></span></div><div><span style="font-size: 12pt;">虽然是 一行数据&nbsp;&nbsp; 但是&nbsp;&nbsp;底层存储的&nbsp;&nbsp;为两个 K-V&nbsp;&nbsp;元组：</span></div><div><span style="font-size: 12pt;">( key= greg + info+company , value= Cloudera&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= greg + info+role, value= Engineer )</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">绿色的写入请求：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/D40D1C81-1E1A-41E5-AA81-48F2FCF22855.png" height="78" width="554"/></span></div><div><span style="font-size: 12pt;">( key= greg + info+company , value= Restaurant&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= greg + info+role , value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;)</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">如果没有任何并发控制策略的话，写入数据（先写WAL，再写memstore）可能会出现不同 KV 写入”交叉”现象，如下图所示：</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/BDCD880D-1000-451D-899A-1D13B2A63E33.png" height="313" width="752"/></span></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">两个 并发请求&nbsp;&nbsp;都是操作同一行，这一行对应的 两个&nbsp;&nbsp;K-V&nbsp;&nbsp;元组（ 元组&nbsp;&nbsp;的值 即 value） 是&nbsp;&nbsp;交叉写入的：</span></span></div><div><span style="font-size: 12pt;">(key= greg + info+company , timestamp=1 , value= Cloudera&nbsp;&nbsp; )&nbsp;&nbsp;--&nbsp;&nbsp;蓝色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">( key= greg + info+company , timestamp=2&nbsp;&nbsp; ,value= Restaurant&nbsp;&nbsp; )&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;绿色的写入请求</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">( key= greg + info+role , timestamp=3&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;)&nbsp;&nbsp;&nbsp;&nbsp; --&nbsp;&nbsp;绿色的写入请求 </span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">( key= greg + info+role ,&nbsp;&nbsp;timestamp=4 ,value= Engineer )&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;蓝色的写入请求</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">对于&nbsp;&nbsp;每一个&nbsp;&nbsp;</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">元组&nbsp;&nbsp;的值&nbsp;&nbsp;</span><span style="font-size: 12pt;">都会取&nbsp;&nbsp;时间戳（timestamp） 最大的（标红的）， 用户最终读取到&nbsp;&nbsp;一行 数据&nbsp;&nbsp;中的两个&nbsp;&nbsp;列（元组）会产生不一致，如下：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/503BC97E-7B75-4524-8776-3F1FB3CB93D5.png" height="82" width="640"/></span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;对于 元组 可以 通过&nbsp;&nbsp; 时间戳版本&nbsp;&nbsp; 来 保证 事务，即&nbsp;&nbsp;某个 元组&nbsp;&nbsp;一定能保持一致性；</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">但是上述例子&nbsp;&nbsp;的中的&nbsp;&nbsp;不一致是出现在&nbsp;&nbsp;行上，</span></div><div><span style="font-size: 12pt;">即 一行数据的&nbsp;&nbsp; 各个列（元组）的版本&nbsp;&nbsp;出现了 混乱 ：company&nbsp;&nbsp;列取了&nbsp;&nbsp; 绿色写入请求，而 role 列 取了&nbsp;&nbsp;蓝色写入请求 ）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：如何实现写写并发控制？</span></div><div><span style="font-size: 12pt;">只需要 在写入（或更新）之前先获取</span> <span style="font-size: 12pt; font-weight: bold;">行锁</span><span style="font-size: 12pt;">，如果获取不到，说明已经有其他线程拿了该锁，就需要不断重试等待或者自旋等待，直至其他线程释放该锁。拿到锁之后开始写入数据，写入完成之后释放行锁即可。这种行锁机制是实现写写并发控制最常用的手段，后面可以看到MySQL也是使用 行锁来实现写写并发的。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：如何实现批量写入多行的写写并发？</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase支持批量写入（或批量更新），即一个线程 同时</span> <span style="font-size: 12pt; font-weight: bold;">更新同一个Region&nbsp;&nbsp;中的多行记录</span><span style="font-size: 12pt;">。</span></div><div><span style="font-size: 12pt;">那如何保证当前事务中的批量写入与其他事务中的批量写入的并发控制呢？与&nbsp;&nbsp;关系数据库 类似使用</span> <span style="font-size: 12pt; font-weight: bold;">两阶段锁协议：</span></div><div><span style="font-size: 12pt;">(1) 获取所有待写入（更新）行记录的行锁&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">(2) 开始执行写入（更新）操作</span></div><div><span style="font-size: 12pt;">(3) 写入完成之后再统一释放所有行记录的行锁</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">显然，两阶段锁协议&nbsp;&nbsp;可以避免出现死锁问题。（ 详见 《RDBMS》-> 2.数据库管理系统实现 -> 6.物理层的 并发控制）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">但是 ，</span> <span style="font-size: 12pt; font-weight: bold;">HBase&nbsp;&nbsp;的 两阶段&nbsp;&nbsp;锁协议&nbsp;&nbsp;仅仅保证了&nbsp;&nbsp;同一个 region&nbsp;&nbsp;内的隔离性，即 HBase&nbsp;&nbsp;仅支持&nbsp;&nbsp;同一个&nbsp;&nbsp;Region&nbsp;&nbsp;中的跨行事务</span><span style="font-size: 12pt;">。</span></div><div><span style="font-size: 12pt; font-weight: bold;">如果一个 事务&nbsp;&nbsp; 操作了 多个 region&nbsp;&nbsp;中的行 则&nbsp;&nbsp;还是会出现死锁</span><span style="font-size: 12pt;">。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">2.2 读写并发控制</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">读写之间是不是也需要一定的并发控制呢？如果不加并发控制，会出现什么现象呢？</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/AB4D9E36-BD93-4186-BFA4-0EA92F5EF3E8.png" height="451" width="1191"/></span></div><div><span style="font-size: 12pt;">上图分别是两个事务更新同一行数据，现在假设 第一个写事务（蓝色） 已经更新完成 ， 在第二个&nbsp;&nbsp;写事务（绿色）更新到一半的时候进来一个读请求，如果没有任何并发控制的话，读请求就会读到不一致的数据，Company列为Restaurant，Role列为Engineer</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/C0826838-55D2-4644-B2DA-F925866561A0.png" height="82" width="640"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">(key= greg + info+company , timestamp=1 , value= Cloudera&nbsp;&nbsp; )&nbsp;&nbsp;--&nbsp;&nbsp;蓝色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 70, 53);">( key= greg + info+role ,&nbsp;&nbsp;timestamp=2 ,value= Engineer )</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;蓝色的写入请求</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 70, 53);">( key= greg + info+company , timestamp=3&nbsp;&nbsp; ,value= Restaurant&nbsp;&nbsp; )&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;绿色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">----------------&nbsp;&nbsp;读取 Greg&nbsp;&nbsp;行&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">( key= greg + info+role , timestamp=4&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;)&nbsp;&nbsp;&nbsp;&nbsp; --&nbsp;&nbsp;绿色的写入请求 </span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">M1：</span></div><div><span style="font-size: 12pt;">实现读写并发最简单的方法就是 仿照 写写并发控制 – 加锁（</span><span style="font-size: 12pt; font-weight: bold;">封锁法</span><span style="font-size: 12pt;">&nbsp;&nbsp;详见 《RDBMS》-> 2.数据库管理系统实现 ）。但几乎所有数据库都不会这么做，性能太差，对于读多写少的应用来说必然不可接受。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">如果&nbsp;&nbsp;一个事务要 写某行，肯定不能让&nbsp;&nbsp;其他事务&nbsp;&nbsp;同时来写，所以 必须加上&nbsp;&nbsp;写锁（排他锁 ，X锁），</span></div><div><span style="font-size: 12pt;">若不加 写锁，可能会出现&nbsp;&nbsp;</span> <span style="font-size: 12pt; font-weight: bold;">丢失更新</span><span style="font-size: 12pt;">&nbsp;&nbsp;（</span><span style="font-size: 12pt; font-weight: bold;">Lost update</span><span style="font-size: 12pt;">） （ 详见 《RDBMS》-> 2.数据库管理系统实现 -> 6.物理层的 并发控制 ），这就是&nbsp;&nbsp; 利用&nbsp;&nbsp;封锁法&nbsp;&nbsp;实现&nbsp;&nbsp; 写写并发控制。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">如果&nbsp;&nbsp;读写并发控制 也使用&nbsp;&nbsp;封锁法中的 X锁&nbsp;&nbsp;来 实现 ，即一个事务在写&nbsp;&nbsp;某行的时候 禁止别的事务来读，虽然&nbsp;&nbsp;可以达到&nbsp;&nbsp;最高的隔离级别——可串行化，但是 系统的并发度会下降；</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">另一方面，若一个事务在写&nbsp;&nbsp;某行的时候 ，随意让&nbsp;&nbsp;别的事务来读，那么会&nbsp;&nbsp;导致&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">脏读（dirty read）</span><span style="font-size: 12pt;">&nbsp;&nbsp;、&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">不可重复读（unrepeatable read）</span></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">（ 详见 《RDBMS》-&gt; 2.数据库管理系统实现 -&gt; 6.物理层的 并发控制 ）</span></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">其实，脏读&nbsp;&nbsp;和&nbsp;&nbsp;不可重复读&nbsp;&nbsp;也不是不可以&nbsp;&nbsp;容忍，这取决于&nbsp;&nbsp;应用要求的&nbsp;&nbsp;事务的隔离级别，（详见&nbsp;&nbsp; 《分布式&nbsp;&nbsp;存储和数据库》->&nbsp;&nbsp;分布式事务处理 ）</span></div><div><span style="font-size: 12pt;">若 隔离&nbsp;&nbsp;级别为&nbsp;&nbsp; 读未提交（Read Uncommitted），则&nbsp;&nbsp;可能出现&nbsp;&nbsp; 脏读；</span></div><div><span style="font-size: 12pt;">若&nbsp;&nbsp;隔离&nbsp;&nbsp;级别为&nbsp;&nbsp;读已提交（Read Committed），则不会出现脏读，但是&nbsp;&nbsp;会出现 不可重复读；</span></div><div><span style="font-size: 12pt;">若&nbsp;&nbsp;隔离&nbsp;&nbsp;级别为&nbsp;&nbsp;&nbsp;&nbsp;可重复读 （Repeatable Read&nbsp;&nbsp;），则不会&nbsp;&nbsp;出现&nbsp;&nbsp;脏读、不可重复读&nbsp;&nbsp;但是&nbsp;&nbsp;会出现&nbsp;&nbsp;幻读；</span></div><div><span style="font-size: 12pt;">若&nbsp;&nbsp;隔离&nbsp;&nbsp;级别为&nbsp;&nbsp;可串性化 （Serializable），则&nbsp;&nbsp;不会&nbsp;&nbsp;出现&nbsp;&nbsp;脏读、不可重复读 、&nbsp;&nbsp;幻读；</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">数据库&nbsp;&nbsp;一般不会选择&nbsp;&nbsp;可串行化，MySql默认的隔离级别为 Repeatable Read ，Oracle默认的隔离级别为 Read Committed</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">因此，读写的并发&nbsp;&nbsp;控制&nbsp;&nbsp;可以采用&nbsp;&nbsp;下面的 MVCC&nbsp;&nbsp;方法&nbsp;&nbsp;</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">M2：</span><span style="font-size: 12pt; font-weight: bold;">MVCC</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase中 MVCC 机制实现主要分为两步：</span></div><ul><li><div><span style="font-size: 12pt;">在事务开始时，为每一个写（更新）事务 分配一个</span> <span style="font-size: 12pt; color: rgb(255, 0, 0);">Region级别</span> <span style="font-size: 12pt;">自增 的序列号</span></div></li><li><div><span style="font-size: 12pt;">为每一个读请求分配一个 已完成（已提交）的最大写事务序列号</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/5C08BC98-3C49-4C6E-818A-815C9094CAFF.png" height="571" width="1484"/></span></div><div><span style="font-size: 12pt;">上图中两个 写事务分别分配了 序列号1（wn=1）和 序列号2（wn=2），读请求进来的时候 事务1 已经完成（已经提交），事务2 还未完成，因此分配事务1 对应的序列号1给读请求。此时 序列号1对 本次读可见，序列号2 对本次读不可见，读到的数据是：</span></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/F3C23DF7-D3E7-4928-9550-8D0556ED3255.png" height="90" width="680"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">(key= greg + info+company , timestamp=1 , value= Cloudera , wn=1&nbsp;&nbsp; )</span><span style="font-size: 12pt; color: rgb(255, 70, 53);">&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;蓝色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">( key= greg + info+role ,&nbsp;&nbsp;timestamp=1.5 ,value= Engineer ,&nbsp;&nbsp; wn=1 )&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt;">--&nbsp;&nbsp;蓝色的写入请求</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">wn&nbsp;&nbsp;list（commit list） : [ 1,&nbsp;&nbsp; ]</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">( key= greg + info+company , timestamp=2&nbsp;&nbsp; ,value= Restaurant , wn=2&nbsp;&nbsp; )&nbsp;&nbsp;--&nbsp;&nbsp;绿色的写入请求</span></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">----------------&nbsp;&nbsp;读取 Greg&nbsp;&nbsp;行&nbsp;&nbsp; ( row=</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">greg ,&nbsp;&nbsp;</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(255, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">wn=max(&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">wn_list&nbsp;&nbsp;</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(255, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">)=1</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= greg + info+role , timestamp=3&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=2&nbsp;&nbsp;)&nbsp;&nbsp;&nbsp;&nbsp; --&nbsp;&nbsp;绿色的写入请求 </span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">wn&nbsp;&nbsp;list（commit list） : [ 1, 2 ]</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">由此可见，</span><span style="font-size: 12pt; font-weight: bold;">MVCC&nbsp;&nbsp;的隔离级别&nbsp;&nbsp;至少为：</span> <span style="font-size: 12pt; font-weight: bold;">读已提交</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">具体实现中，</span><span style="font-size: 12pt; font-weight: bold;">所有的写事务都会生成一个 Region级别 的自增序列</span><span style="font-size: 12pt;">，并添加到队列（每一个 region&nbsp;&nbsp;有一个）中，如下图最左侧队列，其中最底端为已经提交的事务，队列中的事务为未提交事务。现假设当前事务编号为15，并且写入完成（中间队列红色框框），但之前的写入事务还未完成（序列号为12、13、14的事务还未完成），此时当前事务必须等待，而且对读并不可见，直至之前所有事务完成之后才会对读可见（ 即读请求才能读取到该事务写入的数据 ）。如最右侧图，15号事务之前的所有事务都成功完成，此时Read Point就会移动到15号事务处，表示15号事务之前的所有改动都可见。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;"><img src="/Resources/HBase%20%E5%8E%9F%E7%90%864%EF%BC%9A%E4%BA%8B%E5%8A%A1.resources/0B277B7C-EE1B-43DD-ACC4-91705871EF00.png" height="412" width="1067"/></span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">所以，MVCC的精髓是&nbsp;&nbsp;</span> <span style="font-size: 12pt;">写入的时候分配 递增版本号（Sequence Id）（该版本信息取的是&nbsp;&nbsp; 事务开始时的时间戳），读取的时候分配&nbsp;&nbsp; 一个&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">连续已完成最大</span> <span style="font-size: 12pt;">的版本 用于读取 可见，比之大的版本不可见</span><span style="font-size: 12pt;">。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">由此可见 ， 采用 MVCC 隔离级别&nbsp;&nbsp;至少可以达到：</span><span style="font-size: 12pt; font-weight: bold;">可重复读</span><span style="font-size: 12pt;">。</span></div><div><span style="font-size: 12pt;">例如， A事务 读取的时候&nbsp;&nbsp;被分配了&nbsp;&nbsp;版本 wn=3，在A事务的&nbsp;&nbsp;生命期内&nbsp;&nbsp;无论它 读 多少次，一定只能 拿到&nbsp;&nbsp; 版本 wn=3 的数据；即使在&nbsp;&nbsp; A事务的&nbsp;&nbsp;生命期内，&nbsp;&nbsp; B事务&nbsp;&nbsp;更新了数据&nbsp;&nbsp;并提交成功，数据的最大版本变为 wn=4。</span><span style="font-size: 12pt; color: unset; font-family: unset;">因此，不会出现&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">不可重复读</span><span style="font-size: 12pt; color: unset; font-family: unset;">&nbsp;&nbsp;的现象。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase一个标准写事务的流程如下：</span></div><ul><li><div><span style="font-size: 12pt; color: unset; font-family: unset;">锁行，拒绝对相同行的并发写</span></div></li><li><div><span style="font-size: 12pt;">获取当前的写入号</span></div></li><li><div><span style="font-size: 12pt;">将修改写入“写前日志”WAL(Write Ahead Log)</span></div></li><li><div><span style="font-size: 12pt;">将修改写入Memstore，同时用获取到的写入号标记KeyValue对</span></div></li><li><div><span style="font-size: 12pt;">提交事务，即尝试将读取点滚到获取到的写入号(这样变更就可以对所有新的Scan可见)</span></div></li><li><div><span style="font-size: 12pt;">打开行锁</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">HBase</span><span style="font-size: 12pt;">一个标准读事务的流程如下：</span></div><ul><li><div><span style="font-size: 12pt;">打开Scanner</span></div></li><li><div><span style="font-size: 12pt;">获取当前读取点</span></div></li><li><div><span style="font-size: 12pt;">筛选出所有memstore时间戳大于读取点的KeyValue对</span></div></li><li><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关闭Scanner</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><hr/><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：为什么&nbsp;&nbsp;读取的时候&nbsp;&nbsp;必须&nbsp;&nbsp;分配一个&nbsp;&nbsp;连续已完成最大 的版本（wn）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">1.保证了&nbsp;&nbsp;一个 Region&nbsp;&nbsp;内的&nbsp;&nbsp;单行事务：</span></div><div><br/></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">eg1.</span></span></div><div><span style="font-size: 12pt;">在同一个&nbsp;&nbsp;Region&nbsp;&nbsp;中：</span></div><ul><li><div><span style="font-size: 12pt;">t= 5 发起 写事务&nbsp;&nbsp;插入 TID=5 （</span><span style="font-size: 12pt; font-weight: bold;">TID&nbsp;&nbsp;取 事务开始时的时间戳</span><span style="font-size: 12pt;">） ：</span></div></li></ul><div><span style="font-size: 12pt;">( key= abby+ info+company , timestamp=5&nbsp;&nbsp; ,value= Restaurant , wn=5&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key=abby+ info+role , timestamp=</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">5.5</span><span style="font-size: 12pt;">&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=5 )&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">t= 7&nbsp;&nbsp;发起&nbsp;&nbsp;写事务&nbsp;&nbsp;插入&nbsp;&nbsp; TID=7：</span></div></li></ul><div><span style="font-size: 12pt;">( key= keven + info+company , timestamp=7&nbsp;&nbsp; ,value= Restaurant , wn=7&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= keven+ info+role , timestamp=</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">11</span><span style="font-size: 12pt;">&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=7 )&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><br/></div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">t= 8&nbsp;&nbsp;</span><span style="font-size: 12pt;">发起 写事务</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">&nbsp;&nbsp;插入 TID=8：</span></div></li></ul><div><span style="font-size: 12pt;">( key= greg + info+company , timestamp=8&nbsp;&nbsp; ,value= Restaurant , wn=8&nbsp;&nbsp; )</span></div><div><span style="font-size: 12pt;">( key= greg + info+role , &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;timestamp= </span><span style="font-size: 12pt; color: rgb(255, 0, 0);">9</span><span style="font-size: 12pt;">&nbsp;&nbsp; , value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wn=8 )&nbsp;&nbsp; </span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">t=10&nbsp;&nbsp; 发起&nbsp;&nbsp;读事务 Read1 ，读取整个 region（分区） ，</span></div></li></ul><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">此时， 已完成的&nbsp;&nbsp;最大版本号为 8 即</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">TID=8 已经提交</span><span style="font-size: 12pt;">，但是，</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">TID=7 还未提交，所以</span><span style="font-size: 12pt;">&nbsp;&nbsp;连续已完成的&nbsp;&nbsp;最大的版本号为 5&nbsp;&nbsp; ；</span></div><div><span style="font-size: 12pt;">因此 读事务Read1 能看&nbsp;&nbsp;版本&nbsp;&nbsp;小于等于 wn=5 的&nbsp;&nbsp;分区的数据，即&nbsp;&nbsp; keven&nbsp;&nbsp;和&nbsp;&nbsp;greg&nbsp;&nbsp;行 都看不到，即使&nbsp;&nbsp;Read1&nbsp;&nbsp; 在 t=12&nbsp;&nbsp;又读了一次数据。</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; font-weight: bold;">----------------------------------------------------------------------</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">假设&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">读取的时候分配 一个&nbsp;&nbsp; 已完成&nbsp;&nbsp; 最大的版本 用于读取 可见</span><span style="font-size: 12pt; color: unset; font-family: unset;">，而不要求&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">连续已完成&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset;">&nbsp;&nbsp;，则&nbsp;&nbsp;可能出现&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">幻读</span><span style="font-size: 12pt; color: unset; font-family: unset;">：</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">t=10&nbsp;&nbsp; 发起&nbsp;&nbsp;读事务 Read1 ，读取整个 region，</span></div></li></ul><div><span style="font-size: 12pt;">此时， 已完成的&nbsp;&nbsp;最大版本号为 8 即</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">TID=8 已经提交</span><span style="font-size: 12pt;">，</span></div><div><span style="font-size: 12pt;">读事务Read1 能看&nbsp;&nbsp;版本&nbsp;&nbsp;小于等于 wn=8 的&nbsp;&nbsp;分区的数据，但是不能看未提交的，因此：</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">当 t=10&nbsp;&nbsp; Read1&nbsp;&nbsp; 能看到&nbsp;&nbsp;abby&nbsp;&nbsp;greg&nbsp;&nbsp;行，看不到&nbsp;&nbsp;keven&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">当 t=12&nbsp;&nbsp;&nbsp;&nbsp;TID=7 已经提交，Read1&nbsp;&nbsp; 能看到&nbsp;&nbsp;&nbsp;&nbsp;abby&nbsp;&nbsp;greg&nbsp;&nbsp;keven&nbsp;&nbsp;行，此时出现了&nbsp;&nbsp;在一个事务中 ，看到了&nbsp;&nbsp;前一次读取 看不到的行：keven ，即</span> <span style="font-size: 12pt; font-weight: bold;">幻读</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt; font-weight: bold;">----------------------------------------------------------------------</span></div><div><span style="font-size: 12pt;"><br/></span></div><ul><li><div><span style="font-size: 12pt;">t=12&nbsp;&nbsp;发起&nbsp;&nbsp;读事务 Read2 ，读取整个 region，</span></div></li></ul><div><span style="font-size: 12pt;">此时，连续已完成的&nbsp;&nbsp;最大的版本号为 8 ，因此 读事务Read2&nbsp;&nbsp;能看&nbsp;&nbsp;版本&nbsp;&nbsp;小于等于 wn=8 的&nbsp;&nbsp;分区的数据，abby&nbsp;&nbsp;greg&nbsp;&nbsp;keven&nbsp;&nbsp;行&nbsp;&nbsp;均可见</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">2.事务写入的时候分配&nbsp;&nbsp;的 递增版本号 取的是&nbsp;&nbsp;事务提交后的时间戳，则 “读取的时候分配一个已完成最大的版本用于读取可见”&nbsp;&nbsp;也可以实现 跨行的事务</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">eg1.</span></span></div><div><span style="font-size: 12pt;">在同一个&nbsp;&nbsp;Region&nbsp;&nbsp;中：</span></div><ul><li><div><span style="font-size: 12pt;">t= 5 发起 写事务&nbsp;&nbsp;&nbsp;&nbsp;：</span></div></li></ul><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">abby</span><span style="font-size: 12pt;">+ info+company , timestamp=5&nbsp;&nbsp; ,value= Restaurant , wn=5.5)</span></div><div><span style="font-size: 12pt;">( key=</span><span style="font-size: 12pt; font-weight: bold;">abby</span><span style="font-size: 12pt;">+ info+role , timestamp=5.5&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=5.5)&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">插入 TID=5.5 （</span><span style="font-size: 12pt; font-weight: bold;">TID&nbsp;&nbsp;取 事务&nbsp;&nbsp;提交的时间戳</span><span style="font-size: 12pt;">）</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">t= 7&nbsp;&nbsp;发起&nbsp;&nbsp;写事务 ：</span></div></li></ul><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">keven</span> <span style="font-size: 12pt;">+ info+company , timestamp=7&nbsp;&nbsp; ,value= Restaurant , wn=11)</span></div><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">keven</span><span style="font-size: 12pt;">+ info+role , timestamp=11&nbsp;&nbsp; ,value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;, wn=11)&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt;">插入&nbsp;&nbsp; TID=11</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">t= 8&nbsp;&nbsp;</span><span style="font-size: 12pt;">发起 写事务</span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">&nbsp;&nbsp;：</span></div></li></ul><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">greg</span> <span style="font-size: 12pt;">+ info+company , timestamp=8&nbsp;&nbsp; ,value= Restaurant , wn=9)</span></div><div><span style="font-size: 12pt;">( key=</span> <span style="font-size: 12pt; font-weight: bold;">greg</span> <span style="font-size: 12pt;">+ info+role , &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;timestamp=9&nbsp;&nbsp; , value=&nbsp;&nbsp;Waiter&nbsp;&nbsp;,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wn=9)&nbsp;&nbsp; </span></div><div><span style="font-size: 12pt;">插入&nbsp;&nbsp; TID=9</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">t=10&nbsp;&nbsp; 发起&nbsp;&nbsp;读事务 Read1 ，读取整个 region（分区） ，</span></div></li></ul><div><span style="font-size: 12pt;">此时， 已完成（已提交）的&nbsp;&nbsp;最大版本号为 9 即</span> <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; font-size: 12pt; color: rgb(0, 0, 0); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal;">TID=9 已经提交</span><span style="font-size: 12pt;">，</span></div><div><span style="font-size: 12pt; color: unset; font-family: unset;">因此 读事务Read1 能看&nbsp;&nbsp;版本&nbsp;&nbsp;小于等于 wn=9 的&nbsp;&nbsp;分区的数据，即&nbsp;&nbsp;能看到&nbsp;&nbsp;abby&nbsp;&nbsp;&nbsp;&nbsp;greg&nbsp;&nbsp;行，而&nbsp;&nbsp; keven 行 看不到，即使&nbsp;&nbsp;Read1 ， 在 t=12&nbsp;&nbsp;Read1又读了一次数据，结果仍然如此。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><hr/><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">这里需要注意版本必须递增，而且&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">唯一</span><span style="font-size: 12pt; font-weight: bold;">递增版本号 的&nbsp;&nbsp;作用范围一定程度上决定了 事务是什么级别的事务</span><span style="font-size: 12pt;">，比如HBase是 Region级别的 递增版本号，那么 事务就是region级别事务。MySQL中版本是单机递增版本，那么MySQL事务就支持单机跨行事务。Percolator中版本是集群递增版本，那么Percolator事务就是分布式事务。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">因此，在分布式数据库中，</span><span style="font-size: 12pt;">一个&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">统一高可用的发号器</span><span style="font-size: 12pt;">&nbsp;&nbsp;来做 版本号的递增&nbsp;&nbsp;是实现&nbsp;&nbsp;分布式事务的关键</span><span style="font-size: 12pt;">。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：</span> <span style="font-size: 12pt;"><span style="font-size: 12pt; color: rgb(255, 0, 0);">Spanner</span>&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">如何&nbsp;&nbsp;实现&nbsp;&nbsp;跨机房的&nbsp;&nbsp;唯一递增版本号？</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">在google&nbsp;&nbsp;的&nbsp;&nbsp;Spanner&nbsp;&nbsp;中，</span><span style="font-size: 12pt; color: unset; font-family: unset;">存在两个 level&nbsp;&nbsp;的&nbsp;&nbsp;发号器：</span></div><div><font style="font-size: 12pt;"><br/></font></div><ul><li><div><span style="font-size: 12pt;">在每个机房都 有一个&nbsp;&nbsp;中心发号器，该机房的节点&nbsp;&nbsp;处理的事务&nbsp;&nbsp;请求都要&nbsp;&nbsp;来这里&nbsp;&nbsp;拿一个 唯一的递增版本号。这个中心发号器&nbsp;&nbsp;自身&nbsp;&nbsp;也可以做成 分布式的，并采用分布一致性算法&nbsp;&nbsp;保证&nbsp;&nbsp;版本号唯一且递增（&nbsp;&nbsp;例如&nbsp;&nbsp; zookeeper&nbsp;&nbsp;的&nbsp;&nbsp;临时递增节点 ）</span></div></li></ul><div><span style="font-size: 12pt;">&nbsp;&nbsp;</span></div><div><br/></div><ul><li><div><span style="font-size: 12pt;">分布在全球各个&nbsp;&nbsp;机房 中的集群 都有 一个 原子钟，在初始化 校准后 ，所有机房的原子钟 都是同步的（误差很小&nbsp;&nbsp;且能&nbsp;&nbsp;确定误差的范围）。</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">因此Spanner&nbsp;&nbsp;可以&nbsp;&nbsp;实现&nbsp;&nbsp; 全球所有&nbsp;&nbsp;机房中的&nbsp;&nbsp;所有节点的&nbsp;&nbsp;&nbsp;&nbsp;版本的递增，也就实现了&nbsp;&nbsp;全球 的 分布式事务，&nbsp;&nbsp;全球的所有节点可以 作为&nbsp;&nbsp;一个&nbsp;&nbsp;统一的分布式数据库 使用。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">在&nbsp;&nbsp;OceanBase 中，有 3个节点 组成的NTP 服务 来做 发号器，由NTP服务保证 3个节点的时钟同步，因为 时钟的精度可以达到 ns ，即 1 s 可以发 10^9 个号，足以满足 高并发事务的要求；若 有1台 服务器宕机，NTP 服务 会将时钟 整体向后漂移 一段时间，保证 发放的 版本号 一定随时间递增，不会出现时光倒流。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：</span><span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">OceanBase</span><span style="font-size: 12pt; color: rgb(255, 0, 0);">为何&nbsp;&nbsp;只有&nbsp;&nbsp;可串行化&nbsp;&nbsp;和&nbsp;&nbsp;读已提交&nbsp;&nbsp;两种隔离级别？（</span><span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">对比&nbsp;&nbsp;&nbsp;&nbsp;OceanBase 和 DB2&nbsp;&nbsp;&nbsp;&nbsp;中 事务的隔离级别</span><span style="font-size: 12pt; color: rgb(255, 0, 0); font-family: unset;">）</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">1.OB&nbsp;&nbsp;采用 MVCC&nbsp;&nbsp;的方法：</span></div><ul><li><div><span style="font-size: 12pt;">对于&nbsp;&nbsp;写事务，在事务 提交 之后 发一个&nbsp;&nbsp;时间戳作为&nbsp;&nbsp; 发生更新数据的版本号</span></div></li><li><div><span style="font-size: 12pt;">对于读事务，</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果隔离&nbsp;&nbsp;级别设定为&nbsp;&nbsp;可串行化，那么&nbsp;&nbsp;在整个读事务&nbsp;&nbsp;的周期中，所有的读取 都使用&nbsp;&nbsp;第一次读取&nbsp;&nbsp;拿到的版本号，即读取 只能读到&nbsp;&nbsp;更新时间 <=&nbsp;&nbsp;版本号&nbsp;&nbsp;的行 ，这样&nbsp;&nbsp;可以避免&nbsp;&nbsp;幻读（幻读一定是在我读事务的周期里更新了数据，并且更新的这一行数据有一个更大的版本号）； </span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></div><div><span style="font-size: 12pt;">&nbsp;&nbsp;&nbsp;&nbsp; 如果&nbsp;&nbsp;隔离&nbsp;&nbsp;&nbsp;&nbsp;级别设定为&nbsp;&nbsp; 读已提交，那么&nbsp;&nbsp;在整个读事务&nbsp;&nbsp;的周期中，每一次&nbsp;&nbsp;读取&nbsp;&nbsp;都拿一个&nbsp;&nbsp;新的版本号，这样就会出现&nbsp;&nbsp;每次读取&nbsp;&nbsp;所能看到的 数据版本&nbsp;&nbsp;可能不一样（不可重复读现象） </span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">2.OB&nbsp;&nbsp;的&nbsp;&nbsp;更新策略 采用&nbsp;&nbsp; “在commit&nbsp;&nbsp;开始之后&nbsp;&nbsp;才把&nbsp;&nbsp;更新写入数据库”，即&nbsp;&nbsp;遵从&nbsp;&nbsp;commit rule&nbsp;&nbsp;在提交之前&nbsp;&nbsp;先将&nbsp;&nbsp;新的值写入log&nbsp;&nbsp;中，恢复的&nbsp;&nbsp;时候&nbsp;&nbsp;使用&nbsp;&nbsp;日志中的&nbsp;&nbsp;新值&nbsp;&nbsp;去redo</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">3. OB&nbsp;&nbsp;采用&nbsp;&nbsp;主从结构，从节点&nbsp;&nbsp;中存着&nbsp;&nbsp;主节点&nbsp;&nbsp;数据的副本，为了保持&nbsp;&nbsp;一致性，读和写&nbsp;&nbsp;都请求的是主节点。</span></div><ul><li><div><span style="font-size: 12pt;">如果&nbsp;&nbsp;新数据 在主节点&nbsp;&nbsp;成功写入，那么&nbsp;&nbsp; 将 同步复制（主节点&nbsp;&nbsp;要收到&nbsp;&nbsp;从节点&nbsp;&nbsp;的写入&nbsp;&nbsp;成功的 ACK ） 到 n&nbsp;&nbsp;个&nbsp;&nbsp;从节点中（n+1 >= N/2&nbsp;&nbsp; ，N为&nbsp;&nbsp;总的副本数）</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">4.读写&nbsp;&nbsp;都是主节点&nbsp;&nbsp;导致&nbsp;&nbsp;主节点&nbsp;&nbsp;压力过大，OB&nbsp;&nbsp;采用了&nbsp;&nbsp;互为主备的方法：</span></div><div><div><font style="font-size: 12pt;"><br/></font></div><table style="border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 130px;"/><col style="width: 130px;"/><col style="width: 130px;"/></colgroup><tbody><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">节点1</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">节点2&nbsp;&nbsp;</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">节点3</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">A库&nbsp;&nbsp;主</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">A库&nbsp;&nbsp;副本1</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">A库&nbsp;&nbsp;副本2</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">B库&nbsp;&nbsp;副本1</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">B库&nbsp;&nbsp;主</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">B库&nbsp;&nbsp;副本2</span></div></td></tr><tr><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">C库&nbsp;&nbsp;副本1</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">C库&nbsp;&nbsp;副本2</span></div></td><td style="width: 130px; padding: 8px; border: 1px solid;"><div><span style="font-size: 12pt;">C库&nbsp;&nbsp;主</span></div></td></tr></tbody></table><div><span style="font-size: 12pt;">问题来了，请求 A&nbsp;&nbsp;库中的数据，我怎么知道 A库的主节点是哪个：每个节点 都有一张路由表，记录&nbsp;&nbsp;哪个库的&nbsp;&nbsp;主节点是谁，如果来了请求，发现&nbsp;&nbsp;主节点不是我，我把请求路由走</span></div></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; color: rgb(255, 0, 0);">问题：DB2&nbsp;&nbsp; 如何&nbsp;&nbsp;做到&nbsp;&nbsp; 4&nbsp;&nbsp;种隔离级别&nbsp;&nbsp;都支持</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">1.采用&nbsp;&nbsp;锁机制，但是它的锁很复杂：有写锁，还有读锁；</span></div><div><span style="font-size: 12pt;"><br/></span></div><div><span style="font-size: 12pt;">对于读锁，有 范围读锁，比如&nbsp;&nbsp;一个读事务：select *from A where date > 2020-06-01&nbsp;&nbsp;那么&nbsp;&nbsp;读锁会把&nbsp;&nbsp;表中&nbsp;&nbsp;满足 date > 2020-06-01&nbsp;&nbsp;行 全部锁起来&nbsp;&nbsp;不让别人写，这样就不会出现&nbsp;&nbsp;读取到一半&nbsp;&nbsp;内容被人修改的情况。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><span style="font-size: 12pt; font-weight: bold;">3.</span><span style="font-size: 12pt; font-weight: bold;">事务持久性&nbsp;&nbsp;</span></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">HBase事务持久化可以理解为WAL持久化，目前实现了多种持久化策略：SKIP_WAL，ASYNC_WAL，SYNC_WAL，FSYNC_WAL。</span></div><ul><li><div><span style="font-size: 12pt;">SKIP_WAL 表示不写WAL，这样写入更新性能最好，但在RegionServer宕机的时候有可能会丢失部分数据；</span></div></li><li><div><span style="font-size: 12pt;">ASYNC_WAL 表示异步将WAL持久化到硬盘，因为是异步操作所以在异常的情况下也有可能丢失少量数据；</span></div></li><li><div><span style="font-size: 12pt;">SYNC_WAL 表示同步将WAL持久化到操作系统缓存，再由操作系统将数据异步持久化到磁盘，这种场景下RS宕掉并不会丢失数据，当操作系统宕掉会导致部分数据丢失；</span></div></li><li><div><span style="font-size: 12pt;">FSYNC_WAL 表示WAL写入之后立马落盘，性能相对最差。</span></div></li></ul><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt;">用户可以根据业务对数据丢失的敏感性在客户端配置相应的持久化策略。</span></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><span style="font-size: 12pt; font-weight: bold;">引用</span></div><div><a href="http://hbasefly.com/2017/07/26/transaction-2/" style="font-size: 12pt;">http://hbasefly.com/2017/07/26/transaction-2/</a></div><div><a href="http://hbasefly.com/2017/08/19/mysql-transaction/" style="font-size: 12pt;">http://hbasefly.com/2017/08/19/mysql-transaction/</a></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div><div><font style="font-size: 12pt;"><br/></font></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="分布式数据库系列" scheme="https://xinrihui.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="HBase" scheme="https://xinrihui.github.io/tags/HBase/"/>
    
    <category term="事务" scheme="https://xinrihui.github.io/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>MPP 数据库原理</title>
    <link href="https://xinrihui.github.io/2022/12/24/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/"/>
    <id>https://xinrihui.github.io/2022/12/24/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/</id>
    <published>2022-12-24T15:40:19.000Z</published>
    <updated>2022-12-25T02:02:20.784Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.6.1 (469462)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2019-03-03 11:24:10 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="evernote.win32"/><meta name="source-url" content="https://www.zybuluo.com/hadoopMan/note/1005029"/><meta name="updated" content="2022-12-24 15:37:00 +0000"/><title>MPP 数据库原理</title></head><body><div><div><span style="font-weight: bold;"><font style="font-size: 16px;">part1. SMP &amp; MPP</font></span></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">1.服务器的CPU 架构：</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">（1）SMP (Symmetric Multi Processing) 对称多处理系统。</font></div><div><font style="font-size: 16px;">所有的CPU共享全部资源，如总线，内存和I/O系统等。多个CPU之间没有区别，平等地访问内存、外设、一个操作系统。操作系统管理着一个队列，每个处理器依次处理队列中的进程。如果两个处理器同时请求访问一个资源（例如同一段内存地址），由硬件、软件的锁机制去解决资源争用问题。每一个共享的环节都可能造成 SMP 服务器扩展时的瓶颈，而<span style="font-weight: bold;">最受限制的则是内存</span>。由于每个 CPU 必须通过相同的内存总线访问相同的内存资源，因此随着 CPU 数量的增加，内存访问冲突将迅速增加。</font></div><div><font style="font-size: 16px;">（2）海量并行处理结构 (MPP ： Massive Parallel Processing)</font></div><div><font style="font-size: 16px;">由多个 SMP 节点  通过节点互联网络连接而成，<span style="font-weight: bold;">每个节点只访问自己的本地资源 ( 内存、存储等 )</span> ，是一种完全无共享 (Share Nothing) 结构，因而扩展能力最好。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">2.优点&amp;缺点</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">（1）MPP系统不共享资源，因此当需要处理的事务达到一定规模时，MPP的效率要比SMP好。由于MPP系统要在不同处理单元之间传送信息，在通讯时间少的时候，那MPP系统可以充分发挥资源的优势，达到高效率。也就是说：操作相互之间没有什么关系，处理单元之间需要进行的通信比较少，那采用MPP。典型的数据仓库环境具有大量复杂的数据处理和综合分析，要求系统具有很高的 I/O 处理能力，并且存储系统需要提供足够的 I/O 带宽与之匹配，因此适合MPP。</font></div><div><font style="font-size: 16px;">（2）OLTP 系统则以联机事务处理为主，每个交易所涉及的数据不多，要求系统具有很高的事务处理能力，能够在单位时间里处理尽量多的交易，因此适合SMP。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-weight: bold;"><font style="font-size: 16px;">引用</font></span></div><div><a href="https://www.cnblogs.com/yubo/archive/2010/04/23/1718810.html"><font style="font-size: 16px;">https://www.cnblogs.com/yubo/archive/2010/04/23/1718810.html</font></a></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><span style="font-weight: bold;">part2. </span><span style="font-weight: bold;">以 impala 为例 理解 MPP 的 pipline 执行</span></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">1. impala 是一个 MPP 的 查询引擎，它受到 google 的 dremel原理的启发而开发出来的，除了 dremel的全部功能之外，它提</font></div><div><font style="font-size: 16px;">供了 dremel不具备的 join 功能，可以说是 dremel的超集。</font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/20415850-44E2-4408-A856-CF67E38E7A4E.png" height="311" width="402"/><br/></font></div><div><font style="font-size: 16px;">2.<span style="font-weight: bold;">impala与 hive 使用同一个元数据库</span>，可以与hive 实现互访，并兼容大部分HQL 语言。 其基本原理是将一个查询根据</font></div><div><font style="font-size: 16px;">数据所在位置分割成为子查询并在各个节点上运行，各个节点运行结果在汇总形成最终结果后返回给客户端。 impala的每</font></div><div><font style="font-size: 16px;">个节点都直接读取本地数据，并在本地执行子查询。 在执行子查询时，节点之间交换数据完成各自的查询。具体的查询树</font></div><div><font style="font-size: 16px;">（图 ２）分布化过程为：</font></div><div><font style="font-size: 16px;">（1）impala接收到 SQL查询首先生成SQL查询树，由查询树区分 在本地运行 或者 是在分布式系统上运行的查询</font></div><div><font style="font-size: 16px;">（2）把SQL查询 拆散后 分配到 到各个节点上，达到高速查询的目的</font></div><div><font style="font-size: 16px;">（3）各个节点直接从 HDFS 的本地文件读取数据，各个节点上分别进行 连接 和 聚合 操作，由各个节点把处理后的数据汇总发送到接受查询的节点上，由该节点进行汇总聚合及最后的排序截取工作。</font></div><div><font style="font-size: 16px;">（4）查询失败就全部重新执行，无法容错。</font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/A88D3DDD-74C9-48DF-B0C3-E8139CC66D7B.png" height="292" width="356"/><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">3.impala 基本架构</font></div><div><font style="font-size: 16px;">impala 在每个节点上运行一个守护进程 impala daemon，每个节点都可以接受查询。 impala daemon 内部细分为impala</font></div><div><font style="font-size: 16px;">规划器（planner）、impala协调器（coordinator）、impala执行引擎（execengine）。 除此之外，impala 还需要运行状态存储器的守</font></div><div><font style="font-size: 16px;">护进程（statestore daemon），由状态存储器来保存和更新各个impala 的状态以供查询。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/CD66E110-738B-44D0-87B7-FCA6D6CE389B.png" height="384" width="801"/><br/></font></div><div><font style="font-size: 16px;">（1）用户通过impala  shell、JDBC／ODBC 程序发送查询命令到一个 impala 节点上。各个节</font></div><div><font style="font-size: 16px;">点对等，都可以有 impala 守护进程，都可以接收查询请求。</font></div><div><font style="font-size: 16px;">（2）由 impala 规划器接收和分析查询命令，<span style="font-weight: bold;">它与 namenode上的 hive、HDFS元数据库</span>和状态储存器进行通信，<span style="font-weight: bold;">获得各部</span></font></div><div><font style="font-size: 16px;"><span style="font-weight: bold;">分数据的位置，并将查询命令分割成小的子查询</span>。 状态储存器保存了各个 impala 节点的状态。</font></div><div><font style="font-size: 16px;">（3）<span style="font-weight: bold;">impala 协调器将子查询分配到各个节点的 impala 执行引擎上</span>。</font></div><div><font style="font-size: 16px;">（4）各个 impala 执行引擎执行各自的查询，它们直接读取本地 HDFS或 hbase的数据，并与其他执行引擎进行通信</font></div><div><font style="font-size: 16px;">以完成各自的查询。</font></div><div><font style="font-size: 16px;">（5）各个 impala 执行引擎把部分结果返回给 impala 协调器。</font></div><div><font style="font-size: 16px;">（6）impala 协调器汇总部分结果组成最终结果，将最终结果返回给客户端。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-weight: bold;"><font style="font-size: 16px;">part3. 对比 MPP 和 批处理计算框架（ MapReduce 和 spark ）</font></span></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">1.每个executor有独立的cpu、内存和磁盘等资源，除非 遇到 shuffle 过程即数据通过网络进行交换，每个executor不能访问其他executor的资源。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">2.每个executor执行同样的数据处理逻辑，处理的数据则是这个executor所在的节点的本地存储的数据分片。下图中垂直的虚线表示同步点（发生 shuffle ）</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">3.MPP 中最大的问题是  “拖后腿的人（straggler） ” 。下图中 大部分时间里，一直都是一个executor7在孤独的执行，而由于shuffle 其他executor必须等待它执行完 。这就是MPP架构问题的根源所在，这种情况很容易发生，比如磁盘做了Raid，但是有磁盘突然坏了，raid的性能就会下降了，或者因为硬件或者OS的问题导致CPU性能下降。</font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/916B631E-7E5B-4645-BBBE-3EE020027F44.png" height="705" width="1093"/><br/></font></div><div><font style="font-size: 16px;">4.并发是指可以有效的同时运行的查询数。MPP是完全“对称的”，即当查询开始执行时，每个节点都在并行的执行完全相同的任务。因此 <span style="font-weight: bold;">MPP支持的并发数和集群的节点数没有关系</span>。<span style="font-weight: bold;">MPP需要为高效数据处理速度放弃 并发</span>。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">5. 原本在两个同步点之间是单独的 stage 在执行，现在在MR中 则将stage切分成多个独立的“task”，在两个同步点之间，这些任务被随机的分配到空闲的executor上。而MPP的任务是和 这个 任务要处理的数据所在的节点绑定的（<span style="font-weight: bold;">计算和存储绑定</span>）。</font></div><div><font style="font-size: 16px;">MR 中，由于数据块 在多个节点上存在，这样计算框架可以在多个节点上启动任务处理本地数据，而不必在慢节点上吊死。</font></div><div><font style="font-size: 16px;">遇到性能差的 executor 只需要给他 较少的task即可。如果慢节点慢到实在不能忍，推测执行可以就会介入：执行慢的节点的任务会在其他节点启动，同时执行（谁先执行完就用谁的结果，而没有执行完的task会被kill掉）。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">6.MPP下，不需要把中间结果写入磁盘，因为每个executor处理一个task，所以数据可以直接“流入”下一执行阶段进行处理，这就是所谓的pipeline执行，性能非常可观。 但是如果在一个单独的executor中串行的处理不相关的task，就必须把中间结果写入本地磁盘，以便下一个stage能开始消费本 stage的数据。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">7.HAWQ 将 MPP和批处理系统进行了融合</font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/BD325DAA-06F6-4FBA-B682-EA149CC2C93F.png" height="449" width="1120"/><br/></font></div><div><font style="font-size: 16px;">Greenplum中的segemnt是指常驻在节点上的PostgreSQL单独实例，当然这里的PostgreSql是经过修改的。这些单实例可以用来生成“executor”进程，每个查询在单节点对应一个executor。如果是小查询，可以由4个executor进程完成或者一个也可以。如果是大的查询，可能就需要100个甚至1000个executor了。不管查询是大是小，都是按照MPP的方式完成的，即一个进程只能处理本地数据，并且中间结果不写磁盘。但是虚拟segment则可以让executor在任何节点执行。</font></div><div><font style="font-size: 16px;">（1）可以动态增加和删除集群中的”straggler“节点，</font></div><div><font style="font-size: 16px;">（2）查询现在需要的executor数是动态的，这就可以得到更高的并发性</font></div><div><font style="font-size: 16px;">（3）数据pipeline。在两个stage之间，实时的把数据从一个executor传递到另外一个（独立的查询依然是MPP的流程，而不是批处理的流程），所以不需要把中间结果写磁盘</font></div><div><font style="font-size: 16px;">（4）MPP类似，我们仍然可以尽可能的在本地存储的数据上执行查询任务。每个executor尝试在存储自己需要处理数据百分比最高的节点上执行</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">8. MR 为了保证容错性，会对中间结果进行落盘并且要在落盘之后才能被下一个 task 读取，而序列化会带来高延迟。spark 发源之初是为了 改进 MR对迭代计算支持较差而设计的（并不是为了做 SQL查询，而是后来有人把它披上了SQL的外衣），但是仍然没有避免 落盘带来的时间开销。</font></div><div><font style="font-size: 16px;">而 MPP 计算模型 （eg. Greenplum <span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(46, 46, 46);"><font face="Helvetica Neue">Impala</font></span><span style="letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(46, 46, 46); font-family: &quot;Microsoft YaHei&quot;, 宋体, &quot;Myriad Pro&quot;, Lato, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;"> </span>）把整个查询 划分为 一颗 执行计划树，而不是一连串的MapReduce任务；在分发执行计划后，</font></div><div><font style="font-size: 16px;">MPP使用拉取数据的方式获取结果，把结果数据 从 执行计划树的最底层叶节点 向上 传递和汇集，这样 <span style="line-height: 1.45;">减少了落盘的开销。</span></font></div><div><font style="font-size: 16px;">但是它的缺点在于 容错性无法保证，需要从业务的层面来解决。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><img src="/Resources/MPP%20%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86.resources/B27812C9-405C-4AE3-8A5D-B2FBDEDB2AF7.png" height="576" width="1338"/><br/></font></div><div><font style="font-size: 16px;">MPP下，不需要把中间结果写入磁盘，因为每个executor处理一个task，所以数据可以直接“流入”下一执行阶段进行处理，这就是所谓的pipeline执行，性能非常可观。<span style="font-weight: bold;">MR中，在一个单独的executor中串行的处理不相关的task，就必须把中间结果落盘，以便下一个执行步骤能开始消费本步骤的数据</span>。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-weight: bold;"><font style="font-size: 16px;">9.MR 和 MPP 的 设计思路</font></span></div><div><font style="font-size: 16px;"><br/></font></div><ul><li><div><font style="font-size: 16px;">hadoop ( MR + HDFS )</font></div></li></ul><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">    对于数据管理的理念是粗放型管理，以一个文件系统（HDFS）的模式，让用户根据文件夹的层级，把文件一股脑塞到一个分布式文件系统的大池子里面。而当用这些数据的时候，也是以批处理为主，所以每个机器上的文件基本都要从头到尾扫描一遍，所以也不存在太多的物理模型设计与逻辑模型设计。而数据库的本质在于数据管理，需要对外提供在线访问、增删改查等一系列操作。</font></div><div><font style="font-size: 16px;">     </font></div><div><font style="font-size: 16px;">    如果我们想在一大堆数据里面挑拣出符合某个条件的数据，数据库可以根据分区信息首先落到某个机器里，然后可以根据多维分区甚至落到某个文件上，之后再文件里面的索引数据页上使用树形结构查询，很快就可以定位到记录本身。能够做到这一切的前提是，数据库有一套很完善的数据管理和分布体系，因此查询、操作、更新、插入会非常直观高效。数据库能够做到高效的原因是把这些数据通过相对复杂的层级、分类、索引给管理起来，而Hadoop则通过完全放弃这些限制，获得了极大的自由度，但是丧失了对数据的管控能力。</font></div><div><font style="font-size: 16px;">     </font></div><div><font style="font-size: 16px;">    由于使用  这种粗放型的管理方式，只要简单地增加物理机就可以扩大hadoop的存储空间。而对于数据库来说，任何对于集群的改变都涉及到拓扑结构的变更，也可能会涉及到不同机器之间数据的迁移和 分区的记录进行重新散列 ，因此当集群中机器数量多的时候，依然维护复杂的数据管理模型会造成维护成本大幅度上升。</font></div><div><font style="font-size: 16px;">    </font></div><ul><li><div><font style="font-size: 16px;">MPP</font></div></li></ul><div><font style="font-size: 16px;">    </font></div><div><font style="font-size: 16px;">    mpp内存管理比较精细，他主要的想法是在每个机器上放个数据库。传统数据库的内存管理比较复杂，主要是内外存交互的东西，这样的架构决定了<span style="font-weight: bold;">mpp在小数据量的时候，latency 可以做的比较小，但是在大数据量的时候，Throughput做不上去</span>。MapReduce 的job是没有太多精细的内存管理的，他就是拼了命地scan，完了顶多就是个spill，这样的架构导致Throughput很大，但是latency很高。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-size: 16px; color: black; font-family: 微软雅黑; font-weight: bold;">MPP 对比</span><span style="font-size: 16px; color: black; font-family: 微软雅黑; font-weight: bold;">MapReduce</span></div><ul><ul><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">低延迟：</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">shuffle</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">过程的中间结果无需落盘，直接流入下一阶段的执行器中执行，形成数据</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">pipeline</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">  </span></div></li><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">预聚合：</span><span style="font-size: 16px;" /><span style="font-size: 16px; color: black; font-family: 微软雅黑;">同一份</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">数据使用不同</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">的维度进行</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">组织，加快查询（</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">Apache</span><span style="font-size: 16px;" /><span style="font-size: 16px; color: black; font-family: 微软雅黑;">Kylin</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">：</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">Cube</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">）</span></div></li><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">容错性：查询失败后无法利用中间结果复原，</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">必须</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">重试整个查询</span></div></li><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">吞吐量</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">低</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">：复杂的数据管理模型（索引、</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">SQL</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">执行计划树）</span></div></li><li><div><span style="font-size: 16px; color: black; font-family: 微软雅黑;">可</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">扩展性低：小于</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">100</span><span style="font-size: 16px; color: black; font-family: 微软雅黑;">个节点</span></div></li></ul></ul><div><br/></div><div><span style="font-size: 16px;">MR 没有考虑数据之间的依赖关系,作业之间完全独立，中间结果需存入磁盘或通过网络进行节点传输, 无法形成数据pipeline。</span></div><div><br/></div><div><span style="font-size: 16px;">spark在窄依赖中,因为每一个父 分区只能被一个子 分区所使用。因此在窄依赖中每一个父  分区计算完成后可以直接将计算结果传给其对应的子 分区，无需等待其他  分区的计算完成，因此也就无需落盘。在宽依赖关系中,因为一个子 分区需要用到多个父 分区的计算结果，所以必须等待所有的 分区计算完成后才能进行子 RDD 的计算，这被称为 pipeline-breaker。为了容错性，先计算好的分区需要落盘，等待别的 task 来这里取走数据。</span></div><div><br/></div><div><span style="font-size: 16px;">Spark 会根据宽窄依赖关系划分出不同的阶段(stage)，然后再根据 RDD 自身保存的依赖关系形成一个有向无环图(DAG)进行调度。阶段之间为宽依赖。阶段内部的 RDD 全都为窄依赖关系：将具有窄依赖关系的 RDD 分区分配到一个任务中进行管道化操作，任务内部数据无需通过网络传输且任务之间互不干扰。特别是在阶段2中，mapreduce 要把 作业1 的结果落盘，而spark直接骚气的管道操作。</span></div><div><br/></div><div><span style="font-weight: bold; font-size: 16px;">总结 mapreduce ，spark 和 mpp，就是一个 中间计算结果是否落盘的权衡，落盘导致计算慢但是系统的容错好，即任务中间失败了我还可以从落盘的数据恢复任务。MR 是啥操作都落，spark是有shuffle才落，MPP是全在内存 “落盘是什么我不知道”</span></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><span style="font-weight: bold;">10.</span><span style="font-weight: bold;">MPP 和 MR 的结合</span></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;">新型MPP 数据库 将逐步与Hadoop生态系统结合混搭使用，用MPP处理PB级别的、高质量的结构化数据，同时为应用提供丰富的SQL和事务支持能力; 用Hadoop实现半结构化、非结构化数据处理。这样可同时满足结构化、半结构化和非结构化数据的处理需求。</font></div><div><font style="font-size: 16px;">但是 impala对批量数据的处理如数据挖掘分析，不如HIVE稳定可靠。而impala天然是继承Hive的元数据，所以完全可以综合两者的优点，同一套数据，多个引擎。<span style="font-weight: bold;">Impala应对秒级的交互查询，Hive应对批量数据的分析</span>。即实现“<span style="font-weight: bold;">一套数据，多个引擎</span>”。</font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><font style="font-size: 16px;"><br/></font></div><div><span style="font-weight: bold;"><font style="font-size: 16px;">引用</font></span></div><div><font style="font-size: 16px;"><br/></font></div><div><a href="http://blog.jobbole.com/43233/"><font style="font-size: 16px;">http://blog.jobbole.com/43233/</font></a></div><div><a href="https://www.zhihu.com/question/22799482/answer/115844245"><font style="font-size: 16px;">https://www.zhihu.com/question/22799482/answer/115844245</font></a></div><div><a href="https://www.zhihu.com/question/22037987"><font style="font-size: 16px;">https://www.zhihu.com/question/22037987</font></a></div><div><a href="https://www.zhihu.com/question/27589901"><font style="font-size: 16px;">https://www.zhihu.com/question/27589901</font></a></div><div><a href="https://www.zybuluo.com/hadoopMan/note/1005029"><font style="font-size: 16px;">https://www.zybuluo.com/hadoopMan/note/1005029</font></a></div><div><font style="font-size: 16px;"><br/></font></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtm</summary>
      
    
    
    
    <category term="分布式数据库系列" scheme="https://xinrihui.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="spark" scheme="https://xinrihui.github.io/tags/spark/"/>
    
    <category term="OLAP" scheme="https://xinrihui.github.io/tags/OLAP/"/>
    
    <category term="MPP" scheme="https://xinrihui.github.io/tags/MPP/"/>
    
    <category term="MapReduce" scheme="https://xinrihui.github.io/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>XGBoost 源码分析 2</title>
    <link href="https://xinrihui.github.io/2022/12/05/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202/"/>
    <id>https://xinrihui.github.io/2022/12/05/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202/</id>
    <published>2022-12-05T07:12:33.000Z</published>
    <updated>2023-03-10T15:13:54.351Z</updated>
    
    <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8" standalone="yes"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.34 (469085)"/><meta name="author" content="735407517@qq.com"/><meta name="created" content="2021-09-19 08:32:12 +0000"/><meta name="source" content="desktop.win"/><meta name="source-application" content="yinxiang.win32"/><meta name="updated" content="2022-12-04 16:53:34 +0000"/><title>XGBoost 源码分析 2</title></head><body><div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold; line-height: 1.6;">3.树的更新机制</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">：</span></div><ul><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_colmaker</span></div></li></ul><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/updater_colmaker.cc">updater_colmaker.cc</a></div><ul><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_histmaker</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_quantile_hist</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_gpu_hist</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_prune</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_refresh</span></div></li><li><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">updater_sync</span></div></li></ul><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/C9C8E35D-79F0-4DF4-B887-3A1870A04EF0.jpg" height="50%" width="80%"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">同时，从代码继承上来看， 除了剪枝prune，刷新refresh，同步sync之外， 有三种核心的实现 （这里没有把GPU的实现放在图里面）：</span></div><ul style="padding: 0px; margin: 1.4em 0px; display: table;"><li style="list-style-type:none;display:table-row;list-style:none;"><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•HistMaker, CQHistMaker</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•ColMaker</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•QuantileHistMaker, QuantileHistMock</span></div></li></ul><div style="margin: -0.8em 0px;"><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/074EC1D3-7E53-4061-AD13-4590C8AC8FFC.jpg" height="50%" width="80%"/></div><div><br/></div></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">那么， 具体这几个更新的核心差异是什么呢？咱看参数是怎么告诉咱的？</span></div><div style="margin: -0.8em 0px;"><br/></div><ul style="padding: 0px; margin: 1.4em 0px; display: table;"><li style="list-style-type:none;display:table-row;list-style:none;"><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•ColMaker：是精准模型</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•HistMaker：是近似模型</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•QuantileHistMaker：是Hist模型</span></div></li><li style="list-style-type:none;display:table-row;list-style:none;"><div><br/></div><div><span style="display: table-cell; white-space: pre; font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">•GPUHistMaker：GPU近似模型</span></div></li></ul><div style="margin: -0.8em 0px;"><div><br/></div><div><br/></div><div><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/gbtree.cc">gbtree.cc</a></div><div><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">void GBTree::ConfigureUpdaters()&nbsp;&nbsp;</span></div><div><br/></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/D88E2ED6-9EDE-4340-9E30-95DA3CEBD68A.png" height="50%" width="80%"/></div></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;"><br/></span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">对应到论文的实现，精准贪心(kExact) 和 近似分位数( kApprox ) 算法.</span></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/CA30726C-652A-4D4E-8C17-102CA1F6D970.jpg" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">所以接下来， 我们只看精准实现ColMaker。前面咱提到，GBTree的DoBoost 是主要入口。其中最主要的实现是BoostNewTrees。这里对于多类情况， 每个类别都要生成一堆树。</span></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/gbtree.cc">gbtree.cc</a></div><div style="margin: -0.8em 0px;"><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">void GBTree::DoBoost</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/D8C6D1DC-8A99-4A4A-9B40-77CEE8CF49CB.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold;">4.XGBoost ColMaker 实现</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">BoostNewTrees里面主要是生成并发的新树（个数为num_parallel_tree， 这个配置其实和随机森林的意味更接近，后续可以假定就是num_parallel_tree=1， new_trees就一棵树），然后更新两种默认的更新器， ColMaker 和 TreePruner (剪枝)。</span></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/gbtree.cc">gbtree.cc</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">void GBTree::BoostNewTrees</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/6926056C-DF78-404D-B70D-6BBFBF49FA4C.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/23398D86-B30E-4DCD-AFC3-12BAFEA76915.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;">由上图可见7&nbsp;&nbsp;种&nbsp;&nbsp;</span><span style="font-size: 16px; font-weight: bold;">树的</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold; line-height: 1.6;">更新机制</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">然后，就看ColMaker的Update函数实现， 背后其实是 ColMaker::Builder 实现的。 最终依赖于Builder 的 EnumerateSplit实现：</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;">调用关系为：</span></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt;">TreeUpdater</span><span style="font-size: 16px;">:: Update() ->&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt;">TreeUpdater</span><span style="font-size: 12pt;">:: Builder ::</span><span style="font-size: 16px;">Update</span><span style="font-size: 12pt;">&nbsp;&nbsp; ->&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 16px;">&nbsp;&nbsp;</span><span style="font-size: 12pt;">TreeUpdater</span><span style="font-size: 12pt;">:: Builder :: findsplit&nbsp;&nbsp; ->&nbsp;&nbsp;</span><span style="font-size: 12pt;">UpdateSolution ->&nbsp;&nbsp;</span><span style="font-size: 16px;">&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt;">TreeUpdater</span><span style="font-size: 12pt;">:: Builder ::</span><span style="font-size: 12pt;">&nbsp;&nbsp;</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif;">EnumerateSplit</span></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/updater_colmaker.cc">updater_colmaker.cc</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">void Update()</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/860AA39A-F928-4835-BF2C-1EDAA1969706.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">virtual void Update(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/43D554E4-2E53-47F9-8FDA-2742904CD4F6.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">class Builder ::</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">&nbsp;&nbsp;inline void FindSplit(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/974ACC56-E6B8-465B-AF9D-A754204132FE.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">virtual void UpdateSolution(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/4148474B-ADDB-48F7-9081-6E146790AE2C.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class&nbsp;&nbsp; TreeUpdater ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">void EnumerateSplit(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/4A8C69E4-B6C9-488F-BC97-74778EE96FAE.png" height="50%" width="80%"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold; line-height: 1.6;">4.叶子节点分裂 (Split)</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">主要由TreeEvalutor 的 SplitEvaluator类负责完成</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="https://pic1.zhimg.com/80/v2-16faab48b7abe608b00bb734de7bacf4_720w.png"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">大体上咱又能够 把函数 和 对应的Paper公式相关起来了：</span></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/7A0EFC3D-6A81-4916-BD2F-BA3BB635873B.jpg" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 16px; color: unset; font-family: unset; font-weight: bold;">4.1. 计算 split&nbsp;&nbsp;前 原节点的&nbsp;&nbsp;权重(叶子节点的值)&nbsp;&nbsp; 和&nbsp;&nbsp;增益 (gain)</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/updater_colmaker.cc">updater_colmaker.cc</a></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 16px; color: unset; font-family: unset;">&nbsp;&nbsp;</span></div><div><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">inline void InitNewNode</span></div><div style="margin: -0.8em 0px;"><div><br/></div><div><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/00B069E8-EB87-4FD6-BACA-35953ECF55B5.png" height="50%" width="80%"/></div></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><div><br/></div></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">（1）拆分前 节点 的Gain</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">&nbsp;&nbsp;：</span></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/split_evaluator.h">split_evaluator.h</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">TreeEvaluator ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">SplitEvaluator ::&nbsp;&nbsp;</span><span style="font-size: 12pt; font-weight: bold;">float CalcGain</span></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/57C939F7-5FCB-4EF5-9640-ED1DA0266C06.png" height="50%" width="80%"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 12pt; font-weight: bold;">CalcGainGivenWeight</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/1CAC83B1-296E-4969-9A40-AE0D4E612C01.png" height="50%" width="80%"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/param_1.h">param_1.h</a></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><span style="font-size: 12pt; font-weight: bold;">inline T CalcGainGivenWeight</span></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/5C0CF495-F4F1-4ECB-B70E-45326D90B29D.png" height="50%" width="80%"/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: -0.8em 0px;"><br/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/938D9B25-7B42-4658-9D6C-1E335E929BE3.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">代码兼容了 L1(&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(18, 18, 18);">ThresholdL1&nbsp;&nbsp;</span><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">) 的情况，因此和&nbsp;&nbsp;公式不符</span></div><div style="margin: 1.4em 0px;"><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">（2）拆分前 节点的权重</span></div><div><br/></div><div><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; line-height: 1.6;">权重计算，要注意，这里兼容了L1和L2的正则化，但是论文中只给了L2的情况。</span></div><div><br/></div><div><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/param.h">param.h</a></div><div><br/></div><div><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">inline T CalcWeight</span></div></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/3344E4F7-595E-457D-948D-85EBA932711F.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/EE720179-F78A-4612-B9A1-71791241DC7E.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/F03D9AAD-C308-4F5B-879F-0472BE632D8A.jpg" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px; color: rgb(18, 18, 18); font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-weight: bold;">4.2. 计算&nbsp;&nbsp; Split后的 增益变化 loss_chg&nbsp;&nbsp;</span></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/updater_colmaker.cc">updater_colmaker.cc</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">void EnumerateSplit(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/E4ED2242-2AD0-4434-B39E-7D1E415F8945.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; font-weight: bold;">class Builder ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">inline void UpdateEnumeration</span><span style="font-size: 12pt; color: unset; font-family: unset; font-weight: bold;">(</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/1A97EF58-3DC8-499A-8582-A6BB3B551610.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/FD2B0B6A-AD70-4A59-A72B-28B2AA93E905.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><a href="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/split_evaluator.h">split_evaluator.h</a></div><div style="margin: 1.4em 0px;"><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">class&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(18, 18, 18); font-weight: bold;">TreeEvaluator ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(18, 18, 18); font-family: unset; font-weight: bold;">struct SplitEvaluator ::&nbsp;&nbsp;</span><span style="font-size: 12pt; color: rgb(18, 18, 18); font-family: unset; font-weight: bold;">double CalcSplitGain</span></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/8E08FA6D-D0E7-4081-B196-29065E2FF4E6.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><img src="/Resources/XGBoost%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%202.resources/D6456F8B-2390-442B-84EF-8BF187F8390D.png" height="50%" width="80%"/></div><div style="margin: 1.4em 0px;"><span style="font-size: 16px;">其中 GradStats&nbsp;&nbsp;记录了&nbsp;&nbsp;G&nbsp;&nbsp;和&nbsp;&nbsp;H ，即梯度的累加和</span></div><div style="margin: 1.4em 0px;"><br/></div><div style="margin: 1.4em 0px;"><span style="font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; color: rgb(18, 18, 18); font-weight: bold;">引用</span></div><div style="margin: 1.4em 0px;"><a href="https://zhuanlan.zhihu.com/p/336939389" style="color: rgb(18, 18, 18);">https://zhuanlan.zhihu.com/p/336939389</a></div><div><br/></div></div><div><br/></div></body></html>]]></content>
    
    
      
      
    <summary type="html">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/T</summary>
      
    
    
    
    <category term="XGBoost 系列" scheme="https://xinrihui.github.io/categories/XGBoost-%E7%B3%BB%E5%88%97/"/>
    
    
    <category term="xgboost" scheme="https://xinrihui.github.io/tags/xgboost/"/>
    
    <category term="源码分析" scheme="https://xinrihui.github.io/tags/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
</feed>
